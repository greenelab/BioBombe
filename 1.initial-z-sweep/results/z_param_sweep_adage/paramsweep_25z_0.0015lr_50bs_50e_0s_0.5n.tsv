	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.028621012546596193	0.01934632607673368	25	0.0015	50	50	0.0	0.5	9814
1	0.017954920338518015	0.016454370695933786	25	0.0015	50	50	0.0	0.5	9814
2	0.016752132018209832	0.016120579277110032	25	0.0015	50	50	0.0	0.5	9814
3	0.01656574909343269	0.01598763414240134	25	0.0015	50	50	0.0	0.5	9814
4	0.016492268327426913	0.01590240293718433	25	0.0015	50	50	0.0	0.5	9814
5	0.01645868192219581	0.01610157994578377	25	0.0015	50	50	0.0	0.5	9814
6	0.016435425459046832	0.015813070694857188	25	0.0015	50	50	0.0	0.5	9814
7	0.016387277309785078	0.015917770605512947	25	0.0015	50	50	0.0	0.5	9814
8	0.01639459289184548	0.01577047965387826	25	0.0015	50	50	0.0	0.5	9814
9	0.016375293394612616	0.01576823575055337	25	0.0015	50	50	0.0	0.5	9814
10	0.01634920723372187	0.015813767546734435	25	0.0015	50	50	0.0	0.5	9814
11	0.01633874223749892	0.015778620486961496	25	0.0015	50	50	0.0	0.5	9814
12	0.01632800946382373	0.015725589344851375	25	0.0015	50	50	0.0	0.5	9814
13	0.016323574748324382	0.015818730244202894	25	0.0015	50	50	0.0	0.5	9814
14	0.016319224438175416	0.015832696783126654	25	0.0015	50	50	0.0	0.5	9814
15	0.01628234308689095	0.015778638929997642	25	0.0015	50	50	0.0	0.5	9814
16	0.016290475687683482	0.015737565319778588	25	0.0015	50	50	0.0	0.5	9814
17	0.016269519529357342	0.015653838950207537	25	0.0015	50	50	0.0	0.5	9814
18	0.016260472582517616	0.01568104172335585	25	0.0015	50	50	0.0	0.5	9814
19	0.01624296044794872	0.01564016697632708	25	0.0015	50	50	0.0	0.5	9814
20	0.01623392425094409	0.015601838057429795	25	0.0015	50	50	0.0	0.5	9814
21	0.01622521967680437	0.015622356974201038	25	0.0015	50	50	0.0	0.5	9814
22	0.016229982637355738	0.015656798572259926	25	0.0015	50	50	0.0	0.5	9814
23	0.016219602200433867	0.01563949549275078	25	0.0015	50	50	0.0	0.5	9814
24	0.016194866448173827	0.015646965622218116	25	0.0015	50	50	0.0	0.5	9814
25	0.016183105107026013	0.01554599304792131	25	0.0015	50	50	0.0	0.5	9814
26	0.0161831361175052	0.015663129895441164	25	0.0015	50	50	0.0	0.5	9814
27	0.016186761518337388	0.015609612132833975	25	0.0015	50	50	0.0	0.5	9814
28	0.016176440242808923	0.015599030351362425	25	0.0015	50	50	0.0	0.5	9814
29	0.016150135389805902	0.015711713071207358	25	0.0015	50	50	0.0	0.5	9814
30	0.016159637998063327	0.015615781193980181	25	0.0015	50	50	0.0	0.5	9814
31	0.016136889316954495	0.015539655128910597	25	0.0015	50	50	0.0	0.5	9814
32	0.016134537464075213	0.015522939332869495	25	0.0015	50	50	0.0	0.5	9814
33	0.0161386970043757	0.015600924533266525	25	0.0015	50	50	0.0	0.5	9814
34	0.016126965960448346	0.01548706172977932	25	0.0015	50	50	0.0	0.5	9814
35	0.01612738294650214	0.015716278482135918	25	0.0015	50	50	0.0	0.5	9814
36	0.016120367285236598	0.015557698942863348	25	0.0015	50	50	0.0	0.5	9814
37	0.01613110595039527	0.015505383136623448	25	0.0015	50	50	0.0	0.5	9814
38	0.01610651984019309	0.015532758589086067	25	0.0015	50	50	0.0	0.5	9814
39	0.016075241625503705	0.015448040464255481	25	0.0015	50	50	0.0	0.5	9814
40	0.016064229885643173	0.015471119839648216	25	0.0015	50	50	0.0	0.5	9814
41	0.016057674358775496	0.015584231965087111	25	0.0015	50	50	0.0	0.5	9814
42	0.01605309506477154	0.015614490801144399	25	0.0015	50	50	0.0	0.5	9814
43	0.01604184624795882	0.015468435730592813	25	0.0015	50	50	0.0	0.5	9814
44	0.01605820530257952	0.01574223059591041	25	0.0015	50	50	0.0	0.5	9814
45	0.01605186099339897	0.015480178682557369	25	0.0015	50	50	0.0	0.5	9814
46	0.01604125676064192	0.01544210992140934	25	0.0015	50	50	0.0	0.5	9814
47	0.01603814901824232	0.015506168154298006	25	0.0015	50	50	0.0	0.5	9814
48	0.01605137616267724	0.01548121033510617	25	0.0015	50	50	0.0	0.5	9814
49	0.01603398886876802	0.015654050705893888	25	0.0015	50	50	0.0	0.5	9814
