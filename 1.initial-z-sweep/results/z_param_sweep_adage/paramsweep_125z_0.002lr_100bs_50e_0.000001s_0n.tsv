	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.038384419341227216	0.02682735690451717	125	0.002	100	50	1e-06	0.0	1606
1	0.02344001913149356	0.02155573348413234	125	0.002	100	50	1e-06	0.0	1606
2	0.02073424904458134	0.022190332765304563	125	0.002	100	50	1e-06	0.0	1606
3	0.01941278721738682	0.02055296524077027	125	0.002	100	50	1e-06	0.0	1606
4	0.019137054686032377	0.019084246765045772	125	0.002	100	50	1e-06	0.0	1606
5	0.018185467627756302	0.01846349688805996	125	0.002	100	50	1e-06	0.0	1606
6	0.017962225431945023	0.01923889772927328	125	0.002	100	50	1e-06	0.0	1606
7	0.01750181968380579	0.017775153796443177	125	0.002	100	50	1e-06	0.0	1606
8	0.016926642143314283	0.018215860065649733	125	0.002	100	50	1e-06	0.0	1606
9	0.016967712283553173	0.016884940496537243	125	0.002	100	50	1e-06	0.0	1606
10	0.016564039922684737	0.016608244992336738	125	0.002	100	50	1e-06	0.0	1606
11	0.016577506933785152	0.015998023483781126	125	0.002	100	50	1e-06	0.0	1606
12	0.016488655514735717	0.01657078287120816	125	0.002	100	50	1e-06	0.0	1606
13	0.016716991467912907	0.018864160471277074	125	0.002	100	50	1e-06	0.0	1606
14	0.01603269547284992	0.01836611227582905	125	0.002	100	50	1e-06	0.0	1606
15	0.01648471217137869	0.017504279161616447	125	0.002	100	50	1e-06	0.0	1606
16	0.01631497703763737	0.01577567808636345	125	0.002	100	50	1e-06	0.0	1606
17	0.0160381565861658	0.018346651840107392	125	0.002	100	50	1e-06	0.0	1606
18	0.016051851037854496	0.016552042296195463	125	0.002	100	50	1e-06	0.0	1606
19	0.015886315204556148	0.01709172631263106	125	0.002	100	50	1e-06	0.0	1606
20	0.016087281420624284	0.015970282142636426	125	0.002	100	50	1e-06	0.0	1606
21	0.015828140511353693	0.018316913308864227	125	0.002	100	50	1e-06	0.0	1606
22	0.016089129359326312	0.018997075285470507	125	0.002	100	50	1e-06	0.0	1606
23	0.01635622904747471	0.017054429552010322	125	0.002	100	50	1e-06	0.0	1606
24	0.015663738060427194	0.017610615512879697	125	0.002	100	50	1e-06	0.0	1606
25	0.015762273559791432	0.018926165153915295	125	0.002	100	50	1e-06	0.0	1606
26	0.015852719576431553	0.016455145022096416	125	0.002	100	50	1e-06	0.0	1606
27	0.015510863300385586	0.01710935732453036	125	0.002	100	50	1e-06	0.0	1606
28	0.015894776024775237	0.01807666768677832	125	0.002	100	50	1e-06	0.0	1606
29	0.015749801029341863	0.017863115783688214	125	0.002	100	50	1e-06	0.0	1606
30	0.015515920738644584	0.01728984185033273	125	0.002	100	50	1e-06	0.0	1606
31	0.01594290269158237	0.017908604306313095	125	0.002	100	50	1e-06	0.0	1606
32	0.015423311767226024	0.015103218361137018	125	0.002	100	50	1e-06	0.0	1606
33	0.01571038187756813	0.015962799350387392	125	0.002	100	50	1e-06	0.0	1606
34	0.015467385024732279	0.019453447372661494	125	0.002	100	50	1e-06	0.0	1606
35	0.015578853619530991	0.017428571052037278	125	0.002	100	50	1e-06	0.0	1606
36	0.015298172237103592	0.017225859569204013	125	0.002	100	50	1e-06	0.0	1606
37	0.015813584467357554	0.01634540130877529	125	0.002	100	50	1e-06	0.0	1606
38	0.015831415788622266	0.015040455838348395	125	0.002	100	50	1e-06	0.0	1606
39	0.015280590826501239	0.01632714035420413	125	0.002	100	50	1e-06	0.0	1606
40	0.01566031856984169	0.015496384986386016	125	0.002	100	50	1e-06	0.0	1606
41	0.015238844235599338	0.016121919238387853	125	0.002	100	50	1e-06	0.0	1606
42	0.015566237575666319	0.016772975806809292	125	0.002	100	50	1e-06	0.0	1606
43	0.015642700406775064	0.015809692406802515	125	0.002	100	50	1e-06	0.0	1606
44	0.015597651182574635	0.01728176815616925	125	0.002	100	50	1e-06	0.0	1606
45	0.015167365062767738	0.015801893645117547	125	0.002	100	50	1e-06	0.0	1606
46	0.01560430628883051	0.016449580604769646	125	0.002	100	50	1e-06	0.0	1606
47	0.015122781112702249	0.01767764303363133	125	0.002	100	50	1e-06	0.0	1606
48	0.015695442478918985	0.0163543555728849	125	0.002	100	50	1e-06	0.0	1606
49	0.015268550748511092	0.017454957895792923	125	0.002	100	50	1e-06	0.0	1606
