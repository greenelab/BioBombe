	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	2.423083316440171	1.0306682570714567	100	0.0005	50	50	0.001	0.5	612
1	1.9200629871443482	0.895028473428285	100	0.0005	50	50	0.001	0.5	612
2	1.504711837633933	0.7646388527768064	100	0.0005	50	50	0.001	0.5	612
3	1.1402164654113478	0.6427155217978512	100	0.0005	50	50	0.001	0.5	612
4	0.8445052486777774	0.5272687551054398	100	0.0005	50	50	0.001	0.5	612
5	0.6245498434239464	0.5120039190206656	100	0.0005	50	50	0.001	0.5	612
6	0.4877785002543824	0.4919337482115051	100	0.0005	50	50	0.001	0.5	612
7	0.42207712003272385	0.4465736917738249	100	0.0005	50	50	0.001	0.5	612
8	0.3860217923060824	0.5085360741752055	100	0.0005	50	50	0.001	0.5	612
9	0.37455798192987605	0.4164586981783406	100	0.0005	50	50	0.001	0.5	612
10	0.3498560700691824	0.40065027126618596	100	0.0005	50	50	0.001	0.5	612
11	0.33454610525288975	0.4672393145228435	100	0.0005	50	50	0.001	0.5	612
12	0.3330706646211796	0.4016643228084134	100	0.0005	50	50	0.001	0.5	612
13	0.3273141896444186	0.38394729436925445	100	0.0005	50	50	0.001	0.5	612
14	0.31835719898246523	0.37343083011488615	100	0.0005	50	50	0.001	0.5	612
15	0.32323514996952324	0.3644051960389883	100	0.0005	50	50	0.001	0.5	612
16	0.31045288480814315	0.347599890332377	100	0.0005	50	50	0.001	0.5	612
17	0.3035710303994024	0.37288639080456065	100	0.0005	50	50	0.001	0.5	612
18	0.3074517306733889	0.3465064199317254	100	0.0005	50	50	0.001	0.5	612
19	0.3098038696761809	0.3480727122687017	100	0.0005	50	50	0.001	0.5	612
20	0.30583271569454945	0.3411322621838768	100	0.0005	50	50	0.001	0.5	612
21	0.3019600001744658	0.3507347983908243	100	0.0005	50	50	0.001	0.5	612
22	0.30517565957749926	0.3937475840858474	100	0.0005	50	50	0.001	0.5	612
23	0.3037002171157942	0.3240077166780687	100	0.0005	50	50	0.001	0.5	612
24	0.30258187463252384	0.34715939571023213	100	0.0005	50	50	0.001	0.5	612
25	0.3028012916903231	0.3858956266087738	100	0.0005	50	50	0.001	0.5	612
26	0.302066433029842	0.3250227796188048	100	0.0005	50	50	0.001	0.5	612
27	0.2949317045019864	0.3528069228674668	100	0.0005	50	50	0.001	0.5	612
28	0.30076415274277585	0.3570137692341157	100	0.0005	50	50	0.001	0.5	612
29	0.2955731306251577	0.34170633657028754	100	0.0005	50	50	0.001	0.5	612
30	0.29582962592748885	0.3955447001393393	100	0.0005	50	50	0.001	0.5	612
31	0.3007024074273878	0.36753233440975386	100	0.0005	50	50	0.001	0.5	612
32	0.30146317253466887	0.32811948138486813	100	0.0005	50	50	0.001	0.5	612
33	0.2955075620601272	0.35313884534981693	100	0.0005	50	50	0.001	0.5	612
34	0.2995871206683965	0.3492688242609597	100	0.0005	50	50	0.001	0.5	612
35	0.3035596589834166	0.3952295192682948	100	0.0005	50	50	0.001	0.5	612
36	0.3019885104111983	0.3488534182367088	100	0.0005	50	50	0.001	0.5	612
37	0.30211717618771217	0.35804434072219166	100	0.0005	50	50	0.001	0.5	612
38	0.29994761700662104	0.3401414414664755	100	0.0005	50	50	0.001	0.5	612
39	0.29202688326209253	0.3512760132950077	100	0.0005	50	50	0.001	0.5	612
40	0.29947094244726735	0.3692066099060197	100	0.0005	50	50	0.001	0.5	612
41	0.2947802283285364	0.3812070740226578	100	0.0005	50	50	0.001	0.5	612
42	0.2962536605233899	0.33406178348378973	100	0.0005	50	50	0.001	0.5	612
43	0.29702563755927375	0.308376182732573	100	0.0005	50	50	0.001	0.5	612
44	0.2982968349810375	0.3552493553316616	100	0.0005	50	50	0.001	0.5	612
45	0.2965696363213287	0.3981938794625649	100	0.0005	50	50	0.001	0.5	612
46	0.3006243749006096	0.35586266564365554	100	0.0005	50	50	0.001	0.5	612
47	0.29643827431797537	0.3656402037089003	100	0.0005	50	50	0.001	0.5	612
48	0.29854688343916413	0.3147054410345468	100	0.0005	50	50	0.001	0.5	612
49	0.2903292940455213	0.3576489120550867	100	0.0005	50	50	0.001	0.5	612
