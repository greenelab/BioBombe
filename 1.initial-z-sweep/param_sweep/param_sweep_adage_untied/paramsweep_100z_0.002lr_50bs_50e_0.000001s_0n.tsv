	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.025951286273358715	0.017763878615932756	100	0.002	50	50	1e-06	0.0	6596
1	0.016594195608130764	0.015711594800363306	100	0.002	50	50	1e-06	0.0	6596
2	0.015171599448535345	0.01488803189967262	100	0.002	50	50	1e-06	0.0	6596
3	0.014479407360528919	0.014173252306821583	100	0.002	50	50	1e-06	0.0	6596
4	0.01420037355531206	0.015003588916039376	100	0.002	50	50	1e-06	0.0	6596
5	0.013934433797423243	0.013412930986649904	100	0.002	50	50	1e-06	0.0	6596
6	0.013565806719962962	0.013958695175457411	100	0.002	50	50	1e-06	0.0	6596
7	0.013520474009204751	0.013452309938806535	100	0.002	50	50	1e-06	0.0	6596
8	0.013380254370978733	0.014508279412628701	100	0.002	50	50	1e-06	0.0	6596
9	0.013437203080563056	0.01374454697127495	100	0.002	50	50	1e-06	0.0	6596
10	0.013162744373698918	0.014355885441883345	100	0.002	50	50	1e-06	0.0	6596
11	0.013099855681610015	0.014892356295715555	100	0.002	50	50	1e-06	0.0	6596
12	0.012899451104107432	0.013403992569269916	100	0.002	50	50	1e-06	0.0	6596
13	0.01316580682006305	0.012591201498620141	100	0.002	50	50	1e-06	0.0	6596
14	0.012992754355579549	0.013197155151138684	100	0.002	50	50	1e-06	0.0	6596
15	0.012947805487842372	0.013513767164036718	100	0.002	50	50	1e-06	0.0	6596
16	0.01296409656214835	0.012497766187368227	100	0.002	50	50	1e-06	0.0	6596
17	0.012611999364428694	0.013050202967645334	100	0.002	50	50	1e-06	0.0	6596
18	0.01282235161789869	0.013727222702841687	100	0.002	50	50	1e-06	0.0	6596
19	0.01280688989925708	0.013769066402863133	100	0.002	50	50	1e-06	0.0	6596
20	0.013029302518668767	0.012409679792878391	100	0.002	50	50	1e-06	0.0	6596
21	0.012550876146697103	0.013340535723242774	100	0.002	50	50	1e-06	0.0	6596
22	0.012632691974593446	0.012838650615903661	100	0.002	50	50	1e-06	0.0	6596
23	0.01270697702723261	0.013810412498835623	100	0.002	50	50	1e-06	0.0	6596
24	0.013156719762239474	0.014622813010549112	100	0.002	50	50	1e-06	0.0	6596
25	0.012467608545507816	0.012598774885584247	100	0.002	50	50	1e-06	0.0	6596
26	0.012573880388043385	0.012799926851849368	100	0.002	50	50	1e-06	0.0	6596
27	0.01267077224751588	0.01762956286821493	100	0.002	50	50	1e-06	0.0	6596
28	0.0128846855036274	0.013161927652162416	100	0.002	50	50	1e-06	0.0	6596
29	0.012607202872504917	0.015746055974003574	100	0.002	50	50	1e-06	0.0	6596
30	0.012904572975383983	0.014079992890885068	100	0.002	50	50	1e-06	0.0	6596
31	0.012459429493851697	0.01233101584173981	100	0.002	50	50	1e-06	0.0	6596
32	0.013158438727061756	0.014099873420755676	100	0.002	50	50	1e-06	0.0	6596
33	0.012274389270968909	0.012538133267434332	100	0.002	50	50	1e-06	0.0	6596
34	0.012802697646708756	0.013368339325883648	100	0.002	50	50	1e-06	0.0	6596
35	0.012488852325986375	0.013190013760732875	100	0.002	50	50	1e-06	0.0	6596
36	0.012517493077688664	0.012777820551842735	100	0.002	50	50	1e-06	0.0	6596
37	0.012567100196647002	0.012678450352759822	100	0.002	50	50	1e-06	0.0	6596
38	0.012414134831177552	0.01335427907952615	100	0.002	50	50	1e-06	0.0	6596
39	0.012735045717630017	0.015238303083919316	100	0.002	50	50	1e-06	0.0	6596
40	0.012630515873652203	0.012732409996765863	100	0.002	50	50	1e-06	0.0	6596
41	0.012539195068873932	0.014106133372218386	100	0.002	50	50	1e-06	0.0	6596
42	0.012473350823357737	0.014832298905298427	100	0.002	50	50	1e-06	0.0	6596
43	0.012731110353688086	0.013593624764430136	100	0.002	50	50	1e-06	0.0	6596
44	0.012389134262048018	0.012124645739195451	100	0.002	50	50	1e-06	0.0	6596
45	0.01270309873813763	0.013126559372115204	100	0.002	50	50	1e-06	0.0	6596
46	0.012423906533185479	0.012239439037217123	100	0.002	50	50	1e-06	0.0	6596
47	0.012528169250241802	0.013537481945385555	100	0.002	50	50	1e-06	0.0	6596
48	0.012475773826689494	0.012501309022136446	100	0.002	50	50	1e-06	0.0	6596
49	0.012456401568952927	0.013815228383895544	100	0.002	50	50	1e-06	0.0	6596
