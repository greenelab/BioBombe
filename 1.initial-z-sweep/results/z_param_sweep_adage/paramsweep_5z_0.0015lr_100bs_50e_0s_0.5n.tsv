	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.04120387566573407	0.0337361434463903	5	0.0015	100	50	0.0	0.5	5480
1	0.030520091921844607	0.02940631638250775	5	0.0015	100	50	0.0	0.5	5480
2	0.029046772956344738	0.028955276496352246	5	0.0015	100	50	0.0	0.5	5480
3	0.02882633698039793	0.028805139593879762	5	0.0015	100	50	0.0	0.5	5480
4	0.02869602590466893	0.02867193769015386	5	0.0015	100	50	0.0	0.5	5480
5	0.028609050408917546	0.028513371168028556	5	0.0015	100	50	0.0	0.5	5480
6	0.028521075519449865	0.028394738311948785	5	0.0015	100	50	0.0	0.5	5480
7	0.028407167579195494	0.02831457436697319	5	0.0015	100	50	0.0	0.5	5480
8	0.028315014823357788	0.028165790834686726	5	0.0015	100	50	0.0	0.5	5480
9	0.028221091288987348	0.02810794228677198	5	0.0015	100	50	0.0	0.5	5480
10	0.028141584216877163	0.027959656084301822	5	0.0015	100	50	0.0	0.5	5480
11	0.028037584072829216	0.027857417222931554	5	0.0015	100	50	0.0	0.5	5480
12	0.027958455426773002	0.02782316043274922	5	0.0015	100	50	0.0	0.5	5480
13	0.027895889446118757	0.027775645772454616	5	0.0015	100	50	0.0	0.5	5480
14	0.027805903845954546	0.027690287102476816	5	0.0015	100	50	0.0	0.5	5480
15	0.02774476462298988	0.027559759284068702	5	0.0015	100	50	0.0	0.5	5480
16	0.027699143655576793	0.02754286364304974	5	0.0015	100	50	0.0	0.5	5480
17	0.02766890165217052	0.02748721556998006	5	0.0015	100	50	0.0	0.5	5480
18	0.027598974541420133	0.027417641068963657	5	0.0015	100	50	0.0	0.5	5480
19	0.027564198886830205	0.02740129540330707	5	0.0015	100	50	0.0	0.5	5480
20	0.027522504456324644	0.02738792894062645	5	0.0015	100	50	0.0	0.5	5480
21	0.027482084253588987	0.027333146481139027	5	0.0015	100	50	0.0	0.5	5480
22	0.02745336769046799	0.027407417276849255	5	0.0015	100	50	0.0	0.5	5480
23	0.027429162990747078	0.027246737713795547	5	0.0015	100	50	0.0	0.5	5480
24	0.027401970480772028	0.027277722303002332	5	0.0015	100	50	0.0	0.5	5480
25	0.02738039546754913	0.027193275948071114	5	0.0015	100	50	0.0	0.5	5480
26	0.027338224423489852	0.027170948627232138	5	0.0015	100	50	0.0	0.5	5480
27	0.027347325183618185	0.027171772090899785	5	0.0015	100	50	0.0	0.5	5480
28	0.02730905720333826	0.027143858415902687	5	0.0015	100	50	0.0	0.5	5480
29	0.02728470343778627	0.027110247297593558	5	0.0015	100	50	0.0	0.5	5480
30	0.027258808194758295	0.02713991038102379	5	0.0015	100	50	0.0	0.5	5480
31	0.02727259173759755	0.02711822215403585	5	0.0015	100	50	0.0	0.5	5480
32	0.027235216981645573	0.027047248738844582	5	0.0015	100	50	0.0	0.5	5480
33	0.02721773859928325	0.02705655508384422	5	0.0015	100	50	0.0	0.5	5480
34	0.0271966302480272	0.0270654735962075	5	0.0015	100	50	0.0	0.5	5480
35	0.0271810850398242	0.027045925747937957	5	0.0015	100	50	0.0	0.5	5480
36	0.02717555615238463	0.027032731873754334	5	0.0015	100	50	0.0	0.5	5480
37	0.027179502998317933	0.027000613856070586	5	0.0015	100	50	0.0	0.5	5480
38	0.027146966732356927	0.027197494963985328	5	0.0015	100	50	0.0	0.5	5480
39	0.027127486347406547	0.02701193509876272	5	0.0015	100	50	0.0	0.5	5480
40	0.027120854436850986	0.02701402813495345	5	0.0015	100	50	0.0	0.5	5480
41	0.027117237974657562	0.027005568143144164	5	0.0015	100	50	0.0	0.5	5480
42	0.0270815340486059	0.026975167854680158	5	0.0015	100	50	0.0	0.5	5480
43	0.027081724548545957	0.02694967847823185	5	0.0015	100	50	0.0	0.5	5480
44	0.0270692220086925	0.026928141317820002	5	0.0015	100	50	0.0	0.5	5480
45	0.027058876672925673	0.026936257956104343	5	0.0015	100	50	0.0	0.5	5480
46	0.02704108345109491	0.026953257428015624	5	0.0015	100	50	0.0	0.5	5480
47	0.027032767674893307	0.02692290399415885	5	0.0015	100	50	0.0	0.5	5480
48	0.02702528490534241	0.02691061499156414	5	0.0015	100	50	0.0	0.5	5480
49	0.027026387367468388	0.02689588037150312	5	0.0015	100	50	0.0	0.5	5480
