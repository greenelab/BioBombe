	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.03836524828617034	0.028871033679031505	5	0.002	100	50	0.0	0.5	3017
1	0.02697070761838318	0.025650953172383754	5	0.002	100	50	0.0	0.5	3017
2	0.025825548556913394	0.025329638596617014	5	0.002	100	50	0.0	0.5	3017
3	0.02560780359722787	0.02511615175077154	5	0.002	100	50	0.0	0.5	3017
4	0.025427794735176232	0.024943537144684884	5	0.002	100	50	0.0	0.5	3017
5	0.02525288664246991	0.02481199442328846	5	0.002	100	50	0.0	0.5	3017
6	0.0251247298801954	0.02458890917823146	5	0.002	100	50	0.0	0.5	3017
7	0.024975314512168147	0.02445297927576087	5	0.002	100	50	0.0	0.5	3017
8	0.02485370047273316	0.024362019325533515	5	0.002	100	50	0.0	0.5	3017
9	0.02473026115918633	0.02422138268615958	5	0.002	100	50	0.0	0.5	3017
10	0.02465505685673489	0.024145212961115072	5	0.002	100	50	0.0	0.5	3017
11	0.02453854308759167	0.02405779516363577	5	0.002	100	50	0.0	0.5	3017
12	0.02447834912884233	0.02400371773492538	5	0.002	100	50	0.0	0.5	3017
13	0.024390744566988656	0.02385557845704984	5	0.002	100	50	0.0	0.5	3017
14	0.024344891482685344	0.023847563559079032	5	0.002	100	50	0.0	0.5	3017
15	0.024292961617423767	0.02375702308864826	5	0.002	100	50	0.0	0.5	3017
16	0.024255319733066195	0.023839899956695665	5	0.002	100	50	0.0	0.5	3017
17	0.024242358188215407	0.023687758748321644	5	0.002	100	50	0.0	0.5	3017
18	0.02418178536629501	0.02368573310569527	5	0.002	100	50	0.0	0.5	3017
19	0.02419052624470063	0.02362529789569501	5	0.002	100	50	0.0	0.5	3017
20	0.024133806976568972	0.023626001872278993	5	0.002	100	50	0.0	0.5	3017
21	0.02410759345491685	0.023793899491571787	5	0.002	100	50	0.0	0.5	3017
22	0.02410886342193297	0.02359256903368474	5	0.002	100	50	0.0	0.5	3017
23	0.0240945294819963	0.023625632594864866	5	0.002	100	50	0.0	0.5	3017
24	0.02406890032098408	0.02355925670075257	5	0.002	100	50	0.0	0.5	3017
25	0.0240367465186221	0.023525819620455884	5	0.002	100	50	0.0	0.5	3017
26	0.024013077214512207	0.023538149412486338	5	0.002	100	50	0.0	0.5	3017
27	0.023999246778844217	0.023509894663300616	5	0.002	100	50	0.0	0.5	3017
28	0.0239728057263705	0.02351032470283499	5	0.002	100	50	0.0	0.5	3017
29	0.023977421332357682	0.023775313858006925	5	0.002	100	50	0.0	0.5	3017
30	0.023970862157570813	0.02349724223833695	5	0.002	100	50	0.0	0.5	3017
31	0.02394015715931125	0.023464324038269188	5	0.002	100	50	0.0	0.5	3017
32	0.02395441796099115	0.02348781502084454	5	0.002	100	50	0.0	0.5	3017
33	0.02393506689027425	0.023514394429343152	5	0.002	100	50	0.0	0.5	3017
34	0.023944391828937827	0.023450506142345943	5	0.002	100	50	0.0	0.5	3017
35	0.023933376676833276	0.023490017169577215	5	0.002	100	50	0.0	0.5	3017
36	0.023900223079454212	0.023415216994445136	5	0.002	100	50	0.0	0.5	3017
37	0.0238921870744141	0.023460946058281064	5	0.002	100	50	0.0	0.5	3017
38	0.023895559615181406	0.023448228921534683	5	0.002	100	50	0.0	0.5	3017
39	0.023887717671922704	0.023415429809666728	5	0.002	100	50	0.0	0.5	3017
40	0.0238808946634335	0.023425098668862256	5	0.002	100	50	0.0	0.5	3017
41	0.023883202307826208	0.023520326191990373	5	0.002	100	50	0.0	0.5	3017
42	0.02387669878305081	0.02344379451546113	5	0.002	100	50	0.0	0.5	3017
43	0.02387131049870514	0.023409418633517524	5	0.002	100	50	0.0	0.5	3017
44	0.023865583420716385	0.023422375698903323	5	0.002	100	50	0.0	0.5	3017
45	0.023841406707174526	0.023399521238802724	5	0.002	100	50	0.0	0.5	3017
46	0.023879827337685216	0.023520072480489145	5	0.002	100	50	0.0	0.5	3017
47	0.02386156705674229	0.02340585069933881	5	0.002	100	50	0.0	0.5	3017
48	0.023851507767507784	0.023384888911082	5	0.002	100	50	0.0	0.5	3017
49	0.023836557337143374	0.023550203604263967	5	0.002	100	50	0.0	0.5	3017
