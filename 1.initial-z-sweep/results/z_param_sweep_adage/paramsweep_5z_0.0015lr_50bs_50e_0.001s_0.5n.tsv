	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.18878356187199605	0.1240261931036444	5	0.0015	50	50	0.001	0.5	6032
1	0.13257476991216827	0.0829670611861559	5	0.0015	50	50	0.001	0.5	6032
2	0.10621360351264154	0.13768822735399863	5	0.0015	50	50	0.001	0.5	6032
3	0.09294019347895956	0.07565668505931676	5	0.0015	50	50	0.001	0.5	6032
4	0.08287221768748858	0.08455083514946597	5	0.0015	50	50	0.001	0.5	6032
5	0.08473742448888157	0.0854441474261293	5	0.0015	50	50	0.001	0.5	6032
6	0.08127419715815506	0.0827371282342743	5	0.0015	50	50	0.001	0.5	6032
7	0.0810895984614236	0.057990924093736976	5	0.0015	50	50	0.001	0.5	6032
8	0.07579971128685067	0.10265006965478565	5	0.0015	50	50	0.001	0.5	6032
9	0.07722350371579846	0.11167707834143484	5	0.0015	50	50	0.001	0.5	6032
10	0.08256599448584072	0.08687699579030105	5	0.0015	50	50	0.001	0.5	6032
11	0.07677859636782511	0.06920253877202139	5	0.0015	50	50	0.001	0.5	6032
12	0.07729548355648574	0.10103959246871576	5	0.0015	50	50	0.001	0.5	6032
13	0.07669996724370105	0.0972127217236714	5	0.0015	50	50	0.001	0.5	6032
14	0.07831022742584397	0.07753756615274494	5	0.0015	50	50	0.001	0.5	6032
15	0.07432237619166672	0.06799591953793174	5	0.0015	50	50	0.001	0.5	6032
16	0.07347614336812279	0.06042807536416938	5	0.0015	50	50	0.001	0.5	6032
17	0.07561230406514975	0.05907442432830028	5	0.0015	50	50	0.001	0.5	6032
18	0.07268701637678049	0.07183625436535757	5	0.0015	50	50	0.001	0.5	6032
19	0.08102628633951414	0.07350216512470355	5	0.0015	50	50	0.001	0.5	6032
20	0.07523322646095233	0.10890149969044881	5	0.0015	50	50	0.001	0.5	6032
21	0.07536619498733695	0.0631981581506492	5	0.0015	50	50	0.001	0.5	6032
22	0.07319873606143615	0.0820473851796318	5	0.0015	50	50	0.001	0.5	6032
23	0.07550284817132537	0.0919767245222916	5	0.0015	50	50	0.001	0.5	6032
24	0.07608363083077455	0.08159753440898873	5	0.0015	50	50	0.001	0.5	6032
25	0.07454592870400155	0.09580329648908192	5	0.0015	50	50	0.001	0.5	6032
26	0.07610057114693636	0.09197183326599019	5	0.0015	50	50	0.001	0.5	6032
27	0.07657900266289952	0.06990207305772811	5	0.0015	50	50	0.001	0.5	6032
28	0.07203117002292075	0.06101098821906241	5	0.0015	50	50	0.001	0.5	6032
29	0.0745928739768931	0.07761324415015446	5	0.0015	50	50	0.001	0.5	6032
30	0.07300151765194555	0.0808277164601915	5	0.0015	50	50	0.001	0.5	6032
31	0.07388894529086136	0.07472150620379366	5	0.0015	50	50	0.001	0.5	6032
32	0.07413450524236259	0.08274944445713073	5	0.0015	50	50	0.001	0.5	6032
33	0.07184171474877217	0.08105948608703413	5	0.0015	50	50	0.001	0.5	6032
34	0.07392670744811387	0.07946407091207304	5	0.0015	50	50	0.001	0.5	6032
35	0.07428255215252381	0.06778192921874628	5	0.0015	50	50	0.001	0.5	6032
36	0.07382187570177014	0.08749362846291543	5	0.0015	50	50	0.001	0.5	6032
37	0.07562138073911744	0.0885566165581716	5	0.0015	50	50	0.001	0.5	6032
38	0.072347912392441	0.08387123923000825	5	0.0015	50	50	0.001	0.5	6032
39	0.07420346571448555	0.06794157779524476	5	0.0015	50	50	0.001	0.5	6032
40	0.07490772290677102	0.07708871475711151	5	0.0015	50	50	0.001	0.5	6032
41	0.07425295378038066	0.06561199872688628	5	0.0015	50	50	0.001	0.5	6032
42	0.07369881796848568	0.07429698112475941	5	0.0015	50	50	0.001	0.5	6032
43	0.07212276275954452	0.07578535081665556	5	0.0015	50	50	0.001	0.5	6032
44	0.07169109782720301	0.08457585324463836	5	0.0015	50	50	0.001	0.5	6032
45	0.07916099880067586	0.09190116748641143	5	0.0015	50	50	0.001	0.5	6032
46	0.07418679477682368	0.0833128430875264	5	0.0015	50	50	0.001	0.5	6032
47	0.07587126228777506	0.10028589720593811	5	0.0015	50	50	0.001	0.5	6032
48	0.07956895420344998	0.07577148836326873	5	0.0015	50	50	0.001	0.5	6032
49	0.0749549015119322	0.08811597110094577	5	0.0015	50	50	0.001	0.5	6032
