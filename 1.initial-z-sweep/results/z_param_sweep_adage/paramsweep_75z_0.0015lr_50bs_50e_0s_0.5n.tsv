	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.025495708942520977	0.016701149439036733	75	0.0015	50	50	0.0	0.5	7668
1	0.015482936902483218	0.013999827172300897	75	0.0015	50	50	0.0	0.5	7668
2	0.013916575834178829	0.01306942473370475	75	0.0015	50	50	0.0	0.5	7668
3	0.013263082845298983	0.012522634202489776	75	0.0015	50	50	0.0	0.5	7668
4	0.012934584374297448	0.012432774311611803	75	0.0015	50	50	0.0	0.5	7668
5	0.01282652224373782	0.01229472406899439	75	0.0015	50	50	0.0	0.5	7668
6	0.012743506608492293	0.012263785176919364	75	0.0015	50	50	0.0	0.5	7668
7	0.01272591826575514	0.012157003229651351	75	0.0015	50	50	0.0	0.5	7668
8	0.0126805876875505	0.012197359187268504	75	0.0015	50	50	0.0	0.5	7668
9	0.01266169755581185	0.01229701445475363	75	0.0015	50	50	0.0	0.5	7668
10	0.01265505617372648	0.012209050339534452	75	0.0015	50	50	0.0	0.5	7668
11	0.012638115284207154	0.012110732168130163	75	0.0015	50	50	0.0	0.5	7668
12	0.012663322350198855	0.012185720151671374	75	0.0015	50	50	0.0	0.5	7668
13	0.01262073063249164	0.012132294994225124	75	0.0015	50	50	0.0	0.5	7668
14	0.012598590568261289	0.012158023261146381	75	0.0015	50	50	0.0	0.5	7668
15	0.012630169711647696	0.012057917591462172	75	0.0015	50	50	0.0	0.5	7668
16	0.01260807247104021	0.012208478384603164	75	0.0015	50	50	0.0	0.5	7668
17	0.012607644217991746	0.01215943512480072	75	0.0015	50	50	0.0	0.5	7668
18	0.012615469213217753	0.01221969645349291	75	0.0015	50	50	0.0	0.5	7668
19	0.012588034738652653	0.012181166550554122	75	0.0015	50	50	0.0	0.5	7668
20	0.01256618351254778	0.01210106636466989	75	0.0015	50	50	0.0	0.5	7668
21	0.012579760354312634	0.012084875781138928	75	0.0015	50	50	0.0	0.5	7668
22	0.012556229673605422	0.012173554373915747	75	0.0015	50	50	0.0	0.5	7668
23	0.012562678713289354	0.012088186575908278	75	0.0015	50	50	0.0	0.5	7668
24	0.01255580147645808	0.012269901857848492	75	0.0015	50	50	0.0	0.5	7668
25	0.012538044043613502	0.012080424816043154	75	0.0015	50	50	0.0	0.5	7668
26	0.01253004110631278	0.012083060708231725	75	0.0015	50	50	0.0	0.5	7668
27	0.012531283625878348	0.012086313636350245	75	0.0015	50	50	0.0	0.5	7668
28	0.012519818790115295	0.01207761529006819	75	0.0015	50	50	0.0	0.5	7668
29	0.012506243366655883	0.012113654369890803	75	0.0015	50	50	0.0	0.5	7668
30	0.012499347955628027	0.012054314480713403	75	0.0015	50	50	0.0	0.5	7668
31	0.012502999497308629	0.012120318490420655	75	0.0015	50	50	0.0	0.5	7668
32	0.0124988423220708	0.012020064270333966	75	0.0015	50	50	0.0	0.5	7668
33	0.012492480377521112	0.012011147796908254	75	0.0015	50	50	0.0	0.5	7668
34	0.01247727085545249	0.01228895627432298	75	0.0015	50	50	0.0	0.5	7668
35	0.012494106427061434	0.012017064052945569	75	0.0015	50	50	0.0	0.5	7668
36	0.012491927870428457	0.012068601159546275	75	0.0015	50	50	0.0	0.5	7668
37	0.012456765793747531	0.012040628414123851	75	0.0015	50	50	0.0	0.5	7668
38	0.01247464204338653	0.012003269751714703	75	0.0015	50	50	0.0	0.5	7668
39	0.012486394743408272	0.012013176475681835	75	0.0015	50	50	0.0	0.5	7668
40	0.012453709903447114	0.012037175586429312	75	0.0015	50	50	0.0	0.5	7668
41	0.012475311964402812	0.012023913138056348	75	0.0015	50	50	0.0	0.5	7668
42	0.012462450965188629	0.012074279086041063	75	0.0015	50	50	0.0	0.5	7668
43	0.012458134677055714	0.012049885881605271	75	0.0015	50	50	0.0	0.5	7668
44	0.012471933990145456	0.01208342758521979	75	0.0015	50	50	0.0	0.5	7668
45	0.012443128961570696	0.012133301812692423	75	0.0015	50	50	0.0	0.5	7668
46	0.012458594510477983	0.012041356070875324	75	0.0015	50	50	0.0	0.5	7668
47	0.012462126104479533	0.012203332389318464	75	0.0015	50	50	0.0	0.5	7668
48	0.012450304764213015	0.012036319651122758	75	0.0015	50	50	0.0	0.5	7668
49	0.01244078217254148	0.012043227642831566	75	0.0015	50	50	0.0	0.5	7668
