	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.026107282091545954	0.017428356680456357	50	0.0015	50	50	0.0	0.0	1271
1	0.015687462710604762	0.014459621699003371	50	0.0015	50	50	0.0	0.0	1271
2	0.014024410000559496	0.013593760331519248	50	0.0015	50	50	0.0	0.0	1271
3	0.013505970602396994	0.01337424018215495	50	0.0015	50	50	0.0	0.0	1271
4	0.013357744233608151	0.01326254495271761	50	0.0015	50	50	0.0	0.0	1271
5	0.013269674669506761	0.01323547161916132	50	0.0015	50	50	0.0	0.0	1271
6	0.013242172266669397	0.013210906014986066	50	0.0015	50	50	0.0	0.0	1271
7	0.013192522496045979	0.013149412158328192	50	0.0015	50	50	0.0	0.0	1271
8	0.01316855252374818	0.013110672198520905	50	0.0015	50	50	0.0	0.0	1271
9	0.013143985137651307	0.013150483895143063	50	0.0015	50	50	0.0	0.0	1271
10	0.013127075043119768	0.013065159698346377	50	0.0015	50	50	0.0	0.0	1271
11	0.013104925448094527	0.013070295409906663	50	0.0015	50	50	0.0	0.0	1271
12	0.013086782802997734	0.013066343282906777	50	0.0015	50	50	0.0	0.0	1271
13	0.013078996418132028	0.01304953246169063	50	0.0015	50	50	0.0	0.0	1271
14	0.0130612082842927	0.013081764982190575	50	0.0015	50	50	0.0	0.0	1271
15	0.013074681636658009	0.013020212124555904	50	0.0015	50	50	0.0	0.0	1271
16	0.013036423926057172	0.013057672808634164	50	0.0015	50	50	0.0	0.0	1271
17	0.013027738116687117	0.012976495709348591	50	0.0015	50	50	0.0	0.0	1271
18	0.013024475267375615	0.013030400916392671	50	0.0015	50	50	0.0	0.0	1271
19	0.013018804446296522	0.013028577461582296	50	0.0015	50	50	0.0	0.0	1271
20	0.013003152665128765	0.013012244652807143	50	0.0015	50	50	0.0	0.0	1271
21	0.013012186274851413	0.01306799767506852	50	0.0015	50	50	0.0	0.0	1271
22	0.01298714418939373	0.012989966521114395	50	0.0015	50	50	0.0	0.0	1271
23	0.012972848552707486	0.012964518126420833	50	0.0015	50	50	0.0	0.0	1271
24	0.012987487737600322	0.012941609674541148	50	0.0015	50	50	0.0	0.0	1271
25	0.012978654968238948	0.012927862714057214	50	0.0015	50	50	0.0	0.0	1271
26	0.01295565340945391	0.012985459605434884	50	0.0015	50	50	0.0	0.0	1271
27	0.012968803050793358	0.0130371785211603	50	0.0015	50	50	0.0	0.0	1271
28	0.01296898844483383	0.012941540081773388	50	0.0015	50	50	0.0	0.0	1271
29	0.012947341775574866	0.012928654283042962	50	0.0015	50	50	0.0	0.0	1271
30	0.012949477858239073	0.012939456207446227	50	0.0015	50	50	0.0	0.0	1271
31	0.012937307667569344	0.012910494954818521	50	0.0015	50	50	0.0	0.0	1271
32	0.012943480111572297	0.01295852490716808	50	0.0015	50	50	0.0	0.0	1271
33	0.012918635380125781	0.013053928412867436	50	0.0015	50	50	0.0	0.0	1271
34	0.012947621504291077	0.012934667040481736	50	0.0015	50	50	0.0	0.0	1271
35	0.012918064883854417	0.012993734801832735	50	0.0015	50	50	0.0	0.0	1271
36	0.012922911469218208	0.012932018953843851	50	0.0015	50	50	0.0	0.0	1271
37	0.01294432538975587	0.012976150227849502	50	0.0015	50	50	0.0	0.0	1271
38	0.01290813508021753	0.012939672546735457	50	0.0015	50	50	0.0	0.0	1271
39	0.012897159118064022	0.012911438546633174	50	0.0015	50	50	0.0	0.0	1271
40	0.012908066697909433	0.01293516996713715	50	0.0015	50	50	0.0	0.0	1271
41	0.012903969433634735	0.01310767910405851	50	0.0015	50	50	0.0	0.0	1271
42	0.012908992895291157	0.012893410233948131	50	0.0015	50	50	0.0	0.0	1271
43	0.012886460094616603	0.01294874946585007	50	0.0015	50	50	0.0	0.0	1271
44	0.012896461668664238	0.012943847890209628	50	0.0015	50	50	0.0	0.0	1271
45	0.012890670690252154	0.012950494762574167	50	0.0015	50	50	0.0	0.0	1271
46	0.012886432056988728	0.01309750408974136	50	0.0015	50	50	0.0	0.0	1271
47	0.01289804798002677	0.012914466019897913	50	0.0015	50	50	0.0	0.0	1271
48	0.01288933384550909	0.012915586732171233	50	0.0015	50	50	0.0	0.0	1271
49	0.012901858159195576	0.013055465064843116	50	0.0015	50	50	0.0	0.0	1271
