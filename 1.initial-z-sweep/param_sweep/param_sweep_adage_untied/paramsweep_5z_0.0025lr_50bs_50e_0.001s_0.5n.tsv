	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.19192806680005173	0.1437021350313555	5	0.0025	50	50	0.001	0.5	3517
1	0.1397379112655401	0.11206521442868742	5	0.0025	50	50	0.001	0.5	3517
2	0.12617251448334055	0.1493484753951516	5	0.0025	50	50	0.001	0.5	3517
3	0.11356455528063639	0.12182272295423037	5	0.0025	50	50	0.001	0.5	3517
4	0.11021531228968254	0.11272927387893542	5	0.0025	50	50	0.001	0.5	3517
5	0.10513426555490996	0.11449415135565953	5	0.0025	50	50	0.001	0.5	3517
6	0.1089212315292208	0.09150571708013633	5	0.0025	50	50	0.001	0.5	3517
7	0.10112639881403733	0.1561673046810905	5	0.0025	50	50	0.001	0.5	3517
8	0.10322085288046055	0.08577160172549078	5	0.0025	50	50	0.001	0.5	3517
9	0.10086257375430874	0.1649411617000062	5	0.0025	50	50	0.001	0.5	3517
10	0.10156320986469253	0.06736225626265797	5	0.0025	50	50	0.001	0.5	3517
11	0.09876628838337836	0.09657641005903539	5	0.0025	50	50	0.001	0.5	3517
12	0.10193503851859156	0.11728734873505897	5	0.0025	50	50	0.001	0.5	3517
13	0.09842651328876334	0.10248991290025455	5	0.0025	50	50	0.001	0.5	3517
14	0.09894477940433327	0.10953344789335422	5	0.0025	50	50	0.001	0.5	3517
15	0.1044802154871162	0.12390951946178312	5	0.0025	50	50	0.001	0.5	3517
16	0.09985189535919746	0.09572442847501707	5	0.0025	50	50	0.001	0.5	3517
17	0.10114434556607155	0.12722292731927412	5	0.0025	50	50	0.001	0.5	3517
18	0.10277078487117523	0.13368422186169523	5	0.0025	50	50	0.001	0.5	3517
19	0.1015339218302461	0.1450277560356698	5	0.0025	50	50	0.001	0.5	3517
20	0.09992347734062221	0.0873280873604076	5	0.0025	50	50	0.001	0.5	3517
21	0.09782132956983051	0.0776879639145749	5	0.0025	50	50	0.001	0.5	3517
22	0.10034979446934081	0.12135197128210196	5	0.0025	50	50	0.001	0.5	3517
23	0.10342325684774267	0.17312636076834187	5	0.0025	50	50	0.001	0.5	3517
24	0.09744461265831005	0.1167111323138496	5	0.0025	50	50	0.001	0.5	3517
25	0.10240915201625737	0.12433819861701524	5	0.0025	50	50	0.001	0.5	3517
26	0.10431184812637795	0.09442928225428834	5	0.0025	50	50	0.001	0.5	3517
27	0.10015280532410126	0.10779195840169549	5	0.0025	50	50	0.001	0.5	3517
28	0.10084694708164904	0.08600214816074299	5	0.0025	50	50	0.001	0.5	3517
29	0.09941592292825917	0.13711128220047594	5	0.0025	50	50	0.001	0.5	3517
30	0.10154906407585942	0.18541785692849533	5	0.0025	50	50	0.001	0.5	3517
31	0.10941756258619828	0.06847055856117099	5	0.0025	50	50	0.001	0.5	3517
32	0.0984280379377262	0.11390096154313242	5	0.0025	50	50	0.001	0.5	3517
33	0.10317557986359104	0.14781997787337003	5	0.0025	50	50	0.001	0.5	3517
34	0.10840192108691012	0.09607533929623792	5	0.0025	50	50	0.001	0.5	3517
35	0.0968106628385624	0.08788567278569788	5	0.0025	50	50	0.001	0.5	3517
36	0.09956223369285845	0.1744251968356893	5	0.0025	50	50	0.001	0.5	3517
37	0.09882639499806033	0.07971698483078248	5	0.0025	50	50	0.001	0.5	3517
38	0.09592491053428684	0.08628783555947116	5	0.0025	50	50	0.001	0.5	3517
39	0.10563392456572253	0.11091982003436718	5	0.0025	50	50	0.001	0.5	3517
40	0.09714841089084464	0.16463792227194368	5	0.0025	50	50	0.001	0.5	3517
41	0.10466484388366815	0.10618636648866916	5	0.0025	50	50	0.001	0.5	3517
42	0.1014245827181185	0.09721864368161097	5	0.0025	50	50	0.001	0.5	3517
43	0.09560120872291245	0.11857197061893361	5	0.0025	50	50	0.001	0.5	3517
44	0.09937406943937449	0.08178779301919172	5	0.0025	50	50	0.001	0.5	3517
45	0.09739320768498722	0.13148266906150213	5	0.0025	50	50	0.001	0.5	3517
46	0.09634788056862642	0.1387030430152357	5	0.0025	50	50	0.001	0.5	3517
47	0.10118864374970397	0.12477657614884824	5	0.0025	50	50	0.001	0.5	3517
48	0.10577423026921594	0.07330658905079898	5	0.0025	50	50	0.001	0.5	3517
49	0.09743503807849678	0.06855115009539442	5	0.0025	50	50	0.001	0.5	3517
