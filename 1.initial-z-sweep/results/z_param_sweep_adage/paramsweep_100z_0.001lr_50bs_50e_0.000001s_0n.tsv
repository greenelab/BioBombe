	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.02813253871990475	0.019072961151229494	100	0.001	50	50	1e-06	0.0	796
1	0.017090653714109567	0.0165073048647486	100	0.001	50	50	1e-06	0.0	796
2	0.015225798479122764	0.014941688732067781	100	0.001	50	50	1e-06	0.0	796
3	0.014367786199004836	0.01417863103124824	100	0.001	50	50	1e-06	0.0	796
4	0.01372496965090457	0.013457178250382553	100	0.001	50	50	1e-06	0.0	796
5	0.013309138549993785	0.013224599234774053	100	0.001	50	50	1e-06	0.0	796
6	0.012933233393595442	0.01337393156892084	100	0.001	50	50	1e-06	0.0	796
7	0.012653196279604997	0.01310925872508529	100	0.001	50	50	1e-06	0.0	796
8	0.012413509421008597	0.012241214620622576	100	0.001	50	50	1e-06	0.0	796
9	0.012329917963450537	0.01228977343776258	100	0.001	50	50	1e-06	0.0	796
10	0.012162490521988908	0.012619421673123058	100	0.001	50	50	1e-06	0.0	796
11	0.01190305770349407	0.01193796342370558	100	0.001	50	50	1e-06	0.0	796
12	0.01190970329468652	0.011950561447321912	100	0.001	50	50	1e-06	0.0	796
13	0.011788280238711554	0.011795946316754385	100	0.001	50	50	1e-06	0.0	796
14	0.011625634432040828	0.012001373922633965	100	0.001	50	50	1e-06	0.0	796
15	0.011616301019855606	0.012207534238981015	100	0.001	50	50	1e-06	0.0	796
16	0.011429355342744908	0.011601244257923294	100	0.001	50	50	1e-06	0.0	796
17	0.011556583832766164	0.011755124295404604	100	0.001	50	50	1e-06	0.0	796
18	0.01130600081022378	0.011789839625728974	100	0.001	50	50	1e-06	0.0	796
19	0.01125109144393978	0.011361221567394629	100	0.001	50	50	1e-06	0.0	796
20	0.01120705882630135	0.011740092784664941	100	0.001	50	50	1e-06	0.0	796
21	0.011175794549789772	0.011316338698263947	100	0.001	50	50	1e-06	0.0	796
22	0.011124539806030736	0.011110648925969979	100	0.001	50	50	1e-06	0.0	796
23	0.011066662325634309	0.01169503153787915	100	0.001	50	50	1e-06	0.0	796
24	0.01103019898918215	0.012019925565595951	100	0.001	50	50	1e-06	0.0	796
25	0.011055756263924838	0.011299417044319226	100	0.001	50	50	1e-06	0.0	796
26	0.011062565567437906	0.011099403428472935	100	0.001	50	50	1e-06	0.0	796
27	0.010915940717689025	0.011899073113176267	100	0.001	50	50	1e-06	0.0	796
28	0.011069693519017224	0.011220392096167996	100	0.001	50	50	1e-06	0.0	796
29	0.010810821227496614	0.011159575813188152	100	0.001	50	50	1e-06	0.0	796
30	0.010945957520707348	0.011516425600115131	100	0.001	50	50	1e-06	0.0	796
31	0.010851099766797991	0.011267010484026108	100	0.001	50	50	1e-06	0.0	796
32	0.01087038039982645	0.010626784276509262	100	0.001	50	50	1e-06	0.0	796
33	0.010717108844325593	0.011225220433883298	100	0.001	50	50	1e-06	0.0	796
34	0.010891255344409947	0.011183289390762494	100	0.001	50	50	1e-06	0.0	796
35	0.010793122062913723	0.011223624729289608	100	0.001	50	50	1e-06	0.0	796
36	0.010957320211468087	0.011064932296982117	100	0.001	50	50	1e-06	0.0	796
37	0.010745595478565831	0.011460047436034019	100	0.001	50	50	1e-06	0.0	796
38	0.01085893944442877	0.011429991063806112	100	0.001	50	50	1e-06	0.0	796
39	0.010639256234959989	0.010785382134166776	100	0.001	50	50	1e-06	0.0	796
40	0.010748067227032237	0.011880416586909649	100	0.001	50	50	1e-06	0.0	796
41	0.010880160170295508	0.01059566834945068	100	0.001	50	50	1e-06	0.0	796
42	0.010876810549086869	0.011435329365627715	100	0.001	50	50	1e-06	0.0	796
43	0.010874423584465954	0.010922407455400459	100	0.001	50	50	1e-06	0.0	796
44	0.010714569275777854	0.01136095726410244	100	0.001	50	50	1e-06	0.0	796
45	0.010653015796811854	0.012694542750317325	100	0.001	50	50	1e-06	0.0	796
46	0.010767523321411846	0.011179239026147937	100	0.001	50	50	1e-06	0.0	796
47	0.010729592035069522	0.010958306450418145	100	0.001	50	50	1e-06	0.0	796
48	0.010791797736657865	0.01113014736962478	100	0.001	50	50	1e-06	0.0	796
49	0.010576272248971681	0.010415063545919855	100	0.001	50	50	1e-06	0.0	796
