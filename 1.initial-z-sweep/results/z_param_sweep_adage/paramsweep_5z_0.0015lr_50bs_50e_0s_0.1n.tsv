	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.03969149023110816	0.034008116833509495	5	0.0015	50	50	0.0	0.1	1993
1	0.034003572904968964	0.033724148841450134	5	0.0015	50	50	0.0	0.1	1993
2	0.033722155482371605	0.0334463716194347	5	0.0015	50	50	0.0	0.1	1993
3	0.033420123988211405	0.03318181177369723	5	0.0015	50	50	0.0	0.1	1993
4	0.0331173771100876	0.03286494576081947	5	0.0015	50	50	0.0	0.1	1993
5	0.032799489627963585	0.032562845712438594	5	0.0015	50	50	0.0	0.1	1993
6	0.03248905628709057	0.03226709126158266	5	0.0015	50	50	0.0	0.1	1993
7	0.032202407005336504	0.032075122757378546	5	0.0015	50	50	0.0	0.1	1993
8	0.03192330863333516	0.03172550506419707	5	0.0015	50	50	0.0	0.1	1993
9	0.03165553528394023	0.031520656440015275	5	0.0015	50	50	0.0	0.1	1993
10	0.03141902230421162	0.03122687668861896	5	0.0015	50	50	0.0	0.1	1993
11	0.03118771244531849	0.03101719034048613	5	0.0015	50	50	0.0	0.1	1993
12	0.03098426112076225	0.03089019888388723	5	0.0015	50	50	0.0	0.1	1993
13	0.030806759001328413	0.030683924894544863	5	0.0015	50	50	0.0	0.1	1993
14	0.030644614483757857	0.030614107355731852	5	0.0015	50	50	0.0	0.1	1993
15	0.030524378979033852	0.03040084977906703	5	0.0015	50	50	0.0	0.1	1993
16	0.030393895593688602	0.0302625942270113	5	0.0015	50	50	0.0	0.1	1993
17	0.030286793219784197	0.030165467126362637	5	0.0015	50	50	0.0	0.1	1993
18	0.030193424579929524	0.03013711997858083	5	0.0015	50	50	0.0	0.1	1993
19	0.030120499109146662	0.02999583398478095	5	0.0015	50	50	0.0	0.1	1993
20	0.03004838351006337	0.02995343941903137	5	0.0015	50	50	0.0	0.1	1993
21	0.02999393705626508	0.029911180171068495	5	0.0015	50	50	0.0	0.1	1993
22	0.029943122002231343	0.029830460274595603	5	0.0015	50	50	0.0	0.1	1993
23	0.029892262729322328	0.029832431825721924	5	0.0015	50	50	0.0	0.1	1993
24	0.029864664596062112	0.02975151270100879	5	0.0015	50	50	0.0	0.1	1993
25	0.029828166463487044	0.029743666708982243	5	0.0015	50	50	0.0	0.1	1993
26	0.029799126151940858	0.0296759941039988	5	0.0015	50	50	0.0	0.1	1993
27	0.029769070044398927	0.02964120177306363	5	0.0015	50	50	0.0	0.1	1993
28	0.029750494062615596	0.029612853916550684	5	0.0015	50	50	0.0	0.1	1993
29	0.029734232168398107	0.02961857315601628	5	0.0015	50	50	0.0	0.1	1993
30	0.029713887843194252	0.029590571089068974	5	0.0015	50	50	0.0	0.1	1993
31	0.02969389461007804	0.029563559237048457	5	0.0015	50	50	0.0	0.1	1993
32	0.02968268477603592	0.029570361414130057	5	0.0015	50	50	0.0	0.1	1993
33	0.02967339467732569	0.029551311433457735	5	0.0015	50	50	0.0	0.1	1993
34	0.029652130250534772	0.029566812508848156	5	0.0015	50	50	0.0	0.1	1993
35	0.02964413779454588	0.02949524302940182	5	0.0015	50	50	0.0	0.1	1993
36	0.029640223082160133	0.02949351407801216	5	0.0015	50	50	0.0	0.1	1993
37	0.029618674410337106	0.0294775383059028	5	0.0015	50	50	0.0	0.1	1993
38	0.02961001371491681	0.029518363064236896	5	0.0015	50	50	0.0	0.1	1993
39	0.029606329934119633	0.02944708897965474	5	0.0015	50	50	0.0	0.1	1993
40	0.029599066972130987	0.029509816254644047	5	0.0015	50	50	0.0	0.1	1993
41	0.02960152945867206	0.029480311463998335	5	0.0015	50	50	0.0	0.1	1993
42	0.029586077257072674	0.02943109770449694	5	0.0015	50	50	0.0	0.1	1993
43	0.029581599550148156	0.029441877334141824	5	0.0015	50	50	0.0	0.1	1993
44	0.029581278632991082	0.029435443526301282	5	0.0015	50	50	0.0	0.1	1993
45	0.02956620071700297	0.029428534829422804	5	0.0015	50	50	0.0	0.1	1993
46	0.029558065981875947	0.029431871749303992	5	0.0015	50	50	0.0	0.1	1993
47	0.029560341496282946	0.029402198127504744	5	0.0015	50	50	0.0	0.1	1993
48	0.029557703822157808	0.029412904918108343	5	0.0015	50	50	0.0	0.1	1993
49	0.029549573940039632	0.02938514634126345	5	0.0015	50	50	0.0	0.1	1993
