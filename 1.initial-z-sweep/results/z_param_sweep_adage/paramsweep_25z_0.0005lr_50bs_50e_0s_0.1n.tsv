	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.03534828121938634	0.02526092833089669	25	0.0005	50	50	0.0	0.1	1458
1	0.022408534784863734	0.02013608297585985	25	0.0005	50	50	0.0	0.1	1458
2	0.018441696432919263	0.017501462801193985	25	0.0005	50	50	0.0	0.1	1458
3	0.016719320482463294	0.01639774147007992	25	0.0005	50	50	0.0	0.1	1458
4	0.0158966179074565	0.01578971726844803	25	0.0005	50	50	0.0	0.1	1458
5	0.01554175198389223	0.015614632723664234	25	0.0005	50	50	0.0	0.1	1458
6	0.015401897937911078	0.015487112120919314	25	0.0005	50	50	0.0	0.1	1458
7	0.015327890005829794	0.015438410214880342	25	0.0005	50	50	0.0	0.1	1458
8	0.01527683730959943	0.015366603237493089	25	0.0005	50	50	0.0	0.1	1458
9	0.015245081445256253	0.015338708001970675	25	0.0005	50	50	0.0	0.1	1458
10	0.015213568020415309	0.015327284406393367	25	0.0005	50	50	0.0	0.1	1458
11	0.015190582867471556	0.01528608661330168	25	0.0005	50	50	0.0	0.1	1458
12	0.015173207541349291	0.015289967559121306	25	0.0005	50	50	0.0	0.1	1458
13	0.015160824065640352	0.015251798587308104	25	0.0005	50	50	0.0	0.1	1458
14	0.015136896937643888	0.015276519635097475	25	0.0005	50	50	0.0	0.1	1458
15	0.015126273785968598	0.015212613011908007	25	0.0005	50	50	0.0	0.1	1458
16	0.015111224897206621	0.015215825515640739	25	0.0005	50	50	0.0	0.1	1458
17	0.015098745959301272	0.015193593788030157	25	0.0005	50	50	0.0	0.1	1458
18	0.015089701860153713	0.015186913169022955	25	0.0005	50	50	0.0	0.1	1458
19	0.015079442611618964	0.015170956110620932	25	0.0005	50	50	0.0	0.1	1458
20	0.01507034484749391	0.015176700312380696	25	0.0005	50	50	0.0	0.1	1458
21	0.015059860562811677	0.015192429932194048	25	0.0005	50	50	0.0	0.1	1458
22	0.015050616039642521	0.015145896383726803	25	0.0005	50	50	0.0	0.1	1458
23	0.015043557247446356	0.015123276230496271	25	0.0005	50	50	0.0	0.1	1458
24	0.015035452869893209	0.015159081126319291	25	0.0005	50	50	0.0	0.1	1458
25	0.015034446139872062	0.015123462065854902	25	0.0005	50	50	0.0	0.1	1458
26	0.015028639998503443	0.015156499806428275	25	0.0005	50	50	0.0	0.1	1458
27	0.015018953047542387	0.015120430194183358	25	0.0005	50	50	0.0	0.1	1458
28	0.015011490447610746	0.015122603536022553	25	0.0005	50	50	0.0	0.1	1458
29	0.015001873153404413	0.015115129054447432	25	0.0005	50	50	0.0	0.1	1458
30	0.014998282397217937	0.015096160180752752	25	0.0005	50	50	0.0	0.1	1458
31	0.014991920132498286	0.015125866201180916	25	0.0005	50	50	0.0	0.1	1458
32	0.014984743219847685	0.015100848492427264	25	0.0005	50	50	0.0	0.1	1458
33	0.014977731096282131	0.01506716112853749	25	0.0005	50	50	0.0	0.1	1458
34	0.014974908631353935	0.015074859656407773	25	0.0005	50	50	0.0	0.1	1458
35	0.014966958574436208	0.015104334749794257	25	0.0005	50	50	0.0	0.1	1458
36	0.014959768343269255	0.015071931042233002	25	0.0005	50	50	0.0	0.1	1458
37	0.014955554908549325	0.015061635767994715	25	0.0005	50	50	0.0	0.1	1458
38	0.014947331992223261	0.015041257304639821	25	0.0005	50	50	0.0	0.1	1458
39	0.01494753546993018	0.015042210767049178	25	0.0005	50	50	0.0	0.1	1458
40	0.014941051378363341	0.015037677959533653	25	0.0005	50	50	0.0	0.1	1458
41	0.014939004003654931	0.015038398098036733	25	0.0005	50	50	0.0	0.1	1458
42	0.0149313313238466	0.015039680497168811	25	0.0005	50	50	0.0	0.1	1458
43	0.014921963376839108	0.015015642644826814	25	0.0005	50	50	0.0	0.1	1458
44	0.01491744981216508	0.015030019781258435	25	0.0005	50	50	0.0	0.1	1458
45	0.014914937566700263	0.015019742513777079	25	0.0005	50	50	0.0	0.1	1458
46	0.014906684955797514	0.015044400762289363	25	0.0005	50	50	0.0	0.1	1458
47	0.014909834481762304	0.015000712772898989	25	0.0005	50	50	0.0	0.1	1458
48	0.014898683528816467	0.01501634234053227	25	0.0005	50	50	0.0	0.1	1458
49	0.014895305830107116	0.014995990999498856	25	0.0005	50	50	0.0	0.1	1458
