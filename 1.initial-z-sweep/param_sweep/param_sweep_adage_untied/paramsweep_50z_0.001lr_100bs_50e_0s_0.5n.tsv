	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.03447453084686833	0.023046303857438423	50	0.001	100	50	0.0	0.5	9951
1	0.019981663274596263	0.017523512336822585	50	0.001	100	50	0.0	0.5	9951
2	0.016804607286471485	0.01562561776424913	50	0.001	100	50	0.0	0.5	9951
3	0.01537465928804098	0.014545889578432015	50	0.001	100	50	0.0	0.5	9951
4	0.014497662760759785	0.013748476379702355	50	0.001	100	50	0.0	0.5	9951
5	0.013891612038686737	0.013311524236179447	50	0.001	100	50	0.0	0.5	9951
6	0.013512205157888457	0.012966055626024708	50	0.001	100	50	0.0	0.5	9951
7	0.01326356279174681	0.012726767351904289	50	0.001	100	50	0.0	0.5	9951
8	0.013050078612953205	0.012514968892384898	50	0.001	100	50	0.0	0.5	9951
9	0.012921646951126783	0.012492526153433733	50	0.001	100	50	0.0	0.5	9951
10	0.012853686231773508	0.012386856112721773	50	0.001	100	50	0.0	0.5	9951
11	0.012774641536240318	0.01230705431867284	50	0.001	100	50	0.0	0.5	9951
12	0.012750497462027489	0.012323152849069631	50	0.001	100	50	0.0	0.5	9951
13	0.012714359911868476	0.01225067688113018	50	0.001	100	50	0.0	0.5	9951
14	0.012705125138250634	0.01225914877178735	50	0.001	100	50	0.0	0.5	9951
15	0.012679343889086004	0.012211888602954366	50	0.001	100	50	0.0	0.5	9951
16	0.012668339674802619	0.012208584111974527	50	0.001	100	50	0.0	0.5	9951
17	0.012663412448855821	0.012195150987610192	50	0.001	100	50	0.0	0.5	9951
18	0.012645133409772216	0.012250201103507219	50	0.001	100	50	0.0	0.5	9951
19	0.012644995593720239	0.01221264597299165	50	0.001	100	50	0.0	0.5	9951
20	0.012628849866386144	0.012193594966617984	50	0.001	100	50	0.0	0.5	9951
21	0.012628955687703437	0.01219496714489011	50	0.001	100	50	0.0	0.5	9951
22	0.012625863400628181	0.012264474462468469	50	0.001	100	50	0.0	0.5	9951
23	0.012614571497308914	0.012177791473158344	50	0.001	100	50	0.0	0.5	9951
24	0.01261013689658001	0.01216377304906086	50	0.001	100	50	0.0	0.5	9951
25	0.012609991453042651	0.012250442510153777	50	0.001	100	50	0.0	0.5	9951
26	0.012617979336023	0.012140678122539935	50	0.001	100	50	0.0	0.5	9951
27	0.012609083551059054	0.012173112027745972	50	0.001	100	50	0.0	0.5	9951
28	0.012598827038711048	0.012151681823410221	50	0.001	100	50	0.0	0.5	9951
29	0.01259170851542474	0.012175948925344826	50	0.001	100	50	0.0	0.5	9951
30	0.012622589484576646	0.012205565825503598	50	0.001	100	50	0.0	0.5	9951
31	0.012592127056420165	0.012129937058197152	50	0.001	100	50	0.0	0.5	9951
32	0.012583384044174748	0.012135996486827817	50	0.001	100	50	0.0	0.5	9951
33	0.012581004121512076	0.012165592477637313	50	0.001	100	50	0.0	0.5	9951
34	0.012570908558188374	0.012146086830923594	50	0.001	100	50	0.0	0.5	9951
35	0.012568740020619371	0.012156510748766919	50	0.001	100	50	0.0	0.5	9951
36	0.012576747564667187	0.012148793395003216	50	0.001	100	50	0.0	0.5	9951
37	0.012571725649839315	0.012096839438746353	50	0.001	100	50	0.0	0.5	9951
38	0.01256402333739076	0.012114893860516653	50	0.001	100	50	0.0	0.5	9951
39	0.012558284892675778	0.01219168141925882	50	0.001	100	50	0.0	0.5	9951
40	0.012570942457617723	0.012139982552789365	50	0.001	100	50	0.0	0.5	9951
41	0.012562537640230279	0.012123956134895407	50	0.001	100	50	0.0	0.5	9951
42	0.01256359887641712	0.012175722378902637	50	0.001	100	50	0.0	0.5	9951
43	0.012570357489189166	0.012203266092684711	50	0.001	100	50	0.0	0.5	9951
44	0.012561627654272666	0.012115868511850132	50	0.001	100	50	0.0	0.5	9951
45	0.012565739093884441	0.012209420101307546	50	0.001	100	50	0.0	0.5	9951
46	0.012547215415564745	0.012158252487589479	50	0.001	100	50	0.0	0.5	9951
47	0.012571077124309358	0.012106692226137075	50	0.001	100	50	0.0	0.5	9951
48	0.01254847599732677	0.012117144681983423	50	0.001	100	50	0.0	0.5	9951
49	0.012552173465983458	0.01221170964834225	50	0.001	100	50	0.0	0.5	9951
