	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.03618411116739724	0.029077512641253935	5	0.001	50	50	0.0	0.0	5763
1	0.025672478270678874	0.023892195296988432	5	0.001	50	50	0.0	0.0	5763
2	0.02334864433187171	0.023389219147924255	5	0.001	50	50	0.0	0.0	5763
3	0.023085477261188737	0.023179507000553448	5	0.001	50	50	0.0	0.0	5763
4	0.022958267377435206	0.023132879436585915	5	0.001	50	50	0.0	0.0	5763
5	0.022891222515042435	0.02303700167222757	5	0.001	50	50	0.0	0.0	5763
6	0.022804502037831794	0.02298946882710288	5	0.001	50	50	0.0	0.0	5763
7	0.02273895448806099	0.022892275020252224	5	0.001	50	50	0.0	0.0	5763
8	0.022669540491427255	0.022875705085709037	5	0.001	50	50	0.0	0.0	5763
9	0.022607251986327744	0.022778287544191225	5	0.001	50	50	0.0	0.0	5763
10	0.022543094488481945	0.022726467869335333	5	0.001	50	50	0.0	0.0	5763
11	0.022480457429700396	0.022699003764935707	5	0.001	50	50	0.0	0.0	5763
12	0.02242182570367238	0.02268652318768474	5	0.001	50	50	0.0	0.0	5763
13	0.02237570404149192	0.022585636620938664	5	0.001	50	50	0.0	0.0	5763
14	0.022315304819563744	0.022514958871282766	5	0.001	50	50	0.0	0.0	5763
15	0.022287844015273697	0.022481799186216258	5	0.001	50	50	0.0	0.0	5763
16	0.022247650779401423	0.022444823874342282	5	0.001	50	50	0.0	0.0	5763
17	0.02221178387476846	0.02240915168041139	5	0.001	50	50	0.0	0.0	5763
18	0.022183040119165394	0.022422180747894666	5	0.001	50	50	0.0	0.0	5763
19	0.022143608036720257	0.02238574937826475	5	0.001	50	50	0.0	0.0	5763
20	0.022124720836080223	0.022360116072412204	5	0.001	50	50	0.0	0.0	5763
21	0.022099544368482455	0.022318635029045162	5	0.001	50	50	0.0	0.0	5763
22	0.022085374022929875	0.022362226096781443	5	0.001	50	50	0.0	0.0	5763
23	0.022061342281476097	0.02231373133611497	5	0.001	50	50	0.0	0.0	5763
24	0.022049874836268493	0.022284989175787393	5	0.001	50	50	0.0	0.0	5763
25	0.022030428071736555	0.0222861048503713	5	0.001	50	50	0.0	0.0	5763
26	0.0220200400162339	0.022257580120921362	5	0.001	50	50	0.0	0.0	5763
27	0.022009148419261118	0.02226025427390695	5	0.001	50	50	0.0	0.0	5763
28	0.022003429773338135	0.022249955651893444	5	0.001	50	50	0.0	0.0	5763
29	0.021991416866162194	0.022214308121093828	5	0.001	50	50	0.0	0.0	5763
30	0.02197709971674568	0.022215522765173055	5	0.001	50	50	0.0	0.0	5763
31	0.021968957733469373	0.02223564124172892	5	0.001	50	50	0.0	0.0	5763
32	0.021968006261360324	0.02226877331121132	5	0.001	50	50	0.0	0.0	5763
33	0.021954303202877754	0.022224240229388497	5	0.001	50	50	0.0	0.0	5763
34	0.021951423352628764	0.022209620267067312	5	0.001	50	50	0.0	0.0	5763
35	0.021944308003635688	0.02218361181094815	5	0.001	50	50	0.0	0.0	5763
36	0.02193350989589602	0.022183431939259313	5	0.001	50	50	0.0	0.0	5763
37	0.02193346345522326	0.022233307849523213	5	0.001	50	50	0.0	0.0	5763
38	0.02192731285035376	0.02221285181750417	5	0.001	50	50	0.0	0.0	5763
39	0.02193203836407967	0.022157475377217534	5	0.001	50	50	0.0	0.0	5763
40	0.021922309157807327	0.022197839773721268	5	0.001	50	50	0.0	0.0	5763
41	0.02191450985295574	0.02221604846204216	5	0.001	50	50	0.0	0.0	5763
42	0.021914703789874826	0.02217349098072909	5	0.001	50	50	0.0	0.0	5763
43	0.021908561163925724	0.022199931766403336	5	0.001	50	50	0.0	0.0	5763
44	0.021906022342177388	0.022144418473339447	5	0.001	50	50	0.0	0.0	5763
45	0.021899266254552983	0.022162092454289843	5	0.001	50	50	0.0	0.0	5763
46	0.021893274144895915	0.022158732335038667	5	0.001	50	50	0.0	0.0	5763
47	0.0218923664104178	0.022141931681799388	5	0.001	50	50	0.0	0.0	5763
48	0.021897239630142916	0.022157732464985685	5	0.001	50	50	0.0	0.0	5763
49	0.021889154811847937	0.022182539386770922	5	0.001	50	50	0.0	0.0	5763
