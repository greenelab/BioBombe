	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.04891658354972876	0.035429197717921	5	0.0005	100	50	0.0	0.1	6193
1	0.03452784848546584	0.03385901435440403	5	0.0005	100	50	0.0	0.1	6193
2	0.03163717373173447	0.029715475724230077	5	0.0005	100	50	0.0	0.1	6193
3	0.02870998501343896	0.0274747426249443	5	0.0005	100	50	0.0	0.1	6193
4	0.026848748134357902	0.026243562142348655	5	0.0005	100	50	0.0	0.1	6193
5	0.026058582820154195	0.02576724031359584	5	0.0005	100	50	0.0	0.1	6193
6	0.025730501925878477	0.025554092576011416	5	0.0005	100	50	0.0	0.1	6193
7	0.02555175140459701	0.025415228800865934	5	0.0005	100	50	0.0	0.1	6193
8	0.025444170864967575	0.02530821974444458	5	0.0005	100	50	0.0	0.1	6193
9	0.025348642500034112	0.025214886185971317	5	0.0005	100	50	0.0	0.1	6193
10	0.025275234462871228	0.025144577514287617	5	0.0005	100	50	0.0	0.1	6193
11	0.02519765684576435	0.025066011248736947	5	0.0005	100	50	0.0	0.1	6193
12	0.02513734304925834	0.025004443760612272	5	0.0005	100	50	0.0	0.1	6193
13	0.0250660952122843	0.024940838228847056	5	0.0005	100	50	0.0	0.1	6193
14	0.02500198548348021	0.024869045630866664	5	0.0005	100	50	0.0	0.1	6193
15	0.02494018678083932	0.024819777348928197	5	0.0005	100	50	0.0	0.1	6193
16	0.02489314346846233	0.02475753036215474	5	0.0005	100	50	0.0	0.1	6193
17	0.024830610527844264	0.024704088505008482	5	0.0005	100	50	0.0	0.1	6193
18	0.024763245778260216	0.024653080861524002	5	0.0005	100	50	0.0	0.1	6193
19	0.024708407954676465	0.024574515486339082	5	0.0005	100	50	0.0	0.1	6193
20	0.02465215874729983	0.024552596579831144	5	0.0005	100	50	0.0	0.1	6193
21	0.024608804281845705	0.024499320476734386	5	0.0005	100	50	0.0	0.1	6193
22	0.02454408519005631	0.02441789973064203	5	0.0005	100	50	0.0	0.1	6193
23	0.02449311302557491	0.02438927285843324	5	0.0005	100	50	0.0	0.1	6193
24	0.02444100974751566	0.024319560055124145	5	0.0005	100	50	0.0	0.1	6193
25	0.024394789835503236	0.024278239658668665	5	0.0005	100	50	0.0	0.1	6193
26	0.024347463504159082	0.02422129192939794	5	0.0005	100	50	0.0	0.1	6193
27	0.024304191022992614	0.02419888025886926	5	0.0005	100	50	0.0	0.1	6193
28	0.0242598406387942	0.024146187227810548	5	0.0005	100	50	0.0	0.1	6193
29	0.024218917375634873	0.024088415062592773	5	0.0005	100	50	0.0	0.1	6193
30	0.024175542853452074	0.02406728485275067	5	0.0005	100	50	0.0	0.1	6193
31	0.024139485128115458	0.02404302025986675	5	0.0005	100	50	0.0	0.1	6193
32	0.024112216570452892	0.024005143783886847	5	0.0005	100	50	0.0	0.1	6193
33	0.024075586606807666	0.023961721939065032	5	0.0005	100	50	0.0	0.1	6193
34	0.02403471694243495	0.023921103592442053	5	0.0005	100	50	0.0	0.1	6193
35	0.024012033538994774	0.023912375995864377	5	0.0005	100	50	0.0	0.1	6193
36	0.023982600514057414	0.02388598240669781	5	0.0005	100	50	0.0	0.1	6193
37	0.02396383680107204	0.02389047727216726	5	0.0005	100	50	0.0	0.1	6193
38	0.023935553370128527	0.02382831067473665	5	0.0005	100	50	0.0	0.1	6193
39	0.023905883667758848	0.02380625409987643	5	0.0005	100	50	0.0	0.1	6193
40	0.023886626330459078	0.02377910044464509	5	0.0005	100	50	0.0	0.1	6193
41	0.023860017787342584	0.023745847620198192	5	0.0005	100	50	0.0	0.1	6193
42	0.023834042108438543	0.023728766013827195	5	0.0005	100	50	0.0	0.1	6193
43	0.023824300190350155	0.023713447516837495	5	0.0005	100	50	0.0	0.1	6193
44	0.02379967156739471	0.02368826899200279	5	0.0005	100	50	0.0	0.1	6193
45	0.02378688638157803	0.02368419531583216	5	0.0005	100	50	0.0	0.1	6193
46	0.02376281208759709	0.023661083247989816	5	0.0005	100	50	0.0	0.1	6193
47	0.02375259928517681	0.023650601232000565	5	0.0005	100	50	0.0	0.1	6193
48	0.023740133277151344	0.023640381791993948	5	0.0005	100	50	0.0	0.1	6193
49	0.02373014185227383	0.023670547853720803	5	0.0005	100	50	0.0	0.1	6193
