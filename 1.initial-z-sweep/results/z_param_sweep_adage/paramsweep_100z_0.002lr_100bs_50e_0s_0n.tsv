	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.02720363884982211	0.01734628929377286	100	0.002	100	50	0.0	0.0	6338
1	0.015399285320944124	0.014046736097187658	100	0.002	100	50	0.0	0.0	6338
2	0.013469489768201292	0.012815018590489833	100	0.002	100	50	0.0	0.0	6338
3	0.012491188652898126	0.012235618438607307	100	0.002	100	50	0.0	0.0	6338
4	0.011916048181874776	0.011815613358286896	100	0.002	100	50	0.0	0.0	6338
5	0.011532891110538752	0.011457624937804776	100	0.002	100	50	0.0	0.0	6338
6	0.011297153194612934	0.011297291937154178	100	0.002	100	50	0.0	0.0	6338
7	0.011151261445624434	0.011127966085723093	100	0.002	100	50	0.0	0.0	6338
8	0.011053691003331118	0.011097657223575771	100	0.002	100	50	0.0	0.0	6338
9	0.011036551598937164	0.011083885364904003	100	0.002	100	50	0.0	0.0	6338
10	0.011002614336007367	0.01107734244630225	100	0.002	100	50	0.0	0.0	6338
11	0.010967789560656934	0.010992586151491958	100	0.002	100	50	0.0	0.0	6338
12	0.010957580873152819	0.011070044755750474	100	0.002	100	50	0.0	0.0	6338
13	0.0109257574020925	0.011055936465257099	100	0.002	100	50	0.0	0.0	6338
14	0.010915860273897756	0.010957730565412436	100	0.002	100	50	0.0	0.0	6338
15	0.010908725794254752	0.011004690860841515	100	0.002	100	50	0.0	0.0	6338
16	0.010875393436368981	0.011051199151413163	100	0.002	100	50	0.0	0.0	6338
17	0.010910512168804561	0.0110914007338551	100	0.002	100	50	0.0	0.0	6338
18	0.010889823063392765	0.011188865144225995	100	0.002	100	50	0.0	0.0	6338
19	0.010850951835314444	0.01100279075978591	100	0.002	100	50	0.0	0.0	6338
20	0.010872001170520004	0.01109644095903088	100	0.002	100	50	0.0	0.0	6338
21	0.010841682697644836	0.011018549143755186	100	0.002	100	50	0.0	0.0	6338
22	0.010818517937366596	0.01096704408676002	100	0.002	100	50	0.0	0.0	6338
23	0.010836643864960983	0.010915138030399785	100	0.002	100	50	0.0	0.0	6338
24	0.010860896566034813	0.010968075379601058	100	0.002	100	50	0.0	0.0	6338
25	0.010812797986622396	0.01105122149959349	100	0.002	100	50	0.0	0.0	6338
26	0.010837527441250097	0.010917943320014509	100	0.002	100	50	0.0	0.0	6338
27	0.010798971796966119	0.01093599116910484	100	0.002	100	50	0.0	0.0	6338
28	0.010812326304141215	0.011057414465279356	100	0.002	100	50	0.0	0.0	6338
29	0.010848263574236386	0.010971977596258457	100	0.002	100	50	0.0	0.0	6338
30	0.010795789929184995	0.010868976742071927	100	0.002	100	50	0.0	0.0	6338
31	0.010789687545612117	0.010923818572928299	100	0.002	100	50	0.0	0.0	6338
32	0.010815243858261879	0.010867492879881572	100	0.002	100	50	0.0	0.0	6338
33	0.01078926177803634	0.010935482597530572	100	0.002	100	50	0.0	0.0	6338
34	0.010794295556863068	0.010924475669974806	100	0.002	100	50	0.0	0.0	6338
35	0.010799391245835331	0.010964665223575459	100	0.002	100	50	0.0	0.0	6338
36	0.010787030188256948	0.011047411184708087	100	0.002	100	50	0.0	0.0	6338
37	0.010816561683761501	0.010863839349501105	100	0.002	100	50	0.0	0.0	6338
38	0.010758929728411323	0.010906073195329132	100	0.002	100	50	0.0	0.0	6338
39	0.010779230387221072	0.01091062487859856	100	0.002	100	50	0.0	0.0	6338
40	0.010754641823800657	0.01093224915595686	100	0.002	100	50	0.0	0.0	6338
41	0.010790429434028763	0.010870384558123567	100	0.002	100	50	0.0	0.0	6338
42	0.010762114419149602	0.01099631273638222	100	0.002	100	50	0.0	0.0	6338
43	0.010790421899052313	0.010867025323895947	100	0.002	100	50	0.0	0.0	6338
44	0.010762075741312195	0.010885365116792814	100	0.002	100	50	0.0	0.0	6338
45	0.010799573605681668	0.01085592527654784	100	0.002	100	50	0.0	0.0	6338
46	0.010737029860415729	0.010935927978066824	100	0.002	100	50	0.0	0.0	6338
47	0.010780200336085335	0.01088812304785329	100	0.002	100	50	0.0	0.0	6338
48	0.010770539425548554	0.010982199388611386	100	0.002	100	50	0.0	0.0	6338
49	0.010775539596819046	0.010880512461408146	100	0.002	100	50	0.0	0.0	6338
