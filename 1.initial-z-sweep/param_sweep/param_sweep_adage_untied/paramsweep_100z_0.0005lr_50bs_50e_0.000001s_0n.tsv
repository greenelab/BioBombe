	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.0331792525140139	0.021549020738948144	100	0.0005	50	50	1e-06	0.0	3522
1	0.01917215259881265	0.01805323190331801	100	0.0005	50	50	1e-06	0.0	3522
2	0.016799092712885044	0.01610802265372035	100	0.0005	50	50	1e-06	0.0	3522
3	0.01551524737411923	0.015273323522998202	100	0.0005	50	50	1e-06	0.0	3522
4	0.014703777981519344	0.01439637492587131	100	0.0005	50	50	1e-06	0.0	3522
5	0.014122291194514655	0.01435700190889277	100	0.0005	50	50	1e-06	0.0	3522
6	0.013703152686052763	0.01345616307138086	100	0.0005	50	50	1e-06	0.0	3522
7	0.013298688258239235	0.013279462133464804	100	0.0005	50	50	1e-06	0.0	3522
8	0.013016913138812019	0.012911848196791873	100	0.0005	50	50	1e-06	0.0	3522
9	0.012757870886115893	0.012705683398343636	100	0.0005	50	50	1e-06	0.0	3522
10	0.012556010213718459	0.012678743033789198	100	0.0005	50	50	1e-06	0.0	3522
11	0.012381680580373495	0.012424886586361816	100	0.0005	50	50	1e-06	0.0	3522
12	0.01217134187812682	0.012248664606455179	100	0.0005	50	50	1e-06	0.0	3522
13	0.012047631939633466	0.012124514452984866	100	0.0005	50	50	1e-06	0.0	3522
14	0.011852269160839186	0.011864805579840794	100	0.0005	50	50	1e-06	0.0	3522
15	0.011780224159925077	0.012293929193190247	100	0.0005	50	50	1e-06	0.0	3522
16	0.011640953497847778	0.011830484231018656	100	0.0005	50	50	1e-06	0.0	3522
17	0.011551564702704591	0.01176281082470604	100	0.0005	50	50	1e-06	0.0	3522
18	0.011419092856496367	0.011432482212796151	100	0.0005	50	50	1e-06	0.0	3522
19	0.011410216576472506	0.01152227436820932	100	0.0005	50	50	1e-06	0.0	3522
20	0.011222098126586396	0.01129894281415194	100	0.0005	50	50	1e-06	0.0	3522
21	0.011134123940483444	0.011244570574657296	100	0.0005	50	50	1e-06	0.0	3522
22	0.011145472143256587	0.011318363685581128	100	0.0005	50	50	1e-06	0.0	3522
23	0.011082324395279765	0.01116053199477451	100	0.0005	50	50	1e-06	0.0	3522
24	0.010894460213375272	0.011188459279902465	100	0.0005	50	50	1e-06	0.0	3522
25	0.010933133845632974	0.011266733854510474	100	0.0005	50	50	1e-06	0.0	3522
26	0.010842844960020045	0.011216285647414838	100	0.0005	50	50	1e-06	0.0	3522
27	0.010796668532055236	0.010835138277772166	100	0.0005	50	50	1e-06	0.0	3522
28	0.010711280503384962	0.011063868277857568	100	0.0005	50	50	1e-06	0.0	3522
29	0.010620487361262249	0.010972440068255648	100	0.0005	50	50	1e-06	0.0	3522
30	0.010611499582543853	0.010892788918749438	100	0.0005	50	50	1e-06	0.0	3522
31	0.010601713247502234	0.01090538448317557	100	0.0005	50	50	1e-06	0.0	3522
32	0.010523720570308337	0.010644201588163413	100	0.0005	50	50	1e-06	0.0	3522
33	0.010493537657355466	0.010627382002186821	100	0.0005	50	50	1e-06	0.0	3522
34	0.01038337377033883	0.011039942625845938	100	0.0005	50	50	1e-06	0.0	3522
35	0.010372269362002267	0.010703707989981937	100	0.0005	50	50	1e-06	0.0	3522
36	0.010376539361236434	0.010620493285115773	100	0.0005	50	50	1e-06	0.0	3522
37	0.010269574589376702	0.010574647672403155	100	0.0005	50	50	1e-06	0.0	3522
38	0.010254848606961258	0.01045071674122637	100	0.0005	50	50	1e-06	0.0	3522
39	0.010236468915583686	0.010497308898909484	100	0.0005	50	50	1e-06	0.0	3522
40	0.010204472967104812	0.010554719946024865	100	0.0005	50	50	1e-06	0.0	3522
41	0.010181959155101231	0.010500587405455272	100	0.0005	50	50	1e-06	0.0	3522
42	0.010149090554698563	0.010373577758684098	100	0.0005	50	50	1e-06	0.0	3522
43	0.010139796392520986	0.010334076847788481	100	0.0005	50	50	1e-06	0.0	3522
44	0.01004846763687182	0.0102829015733635	100	0.0005	50	50	1e-06	0.0	3522
45	0.010072926952299112	0.010351218147840829	100	0.0005	50	50	1e-06	0.0	3522
46	0.010091358034517411	0.010756580499187825	100	0.0005	50	50	1e-06	0.0	3522
47	0.009974118634190897	0.0102663516951992	100	0.0005	50	50	1e-06	0.0	3522
48	0.010039023233603927	0.010269267552213504	100	0.0005	50	50	1e-06	0.0	3522
49	0.010032285426833463	0.010242598255950223	100	0.0005	50	50	1e-06	0.0	3522
