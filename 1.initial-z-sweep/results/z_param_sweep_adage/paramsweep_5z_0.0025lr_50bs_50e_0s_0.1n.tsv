	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.03384057295361361	0.028518454123637415	5	0.0025	50	50	0.0	0.1	9473
1	0.028664745632026763	0.0279258490249828	5	0.0025	50	50	0.0	0.1	9473
2	0.028306328445874034	0.027626783036792484	5	0.0025	50	50	0.0	0.1	9473
3	0.027988096930044663	0.02727529123411238	5	0.0025	50	50	0.0	0.1	9473
4	0.027698519235302914	0.027075592894997468	5	0.0025	50	50	0.0	0.1	9473
5	0.027525567940470834	0.026912472148498887	5	0.0025	50	50	0.0	0.1	9473
6	0.027385272235857634	0.02679098345852149	5	0.0025	50	50	0.0	0.1	9473
7	0.027264541837814307	0.026656614737602995	5	0.0025	50	50	0.0	0.1	9473
8	0.027216421054575453	0.026766977388675308	5	0.0025	50	50	0.0	0.1	9473
9	0.027168787199587128	0.02655568579657014	5	0.0025	50	50	0.0	0.1	9473
10	0.027099943313853313	0.026560705422243928	5	0.0025	50	50	0.0	0.1	9473
11	0.02708717738869377	0.02646648858533193	5	0.0025	50	50	0.0	0.1	9473
12	0.027015549164080575	0.026437333897183547	5	0.0025	50	50	0.0	0.1	9473
13	0.026997308210084607	0.026370545176087556	5	0.0025	50	50	0.0	0.1	9473
14	0.02696951284045293	0.02634846317238151	5	0.0025	50	50	0.0	0.1	9473
15	0.026933188883701102	0.026365418799121795	5	0.0025	50	50	0.0	0.1	9473
16	0.026929341977297735	0.02632670974925189	5	0.0025	50	50	0.0	0.1	9473
17	0.026909614318239124	0.026381185630881307	5	0.0025	50	50	0.0	0.1	9473
18	0.026892876156164407	0.026318282440988557	5	0.0025	50	50	0.0	0.1	9473
19	0.026876011587901802	0.02629740308279289	5	0.0025	50	50	0.0	0.1	9473
20	0.026889214865625077	0.026328801239767677	5	0.0025	50	50	0.0	0.1	9473
21	0.02685244050532703	0.026245268806102853	5	0.0025	50	50	0.0	0.1	9473
22	0.026854677402250043	0.02625771770057897	5	0.0025	50	50	0.0	0.1	9473
23	0.026831795760571583	0.026231890811405038	5	0.0025	50	50	0.0	0.1	9473
24	0.026831997756156738	0.02624777249322339	5	0.0025	50	50	0.0	0.1	9473
25	0.026834611521421768	0.026279624693993173	5	0.0025	50	50	0.0	0.1	9473
26	0.02681714507835167	0.02630677088795953	5	0.0025	50	50	0.0	0.1	9473
27	0.026819107326238944	0.02617468864409463	5	0.0025	50	50	0.0	0.1	9473
28	0.02681980596084144	0.026254399560292182	5	0.0025	50	50	0.0	0.1	9473
29	0.02679498081269552	0.026292080326757287	5	0.0025	50	50	0.0	0.1	9473
30	0.026796537580958565	0.02628723294411859	5	0.0025	50	50	0.0	0.1	9473
31	0.026781341341194243	0.026188411815786454	5	0.0025	50	50	0.0	0.1	9473
32	0.026787133056313847	0.02613952050402219	5	0.0025	50	50	0.0	0.1	9473
33	0.02678127064062212	0.02639068823742251	5	0.0025	50	50	0.0	0.1	9473
34	0.026778542743868154	0.026177299826852907	5	0.0025	50	50	0.0	0.1	9473
35	0.02678110799428147	0.026159838016499296	5	0.0025	50	50	0.0	0.1	9473
36	0.026763216335622068	0.026144911034698695	5	0.0025	50	50	0.0	0.1	9473
37	0.026752658353770793	0.026117970689732303	5	0.0025	50	50	0.0	0.1	9473
38	0.026726954903037645	0.026118507017568467	5	0.0025	50	50	0.0	0.1	9473
39	0.026720426891592323	0.026053262842430897	5	0.0025	50	50	0.0	0.1	9473
40	0.02672869758912972	0.026077846528153804	5	0.0025	50	50	0.0	0.1	9473
41	0.02673602897844418	0.026055180715186876	5	0.0025	50	50	0.0	0.1	9473
42	0.026693659701291502	0.026131430793959597	5	0.0025	50	50	0.0	0.1	9473
43	0.02669210409676118	0.025995983337951434	5	0.0025	50	50	0.0	0.1	9473
44	0.02666128835254289	0.025991867686377883	5	0.0025	50	50	0.0	0.1	9473
45	0.02664818314794468	0.026006770265034007	5	0.0025	50	50	0.0	0.1	9473
46	0.02662998959295468	0.025973845429960674	5	0.0025	50	50	0.0	0.1	9473
47	0.026612509659014686	0.02589478398927881	5	0.0025	50	50	0.0	0.1	9473
48	0.026568288406604322	0.025939105961820818	5	0.0025	50	50	0.0	0.1	9473
49	0.026564373495942737	0.02588260440551186	5	0.0025	50	50	0.0	0.1	9473
