	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.05516014697795389	0.03639297923126594	5	0.0005	100	50	0.0	0.5	7280
1	0.03540322786513872	0.035285465077392004	5	0.0005	100	50	0.0	0.5	7280
2	0.03487405116659643	0.034879925338476614	5	0.0005	100	50	0.0	0.5	7280
3	0.03458114974236344	0.034627002893624755	5	0.0005	100	50	0.0	0.5	7280
4	0.03436710868372327	0.034447423337351527	5	0.0005	100	50	0.0	0.5	7280
5	0.034234595410133996	0.034335816503425855	5	0.0005	100	50	0.0	0.5	7280
6	0.034130120357269186	0.03423199108864108	5	0.0005	100	50	0.0	0.5	7280
7	0.03405279648653204	0.034178152609167775	5	0.0005	100	50	0.0	0.5	7280
8	0.033996276299014146	0.03409878205130479	5	0.0005	100	50	0.0	0.5	7280
9	0.03394012274686593	0.03403770192802294	5	0.0005	100	50	0.0	0.5	7280
10	0.03388496038590913	0.033959430665575524	5	0.0005	100	50	0.0	0.5	7280
11	0.033836252779214954	0.0339041002536367	5	0.0005	100	50	0.0	0.5	7280
12	0.033770770269854596	0.03383885648094445	5	0.0005	100	50	0.0	0.5	7280
13	0.03370643222048953	0.03378714524907546	5	0.0005	100	50	0.0	0.5	7280
14	0.033649612528021754	0.03371073376836102	5	0.0005	100	50	0.0	0.5	7280
15	0.03359684516106568	0.03364379103535904	5	0.0005	100	50	0.0	0.5	7280
16	0.03353093988686075	0.03359216678866237	5	0.0005	100	50	0.0	0.5	7280
17	0.03345521043878831	0.033511860912263276	5	0.0005	100	50	0.0	0.5	7280
18	0.03339671506103681	0.033460695389123996	5	0.0005	100	50	0.0	0.5	7280
19	0.03332591021917685	0.03337264125792748	5	0.0005	100	50	0.0	0.5	7280
20	0.03326079885091549	0.03329597255410929	5	0.0005	100	50	0.0	0.5	7280
21	0.03318636594713209	0.03324175685159791	5	0.0005	100	50	0.0	0.5	7280
22	0.03312181704863154	0.033175972705247525	5	0.0005	100	50	0.0	0.5	7280
23	0.03304302963073697	0.033090147636759576	5	0.0005	100	50	0.0	0.5	7280
24	0.03296234026831445	0.03303255184943544	5	0.0005	100	50	0.0	0.5	7280
25	0.03289630668471106	0.0329324218870121	5	0.0005	100	50	0.0	0.5	7280
26	0.032810760098001435	0.03285457953867675	5	0.0005	100	50	0.0	0.5	7280
27	0.032730500431766764	0.032785755192173596	5	0.0005	100	50	0.0	0.5	7280
28	0.032659625421434205	0.03271190286480446	5	0.0005	100	50	0.0	0.5	7280
29	0.032584288528251	0.03263275254069049	5	0.0005	100	50	0.0	0.5	7280
30	0.03250204574193659	0.03255741445643268	5	0.0005	100	50	0.0	0.5	7280
31	0.03242374930131465	0.032465298042185675	5	0.0005	100	50	0.0	0.5	7280
32	0.03235127113369298	0.03239349389794224	5	0.0005	100	50	0.0	0.5	7280
33	0.032267007663328365	0.032317455687041946	5	0.0005	100	50	0.0	0.5	7280
34	0.03209461031734317	0.03023219447988967	5	0.0005	100	50	0.0	0.5	7280
35	0.028745549049358634	0.028171081811787978	5	0.0005	100	50	0.0	0.5	7280
36	0.02821011266831503	0.027991089286072534	5	0.0005	100	50	0.0	0.5	7280
37	0.028110948611598182	0.027923267715776173	5	0.0005	100	50	0.0	0.5	7280
38	0.02803978320414197	0.027838360724781942	5	0.0005	100	50	0.0	0.5	7280
39	0.027992886660208386	0.02781391664840865	5	0.0005	100	50	0.0	0.5	7280
40	0.027961399695099597	0.027768399840644623	5	0.0005	100	50	0.0	0.5	7280
41	0.027927741412305685	0.027717392339618667	5	0.0005	100	50	0.0	0.5	7280
42	0.027892644081490715	0.0276812807786818	5	0.0005	100	50	0.0	0.5	7280
43	0.0278429928027243	0.02767588605260188	5	0.0005	100	50	0.0	0.5	7280
44	0.027819017477473645	0.027640251172118845	5	0.0005	100	50	0.0	0.5	7280
45	0.027794480260272	0.027622708135478583	5	0.0005	100	50	0.0	0.5	7280
46	0.027773325380484434	0.027559736330439667	5	0.0005	100	50	0.0	0.5	7280
47	0.027747981026285857	0.027541150102110484	5	0.0005	100	50	0.0	0.5	7280
48	0.027734594754015907	0.02753211280427175	5	0.0005	100	50	0.0	0.5	7280
49	0.027696487674378607	0.027491628546730738	5	0.0005	100	50	0.0	0.5	7280
