	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.03264440601228762	0.022646753986439103	50	0.0015	100	50	0.0	0.1	6115
1	0.019396835205346127	0.01711608065260186	50	0.0015	100	50	0.0	0.1	6115
2	0.01622783173624421	0.015404743954439578	50	0.0015	100	50	0.0	0.1	6115
3	0.014900825540066671	0.01449920651974801	50	0.0015	100	50	0.0	0.1	6115
4	0.01428608728489023	0.01423183590686572	50	0.0015	100	50	0.0	0.1	6115
5	0.01406583225928998	0.014038196597497618	50	0.0015	100	50	0.0	0.1	6115
6	0.013975800858397173	0.014081004946483709	50	0.0015	100	50	0.0	0.1	6115
7	0.013927251002688464	0.013910009538181426	50	0.0015	100	50	0.0	0.1	6115
8	0.013897470319179588	0.013923106465780712	50	0.0015	100	50	0.0	0.1	6115
9	0.013864070280965287	0.01389404292259344	50	0.0015	100	50	0.0	0.1	6115
10	0.013839488114315126	0.013875474072422967	50	0.0015	100	50	0.0	0.1	6115
11	0.01381235105083189	0.013894046663910321	50	0.0015	100	50	0.0	0.1	6115
12	0.013808105583483242	0.013807931601516832	50	0.0015	100	50	0.0	0.1	6115
13	0.013788522015451676	0.013825371553391275	50	0.0015	100	50	0.0	0.1	6115
14	0.01378661647059469	0.013830146713121785	50	0.0015	100	50	0.0	0.1	6115
15	0.013762335310705243	0.01377930666140172	50	0.0015	100	50	0.0	0.1	6115
16	0.013758475460372505	0.013821163179128508	50	0.0015	100	50	0.0	0.1	6115
17	0.013748396070875702	0.01377845266353104	50	0.0015	100	50	0.0	0.1	6115
18	0.013736263891385407	0.013811892382871808	50	0.0015	100	50	0.0	0.1	6115
19	0.013738407086749982	0.01379279497597744	50	0.0015	100	50	0.0	0.1	6115
20	0.013737308254437164	0.013773960727364908	50	0.0015	100	50	0.0	0.1	6115
21	0.013720542477208535	0.01380523851045174	50	0.0015	100	50	0.0	0.1	6115
22	0.013714237863958376	0.013825617048597359	50	0.0015	100	50	0.0	0.1	6115
23	0.013712488390777596	0.01378645962656228	50	0.0015	100	50	0.0	0.1	6115
24	0.013692696762334448	0.01375785538923159	50	0.0015	100	50	0.0	0.1	6115
25	0.01369983512458241	0.013753540881590679	50	0.0015	100	50	0.0	0.1	6115
26	0.013679362352849205	0.013722586926307892	50	0.0015	100	50	0.0	0.1	6115
27	0.013685039312069295	0.013723420326457311	50	0.0015	100	50	0.0	0.1	6115
28	0.013668032888032977	0.013847576153338183	50	0.0015	100	50	0.0	0.1	6115
29	0.013669269185160636	0.0137412055764155	50	0.0015	100	50	0.0	0.1	6115
30	0.013661876516245503	0.013698776234760453	50	0.0015	100	50	0.0	0.1	6115
31	0.013656115148113192	0.013720439823547353	50	0.0015	100	50	0.0	0.1	6115
32	0.013646912288198141	0.01382999019216511	50	0.0015	100	50	0.0	0.1	6115
33	0.013667955702139266	0.01369756351921344	50	0.0015	100	50	0.0	0.1	6115
34	0.013632489215457153	0.013684582645447486	50	0.0015	100	50	0.0	0.1	6115
35	0.013624615049308043	0.013732448188199823	50	0.0015	100	50	0.0	0.1	6115
36	0.013635121571456323	0.013665764475059669	50	0.0015	100	50	0.0	0.1	6115
37	0.013616331198088399	0.013672871150104881	50	0.0015	100	50	0.0	0.1	6115
38	0.013612104990803245	0.013679067235632334	50	0.0015	100	50	0.0	0.1	6115
39	0.013613962444964458	0.013734192051435064	50	0.0015	100	50	0.0	0.1	6115
40	0.01360739168627798	0.013663057282381829	50	0.0015	100	50	0.0	0.1	6115
41	0.01361272664817657	0.0136254410442841	50	0.0015	100	50	0.0	0.1	6115
42	0.013597695064324003	0.013694273965009426	50	0.0015	100	50	0.0	0.1	6115
43	0.013590236678446447	0.01370799176245358	50	0.0015	100	50	0.0	0.1	6115
44	0.013590790495900961	0.0136868846184266	50	0.0015	100	50	0.0	0.1	6115
45	0.013579871522813392	0.013720262311327754	50	0.0015	100	50	0.0	0.1	6115
46	0.01358665351026828	0.01363573054539086	50	0.0015	100	50	0.0	0.1	6115
47	0.013571883118616923	0.01358918102732352	50	0.0015	100	50	0.0	0.1	6115
48	0.013566244609968975	0.013654810278525088	50	0.0015	100	50	0.0	0.1	6115
49	0.013561353097616056	0.013629497198056765	50	0.0015	100	50	0.0	0.1	6115
