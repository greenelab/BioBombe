	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.033249624551187906	0.021771878296114062	100	0.0005	50	50	1e-06	0.1	8933
1	0.019708066128576635	0.017939910680824893	100	0.0005	50	50	1e-06	0.1	8933
2	0.017361967854180423	0.01639769738807163	100	0.0005	50	50	1e-06	0.1	8933
3	0.01612470313727786	0.01540160126250458	100	0.0005	50	50	1e-06	0.1	8933
4	0.015287516581943947	0.014719270586426126	100	0.0005	50	50	1e-06	0.1	8933
5	0.014696529537695008	0.014369895516130824	100	0.0005	50	50	1e-06	0.1	8933
6	0.014244894003682571	0.013892905767045445	100	0.0005	50	50	1e-06	0.1	8933
7	0.013836788577238857	0.01342632793367308	100	0.0005	50	50	1e-06	0.1	8933
8	0.01351959926717266	0.013159939914186758	100	0.0005	50	50	1e-06	0.1	8933
9	0.013270930730104826	0.012891933044158706	100	0.0005	50	50	1e-06	0.1	8933
10	0.013001782212631584	0.012675731964623039	100	0.0005	50	50	1e-06	0.1	8933
11	0.012815796624812515	0.012553386046528019	100	0.0005	50	50	1e-06	0.1	8933
12	0.012643870158113272	0.012425729205358211	100	0.0005	50	50	1e-06	0.1	8933
13	0.012455203143400307	0.01244376176330715	100	0.0005	50	50	1e-06	0.1	8933
14	0.012357802807823302	0.012899904682819178	100	0.0005	50	50	1e-06	0.1	8933
15	0.012219287279958073	0.011971843005095682	100	0.0005	50	50	1e-06	0.1	8933
16	0.012063820502858992	0.011857793093026824	100	0.0005	50	50	1e-06	0.1	8933
17	0.011927168696412723	0.011742977689004308	100	0.0005	50	50	1e-06	0.1	8933
18	0.011808652195394431	0.011602088312189278	100	0.0005	50	50	1e-06	0.1	8933
19	0.01176928407501227	0.011987960899166806	100	0.0005	50	50	1e-06	0.1	8933
20	0.011651357352293527	0.011543753218568192	100	0.0005	50	50	1e-06	0.1	8933
21	0.01160382414089244	0.011537635622343074	100	0.0005	50	50	1e-06	0.1	8933
22	0.011473840457253403	0.011444031073930843	100	0.0005	50	50	1e-06	0.1	8933
23	0.01141695065231309	0.01128270404224585	100	0.0005	50	50	1e-06	0.1	8933
24	0.011389613236539786	0.011237146306149021	100	0.0005	50	50	1e-06	0.1	8933
25	0.011286544872268371	0.011144017449884637	100	0.0005	50	50	1e-06	0.1	8933
26	0.011189103368038512	0.01114699875412377	100	0.0005	50	50	1e-06	0.1	8933
27	0.011130883068128872	0.011041577992672332	100	0.0005	50	50	1e-06	0.1	8933
28	0.011081232707822828	0.011137560182687316	100	0.0005	50	50	1e-06	0.1	8933
29	0.011077331089656367	0.010965028742103915	100	0.0005	50	50	1e-06	0.1	8933
30	0.011007830838087191	0.01086168841638711	100	0.0005	50	50	1e-06	0.1	8933
31	0.010957809799523646	0.010900834110524527	100	0.0005	50	50	1e-06	0.1	8933
32	0.010864223578950146	0.010965724424040568	100	0.0005	50	50	1e-06	0.1	8933
33	0.010866184084503358	0.011008677961408066	100	0.0005	50	50	1e-06	0.1	8933
34	0.010834385291462996	0.010720654180625998	100	0.0005	50	50	1e-06	0.1	8933
35	0.010814236885046118	0.010787444887237613	100	0.0005	50	50	1e-06	0.1	8933
36	0.0107712017911078	0.010712441464754295	100	0.0005	50	50	1e-06	0.1	8933
37	0.010673220113947201	0.010690125063360877	100	0.0005	50	50	1e-06	0.1	8933
38	0.010650493228042448	0.01072036264816844	100	0.0005	50	50	1e-06	0.1	8933
39	0.01068561811049183	0.010876773708779543	100	0.0005	50	50	1e-06	0.1	8933
40	0.010639048461177695	0.010542251899781464	100	0.0005	50	50	1e-06	0.1	8933
41	0.01059719342091322	0.010546299491797077	100	0.0005	50	50	1e-06	0.1	8933
42	0.010517507378147687	0.010527283442963492	100	0.0005	50	50	1e-06	0.1	8933
43	0.010572332423625572	0.010586026309852276	100	0.0005	50	50	1e-06	0.1	8933
44	0.010472961587671688	0.010698894313029075	100	0.0005	50	50	1e-06	0.1	8933
45	0.010459209248046813	0.010693804626255144	100	0.0005	50	50	1e-06	0.1	8933
46	0.010491605129472465	0.01045975266968258	100	0.0005	50	50	1e-06	0.1	8933
47	0.010463067114829675	0.011109613587306973	100	0.0005	50	50	1e-06	0.1	8933
48	0.0104340285674833	0.010549822767010497	100	0.0005	50	50	1e-06	0.1	8933
49	0.010398532611412025	0.010391262498814221	100	0.0005	50	50	1e-06	0.1	8933
