	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.03903734941531396	0.027682202467498997	50	0.0005	100	50	0.0	0.5	2978
1	0.023933981092816695	0.02064403048208977	50	0.0005	100	50	0.0	0.5	2978
2	0.019195080721630346	0.017502113332683453	50	0.0005	100	50	0.0	0.5	2978
3	0.017054137067874647	0.01602037120289944	50	0.0005	100	50	0.0	0.5	2978
4	0.015878272880710528	0.01502445303295413	50	0.0005	100	50	0.0	0.5	2978
5	0.015060867220111896	0.014338528076774418	50	0.0005	100	50	0.0	0.5	2978
6	0.014519566823417216	0.013898270746005652	50	0.0005	100	50	0.0	0.5	2978
7	0.014108894899618888	0.01341359391024988	50	0.0005	100	50	0.0	0.5	2978
8	0.013745747765049878	0.013069704564975622	50	0.0005	100	50	0.0	0.5	2978
9	0.013454151807914287	0.012810969780453874	50	0.0005	100	50	0.0	0.5	2978
10	0.013211527102298675	0.012547920360078547	50	0.0005	100	50	0.0	0.5	2978
11	0.013000945407771778	0.012367981441504184	50	0.0005	100	50	0.0	0.5	2978
12	0.012820468232444062	0.012160003422109506	50	0.0005	100	50	0.0	0.5	2978
13	0.012671466426155898	0.012015678287692098	50	0.0005	100	50	0.0	0.5	2978
14	0.012550606991801659	0.011880362169535735	50	0.0005	100	50	0.0	0.5	2978
15	0.01243650825458924	0.011774911212220247	50	0.0005	100	50	0.0	0.5	2978
16	0.012354566295261491	0.011722867654896489	50	0.0005	100	50	0.0	0.5	2978
17	0.012260973921903867	0.01160581938274219	50	0.0005	100	50	0.0	0.5	2978
18	0.012194572912894596	0.011538206296928413	50	0.0005	100	50	0.0	0.5	2978
19	0.01213328769331776	0.011483288045979709	50	0.0005	100	50	0.0	0.5	2978
20	0.012090305271889418	0.011429315089224972	50	0.0005	100	50	0.0	0.5	2978
21	0.012056864654012305	0.011382054040710625	50	0.0005	100	50	0.0	0.5	2978
22	0.01202954748186541	0.01138559074798175	50	0.0005	100	50	0.0	0.5	2978
23	0.012016237881495672	0.011341785874937164	50	0.0005	100	50	0.0	0.5	2978
24	0.011982656715733205	0.011343032224940753	50	0.0005	100	50	0.0	0.5	2978
25	0.011967762936455567	0.011301096512741957	50	0.0005	100	50	0.0	0.5	2978
26	0.011949124452172697	0.01129628446693915	50	0.0005	100	50	0.0	0.5	2978
27	0.011937740606745682	0.011304357133620557	50	0.0005	100	50	0.0	0.5	2978
28	0.011938266828339589	0.011287832258707251	50	0.0005	100	50	0.0	0.5	2978
29	0.011928770288074673	0.011269480990776596	50	0.0005	100	50	0.0	0.5	2978
30	0.011916513402582095	0.011251080323573394	50	0.0005	100	50	0.0	0.5	2978
31	0.011905454492761784	0.01127321414300463	50	0.0005	100	50	0.0	0.5	2978
32	0.01191102505166748	0.011242710299661693	50	0.0005	100	50	0.0	0.5	2978
33	0.011903888485873784	0.011230141050885671	50	0.0005	100	50	0.0	0.5	2978
34	0.011887162218568278	0.011230136869728109	50	0.0005	100	50	0.0	0.5	2978
35	0.011889772316323993	0.01121494017299229	50	0.0005	100	50	0.0	0.5	2978
36	0.011888928633647468	0.01122986467245318	50	0.0005	100	50	0.0	0.5	2978
37	0.01187604908456138	0.011223959980486227	50	0.0005	100	50	0.0	0.5	2978
38	0.011867231408106993	0.011216026315924998	50	0.0005	100	50	0.0	0.5	2978
39	0.01186244128871316	0.011222575849944273	50	0.0005	100	50	0.0	0.5	2978
40	0.011864091263141875	0.011188633939390201	50	0.0005	100	50	0.0	0.5	2978
41	0.011866001371212338	0.011248162256671298	50	0.0005	100	50	0.0	0.5	2978
42	0.011853694917750285	0.011205222343680508	50	0.0005	100	50	0.0	0.5	2978
43	0.011854951654009866	0.011227144409206127	50	0.0005	100	50	0.0	0.5	2978
44	0.01184417153693301	0.011234417189104949	50	0.0005	100	50	0.0	0.5	2978
45	0.01184874886509736	0.01122067575245013	50	0.0005	100	50	0.0	0.5	2978
46	0.01185000152967757	0.01122747157766247	50	0.0005	100	50	0.0	0.5	2978
47	0.011848240711537372	0.011199309494182554	50	0.0005	100	50	0.0	0.5	2978
48	0.011841502367423562	0.011257136867419028	50	0.0005	100	50	0.0	0.5	2978
49	0.01184537017609717	0.011242291142177513	50	0.0005	100	50	0.0	0.5	2978
