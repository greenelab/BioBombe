	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.03606305884914274	0.028768695634478137	5	0.0015	50	50	0.0	0.5	4192
1	0.02631337314145219	0.025972706431355578	5	0.0015	50	50	0.0	0.5	4192
2	0.025585825875295433	0.025730467908953388	5	0.0015	50	50	0.0	0.5	4192
3	0.025345770032690736	0.025505225240016076	5	0.0015	50	50	0.0	0.5	4192
4	0.025142601926960537	0.02523448404074285	5	0.0015	50	50	0.0	0.5	4192
5	0.02494572749517523	0.025221014808485886	5	0.0015	50	50	0.0	0.5	4192
6	0.02479098386200584	0.02479756587891916	5	0.0015	50	50	0.0	0.5	4192
7	0.02463155745760257	0.024668284458594387	5	0.0015	50	50	0.0	0.5	4192
8	0.024486397433316404	0.024529665868807705	5	0.0015	50	50	0.0	0.5	4192
9	0.024420117318644467	0.024555428655209096	5	0.0015	50	50	0.0	0.5	4192
10	0.024331139599668743	0.02452352154380277	5	0.0015	50	50	0.0	0.5	4192
11	0.024257565389942264	0.02431077859498005	5	0.0015	50	50	0.0	0.5	4192
12	0.024203733246922682	0.024284806138128896	5	0.0015	50	50	0.0	0.5	4192
13	0.024149022065993515	0.024227505065429505	5	0.0015	50	50	0.0	0.5	4192
14	0.024134124498103954	0.024151393844537707	5	0.0015	50	50	0.0	0.5	4192
15	0.0240668666304744	0.02413553812578463	5	0.0015	50	50	0.0	0.5	4192
16	0.02407099378789844	0.02409868425979897	5	0.0015	50	50	0.0	0.5	4192
17	0.024039547485166336	0.024056203271588222	5	0.0015	50	50	0.0	0.5	4192
18	0.024000069980141422	0.024063889731441128	5	0.0015	50	50	0.0	0.5	4192
19	0.02397628469594693	0.024121059275750447	5	0.0015	50	50	0.0	0.5	4192
20	0.023960742523817927	0.024094857218502585	5	0.0015	50	50	0.0	0.5	4192
21	0.023946899309054668	0.023966476923107646	5	0.0015	50	50	0.0	0.5	4192
22	0.02392368654316909	0.024022539336782795	5	0.0015	50	50	0.0	0.5	4192
23	0.023910800212534937	0.02404547481304373	5	0.0015	50	50	0.0	0.5	4192
24	0.023879719229270013	0.023972839594286213	5	0.0015	50	50	0.0	0.5	4192
25	0.023886614241173755	0.02399903909440364	5	0.0015	50	50	0.0	0.5	4192
26	0.023876081599251288	0.02395888180409631	5	0.0015	50	50	0.0	0.5	4192
27	0.023864031669702652	0.024057595721707747	5	0.0015	50	50	0.0	0.5	4192
28	0.02386929600414581	0.02398013976361624	5	0.0015	50	50	0.0	0.5	4192
29	0.02384184514570411	0.02396404196866156	5	0.0015	50	50	0.0	0.5	4192
30	0.023837890309571244	0.024003132921331927	5	0.0015	50	50	0.0	0.5	4192
31	0.023823205084218098	0.02399914555009419	5	0.0015	50	50	0.0	0.5	4192
32	0.023801790453192025	0.023983479076800564	5	0.0015	50	50	0.0	0.5	4192
33	0.02381792698701782	0.02391250210370776	5	0.0015	50	50	0.0	0.5	4192
34	0.023810491146705588	0.024130141472953226	5	0.0015	50	50	0.0	0.5	4192
35	0.023817752269201055	0.023938601847246544	5	0.0015	50	50	0.0	0.5	4192
36	0.023801478203973773	0.023876960736558723	5	0.0015	50	50	0.0	0.5	4192
37	0.023802636505878213	0.023891646012549873	5	0.0015	50	50	0.0	0.5	4192
38	0.023784243146824896	0.02394599743529328	5	0.0015	50	50	0.0	0.5	4192
39	0.023801872940095073	0.02392475149927244	5	0.0015	50	50	0.0	0.5	4192
40	0.02377690986439176	0.02390724598264489	5	0.0015	50	50	0.0	0.5	4192
41	0.023779077174609593	0.02385848271972135	5	0.0015	50	50	0.0	0.5	4192
42	0.023762683700629644	0.024034598621452515	5	0.0015	50	50	0.0	0.5	4192
43	0.02375601263198173	0.02390885201013909	5	0.0015	50	50	0.0	0.5	4192
44	0.02379067726654903	0.02387055969773925	5	0.0015	50	50	0.0	0.5	4192
45	0.023753348497530802	0.023919184555087673	5	0.0015	50	50	0.0	0.5	4192
46	0.023734781141735713	0.023872766825397202	5	0.0015	50	50	0.0	0.5	4192
47	0.023774432294046185	0.023859062493844653	5	0.0015	50	50	0.0	0.5	4192
48	0.023753581255750347	0.0238599709233351	5	0.0015	50	50	0.0	0.5	4192
49	0.023760029859900233	0.023858058157717063	5	0.0015	50	50	0.0	0.5	4192
