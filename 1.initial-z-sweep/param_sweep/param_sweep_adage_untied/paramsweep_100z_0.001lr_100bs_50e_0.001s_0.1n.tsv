	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	2.592255998513251	1.761760745062199	100	0.001	100	50	0.001	0.1	2566
1	2.0231360345809755	1.7547230521078092	100	0.001	100	50	0.001	0.1	2566
2	1.904494909548448	1.6241484990995199	100	0.001	100	50	0.001	0.1	2566
3	1.7950556888300948	1.6183835469741894	100	0.001	100	50	0.001	0.1	2566
4	1.7085740064176504	1.7101024391546304	100	0.001	100	50	0.001	0.1	2566
5	1.6202440971391279	1.7242061986977921	100	0.001	100	50	0.001	0.1	2566
6	1.5728535340333307	1.5990016452441025	100	0.001	100	50	0.001	0.1	2566
7	1.5007881056020684	1.3164062560402412	100	0.001	100	50	0.001	0.1	2566
8	1.4093691439725102	1.8729549379695214	100	0.001	100	50	0.001	0.1	2566
9	1.39694198466577	1.6797412690879283	100	0.001	100	50	0.001	0.1	2566
10	1.4163722520767155	1.6943412750218612	100	0.001	100	50	0.001	0.1	2566
11	1.315285570518213	1.9161245773900764	100	0.001	100	50	0.001	0.1	2566
12	1.382514594867786	1.68955509031252	100	0.001	100	50	0.001	0.1	2566
13	1.2536114722658114	1.642821903780359	100	0.001	100	50	0.001	0.1	2566
14	1.2500549180245761	1.6452979680229098	100	0.001	100	50	0.001	0.1	2566
15	1.2064309187964022	1.3691991510628285	100	0.001	100	50	0.001	0.1	2566
16	1.20680606175239	1.6543266655838056	100	0.001	100	50	0.001	0.1	2566
17	1.290169004937813	1.4909296599902342	100	0.001	100	50	0.001	0.1	2566
18	1.244260943475444	1.590562062441277	100	0.001	100	50	0.001	0.1	2566
19	1.1919385325220988	1.489548137265455	100	0.001	100	50	0.001	0.1	2566
20	1.120330569245579	1.6497439352321808	100	0.001	100	50	0.001	0.1	2566
21	1.1784005241750923	1.767463975381213	100	0.001	100	50	0.001	0.1	2566
22	1.2002665084799278	1.6790229149347966	100	0.001	100	50	0.001	0.1	2566
23	1.1835314564341175	1.7126989680312104	100	0.001	100	50	0.001	0.1	2566
24	1.3830442823430855	1.66609671181976	100	0.001	100	50	0.001	0.1	2566
25	1.2276875100334126	1.4153446201840505	100	0.001	100	50	0.001	0.1	2566
26	1.2671291920066854	1.6553857544184187	100	0.001	100	50	0.001	0.1	2566
27	1.1593521648061575	1.7131523929863997	100	0.001	100	50	0.001	0.1	2566
28	1.2062103427027613	1.8127676189287671	100	0.001	100	50	0.001	0.1	2566
29	1.2382608299476743	1.6166056410532381	100	0.001	100	50	0.001	0.1	2566
30	1.1846220746460674	1.5189991702769043	100	0.001	100	50	0.001	0.1	2566
31	1.2254917495080113	1.8765582153947586	100	0.001	100	50	0.001	0.1	2566
32	1.311265136652794	1.9154077347788254	100	0.001	100	50	0.001	0.1	2566
33	1.2666056604918798	1.6901390145659219	100	0.001	100	50	0.001	0.1	2566
34	1.2582748015084202	1.8598754586042912	100	0.001	100	50	0.001	0.1	2566
35	1.182229996161292	1.8133849784247507	100	0.001	100	50	0.001	0.1	2566
36	1.3426971855480057	1.84732263357188	100	0.001	100	50	0.001	0.1	2566
37	1.2807744687711422	1.7012813861693752	100	0.001	100	50	0.001	0.1	2566
38	1.2444828792030824	1.7346471454627654	100	0.001	100	50	0.001	0.1	2566
39	1.3067527341229064	1.370588224886936	100	0.001	100	50	0.001	0.1	2566
40	1.1902811773874094	1.5784930050031176	100	0.001	100	50	0.001	0.1	2566
41	1.246157975894896	1.738411984981588	100	0.001	100	50	0.001	0.1	2566
42	1.2021151226748825	1.903082211318481	100	0.001	100	50	0.001	0.1	2566
43	1.3518682470372818	1.7697093011544265	100	0.001	100	50	0.001	0.1	2566
44	1.2589327116046387	1.9517589923756529	100	0.001	100	50	0.001	0.1	2566
45	1.3355952104238753	1.6917455947421933	100	0.001	100	50	0.001	0.1	2566
46	1.2611892908988869	2.0808894068971417	100	0.001	100	50	0.001	0.1	2566
47	1.2450758621585771	1.5658395231112012	100	0.001	100	50	0.001	0.1	2566
48	1.1750302505261407	1.7401908775132655	100	0.001	100	50	0.001	0.1	2566
49	1.2293038076344072	1.6734173450597614	100	0.001	100	50	0.001	0.1	2566
