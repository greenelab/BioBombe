	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.027549671761720858	0.018495435372393856	50	0.001	50	50	0.0	0.1	9919
1	0.01625327758926771	0.015076723491085646	50	0.001	50	50	0.0	0.1	9919
2	0.014167643332940783	0.013690974394190722	50	0.001	50	50	0.0	0.1	9919
3	0.013213988829474957	0.013001533495849907	50	0.001	50	50	0.0	0.1	9919
4	0.012742539004902683	0.012706002849109657	50	0.001	50	50	0.0	0.1	9919
5	0.01255304918109082	0.012549666290743059	50	0.001	50	50	0.0	0.1	9919
6	0.012455108295027892	0.012534484354490645	50	0.001	50	50	0.0	0.1	9919
7	0.012423723783020695	0.012482606841475626	50	0.001	50	50	0.0	0.1	9919
8	0.01238430509675984	0.012571606247278062	50	0.001	50	50	0.0	0.1	9919
9	0.012364067853468295	0.012385996311447132	50	0.001	50	50	0.0	0.1	9919
10	0.012347257799880228	0.012390288121884344	50	0.001	50	50	0.0	0.1	9919
11	0.012327957084002921	0.012370518681167645	50	0.001	50	50	0.0	0.1	9919
12	0.012307642233135229	0.012396869028831189	50	0.001	50	50	0.0	0.1	9919
13	0.01229861316377091	0.012331557773538004	50	0.001	50	50	0.0	0.1	9919
14	0.012286380378983169	0.012349293508476099	50	0.001	50	50	0.0	0.1	9919
15	0.012288652643704628	0.01231339231603574	50	0.001	50	50	0.0	0.1	9919
16	0.012283465638420355	0.012336296869894172	50	0.001	50	50	0.0	0.1	9919
17	0.012276806658760946	0.012320997360844457	50	0.001	50	50	0.0	0.1	9919
18	0.012262928275860237	0.012305452176734776	50	0.001	50	50	0.0	0.1	9919
19	0.012266272981430985	0.012282720090283604	50	0.001	50	50	0.0	0.1	9919
20	0.012246736514200114	0.01227314991922782	50	0.001	50	50	0.0	0.1	9919
21	0.012247571449390027	0.012294928162193092	50	0.001	50	50	0.0	0.1	9919
22	0.012246736299500231	0.012325865789948754	50	0.001	50	50	0.0	0.1	9919
23	0.012252107439219357	0.012267634304628546	50	0.001	50	50	0.0	0.1	9919
24	0.012245686624456792	0.012313407017755008	50	0.001	50	50	0.0	0.1	9919
25	0.012233240198841464	0.012297248318221555	50	0.001	50	50	0.0	0.1	9919
26	0.012235686029618711	0.012254281482351213	50	0.001	50	50	0.0	0.1	9919
27	0.012216966537487415	0.01224909326236118	50	0.001	50	50	0.0	0.1	9919
28	0.012220910956916292	0.012252305199821296	50	0.001	50	50	0.0	0.1	9919
29	0.012210869837722882	0.01226982084346889	50	0.001	50	50	0.0	0.1	9919
30	0.012214360753616283	0.0123279532079316	50	0.001	50	50	0.0	0.1	9919
31	0.012207746717370046	0.01225893761976898	50	0.001	50	50	0.0	0.1	9919
32	0.01221514348645928	0.012263673338077492	50	0.001	50	50	0.0	0.1	9919
33	0.012199204383224239	0.012250830670444733	50	0.001	50	50	0.0	0.1	9919
34	0.0121985296931992	0.012246991885224105	50	0.001	50	50	0.0	0.1	9919
35	0.012194748872210955	0.012266532391537672	50	0.001	50	50	0.0	0.1	9919
36	0.012192174161151233	0.012293287130859797	50	0.001	50	50	0.0	0.1	9919
37	0.012189571954655044	0.012235564295466041	50	0.001	50	50	0.0	0.1	9919
38	0.012185352517045146	0.012220162389012868	50	0.001	50	50	0.0	0.1	9919
39	0.012185211667491617	0.012244981619214237	50	0.001	50	50	0.0	0.1	9919
40	0.012191027605111244	0.01227787644718106	50	0.001	50	50	0.0	0.1	9919
41	0.012188888471136276	0.012241208122733332	50	0.001	50	50	0.0	0.1	9919
42	0.012196271306994706	0.012312585445224213	50	0.001	50	50	0.0	0.1	9919
43	0.012190090102148237	0.012212324757520715	50	0.001	50	50	0.0	0.1	9919
44	0.012179010341308626	0.012207737226345458	50	0.001	50	50	0.0	0.1	9919
45	0.012169175168969712	0.012231303946992978	50	0.001	50	50	0.0	0.1	9919
46	0.012173322896621224	0.01218666550462948	50	0.001	50	50	0.0	0.1	9919
47	0.01217210752204651	0.012379999845920853	50	0.001	50	50	0.0	0.1	9919
48	0.012173134106760778	0.01224815478836886	50	0.001	50	50	0.0	0.1	9919
49	0.012169037119716068	0.012275288563513733	50	0.001	50	50	0.0	0.1	9919
