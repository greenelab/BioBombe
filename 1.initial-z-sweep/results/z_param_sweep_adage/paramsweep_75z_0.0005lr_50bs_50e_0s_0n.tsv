	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.029842991161247338	0.01985770301896915	75	0.0005	50	50	0.0	0.0	1907
1	0.01731422954235686	0.01551866383749429	75	0.0005	50	50	0.0	0.0	1907
2	0.01461625133603368	0.013811946219727254	75	0.0005	50	50	0.0	0.0	1907
3	0.013344345937254361	0.012924162533853638	75	0.0005	50	50	0.0	0.0	1907
4	0.01253981546743316	0.012243612548318579	75	0.0005	50	50	0.0	0.0	1907
5	0.011957164482093543	0.01175812492770344	75	0.0005	50	50	0.0	0.0	1907
6	0.011527882791457217	0.011415576987880252	75	0.0005	50	50	0.0	0.0	1907
7	0.011201146221791414	0.01112510153158331	75	0.0005	50	50	0.0	0.0	1907
8	0.010949972776750899	0.01091659879472185	75	0.0005	50	50	0.0	0.0	1907
9	0.01076376356129472	0.010796104166051285	75	0.0005	50	50	0.0	0.0	1907
10	0.01061664675496472	0.010627029196539071	75	0.0005	50	50	0.0	0.0	1907
11	0.010515272352279727	0.010557135784318297	75	0.0005	50	50	0.0	0.0	1907
12	0.010452200902308717	0.010495296458626454	75	0.0005	50	50	0.0	0.0	1907
13	0.010395167964080923	0.010458180030904013	75	0.0005	50	50	0.0	0.0	1907
14	0.010356536926498837	0.010430638313321949	75	0.0005	50	50	0.0	0.0	1907
15	0.010329039264967017	0.010408665318875422	75	0.0005	50	50	0.0	0.0	1907
16	0.010310346498320818	0.010382447430924521	75	0.0005	50	50	0.0	0.0	1907
17	0.010289748351157035	0.010358020592032153	75	0.0005	50	50	0.0	0.0	1907
18	0.010277502277436013	0.010357216442178357	75	0.0005	50	50	0.0	0.0	1907
19	0.0102627094656753	0.010337767942699944	75	0.0005	50	50	0.0	0.0	1907
20	0.010252563844826819	0.010343223594727412	75	0.0005	50	50	0.0	0.0	1907
21	0.010245694824075212	0.0103268200570778	75	0.0005	50	50	0.0	0.0	1907
22	0.010234307915662511	0.010393339310760252	75	0.0005	50	50	0.0	0.0	1907
23	0.010228431395573716	0.010327474196329286	75	0.0005	50	50	0.0	0.0	1907
24	0.010216895642658798	0.010337035545641218	75	0.0005	50	50	0.0	0.0	1907
25	0.010212694282284246	0.010303894052527717	75	0.0005	50	50	0.0	0.0	1907
26	0.01020586494460083	0.010302060892730667	75	0.0005	50	50	0.0	0.0	1907
27	0.010200681972706132	0.010293628382950622	75	0.0005	50	50	0.0	0.0	1907
28	0.01019651034262562	0.010286683522976835	75	0.0005	50	50	0.0	0.0	1907
29	0.0101909085729861	0.01030908122900909	75	0.0005	50	50	0.0	0.0	1907
30	0.010183636520782554	0.010305211220442338	75	0.0005	50	50	0.0	0.0	1907
31	0.01018314515962258	0.010271661651336783	75	0.0005	50	50	0.0	0.0	1907
32	0.010177982546718376	0.010285581351679894	75	0.0005	50	50	0.0	0.0	1907
33	0.010173957070762574	0.010288835686576297	75	0.0005	50	50	0.0	0.0	1907
34	0.010173602107448075	0.010275380698390605	75	0.0005	50	50	0.0	0.0	1907
35	0.010164665430566558	0.010271314424720823	75	0.0005	50	50	0.0	0.0	1907
36	0.01015959097382956	0.010271155855922922	75	0.0005	50	50	0.0	0.0	1907
37	0.01015744613853386	0.01026882415185068	75	0.0005	50	50	0.0	0.0	1907
38	0.010154972661832346	0.010261611893673358	75	0.0005	50	50	0.0	0.0	1907
39	0.010152631220314286	0.01026748642539089	75	0.0005	50	50	0.0	0.0	1907
40	0.010148985898598093	0.010278180246926972	75	0.0005	50	50	0.0	0.0	1907
41	0.010148086665839537	0.010256806433015641	75	0.0005	50	50	0.0	0.0	1907
42	0.010145660213161246	0.010251472518916454	75	0.0005	50	50	0.0	0.0	1907
43	0.010139510834455636	0.010273319036908177	75	0.0005	50	50	0.0	0.0	1907
44	0.0101444333989415	0.010270953593316201	75	0.0005	50	50	0.0	0.0	1907
45	0.010143005066819099	0.010261730194789844	75	0.0005	50	50	0.0	0.0	1907
46	0.010132952625422477	0.010278877221674696	75	0.0005	50	50	0.0	0.0	1907
47	0.010132901588490263	0.010252776671464538	75	0.0005	50	50	0.0	0.0	1907
48	0.010135430803853521	0.010240504354323986	75	0.0005	50	50	0.0	0.0	1907
49	0.010126155229936583	0.010260543575862967	75	0.0005	50	50	0.0	0.0	1907
