	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.03589686889406802	0.024316737157636346	25	0.001	100	50	0.0	0.0	5507
1	0.021541583592709898	0.019481470762087783	25	0.001	100	50	0.0	0.0	5507
2	0.017850901812994112	0.016904784875777665	25	0.001	100	50	0.0	0.0	5507
3	0.016135510751572105	0.015774566626771003	25	0.001	100	50	0.0	0.0	5507
4	0.015333518739696721	0.015224121023062082	25	0.001	100	50	0.0	0.0	5507
5	0.01492582523050973	0.014932715542343789	25	0.001	100	50	0.0	0.0	5507
6	0.014667291296207694	0.014743653177702177	25	0.001	100	50	0.0	0.0	5507
7	0.014514594364954456	0.01459715405682077	25	0.001	100	50	0.0	0.0	5507
8	0.014428276772467677	0.014498569201286277	25	0.001	100	50	0.0	0.0	5507
9	0.014364497735502742	0.014533459768055389	25	0.001	100	50	0.0	0.0	5507
10	0.014332072976349353	0.014401190542040775	25	0.001	100	50	0.0	0.0	5507
11	0.014281839786500489	0.014394572811347235	25	0.001	100	50	0.0	0.0	5507
12	0.014255777459967995	0.014355887555611634	25	0.001	100	50	0.0	0.0	5507
13	0.014232985137694765	0.014358745681310703	25	0.001	100	50	0.0	0.0	5507
14	0.014222065241496646	0.014331460734526583	25	0.001	100	50	0.0	0.0	5507
15	0.014195543473047613	0.014319015100569843	25	0.001	100	50	0.0	0.0	5507
16	0.014177730407506072	0.014288826172469793	25	0.001	100	50	0.0	0.0	5507
17	0.014166092399963281	0.014308515831073088	25	0.001	100	50	0.0	0.0	5507
18	0.014162703869496486	0.0142779961677115	25	0.001	100	50	0.0	0.0	5507
19	0.014140115180958613	0.014287998153690968	25	0.001	100	50	0.0	0.0	5507
20	0.014132064331054187	0.014278592734132853	25	0.001	100	50	0.0	0.0	5507
21	0.014117760461171648	0.014273998055101352	25	0.001	100	50	0.0	0.0	5507
22	0.014112081008365788	0.014253354253849267	25	0.001	100	50	0.0	0.0	5507
23	0.014105491005248343	0.01423000146672272	25	0.001	100	50	0.0	0.0	5507
24	0.014097399381461812	0.014206688028420135	25	0.001	100	50	0.0	0.0	5507
25	0.014081860531442454	0.014211081116180689	25	0.001	100	50	0.0	0.0	5507
26	0.014082141781856444	0.014203902800526491	25	0.001	100	50	0.0	0.0	5507
27	0.01406838595419948	0.014231146475296632	25	0.001	100	50	0.0	0.0	5507
28	0.014060571244186148	0.014172420901091446	25	0.001	100	50	0.0	0.0	5507
29	0.01404869887470474	0.014188964154934564	25	0.001	100	50	0.0	0.0	5507
30	0.014041951824955956	0.014166059802298792	25	0.001	100	50	0.0	0.0	5507
31	0.014031672098109032	0.014165909964427438	25	0.001	100	50	0.0	0.0	5507
32	0.014027988684775155	0.014154309570703861	25	0.001	100	50	0.0	0.0	5507
33	0.014021710559850822	0.014201893449812614	25	0.001	100	50	0.0	0.0	5507
34	0.014015720817235214	0.014149715308363533	25	0.001	100	50	0.0	0.0	5507
35	0.014008145012091269	0.014157358811630459	25	0.001	100	50	0.0	0.0	5507
36	0.014001970968227907	0.014148385778610838	25	0.001	100	50	0.0	0.0	5507
37	0.01399412399218631	0.014149450355104348	25	0.001	100	50	0.0	0.0	5507
38	0.013986027733949474	0.014115911808726778	25	0.001	100	50	0.0	0.0	5507
39	0.013979962578742452	0.014112131394103996	25	0.001	100	50	0.0	0.0	5507
40	0.013972483552686817	0.01411808381857881	25	0.001	100	50	0.0	0.0	5507
41	0.013968287835060492	0.014104454217204401	25	0.001	100	50	0.0	0.0	5507
42	0.0139631894907355	0.014114479502274816	25	0.001	100	50	0.0	0.0	5507
43	0.013955380909265982	0.01408861729763377	25	0.001	100	50	0.0	0.0	5507
44	0.013946838096646152	0.0140873046153818	25	0.001	100	50	0.0	0.0	5507
45	0.013943617073740878	0.014093334464281513	25	0.001	100	50	0.0	0.0	5507
46	0.013933545043008318	0.014061470264942878	25	0.001	100	50	0.0	0.0	5507
47	0.01393572993872951	0.014087926437918018	25	0.001	100	50	0.0	0.0	5507
48	0.013933739931037983	0.014074013442029005	25	0.001	100	50	0.0	0.0	5507
49	0.013921650868329886	0.014123261288292777	25	0.001	100	50	0.0	0.0	5507
