	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.029397326002634953	0.019417098710886836	50	0.002	100	50	0.0	0.1	2881
1	0.01705302694145759	0.01559403089603434	50	0.002	100	50	0.0	0.1	2881
2	0.01466562101710657	0.01415230502084211	50	0.002	100	50	0.0	0.1	2881
3	0.013698353277178794	0.01354476050910029	50	0.002	100	50	0.0	0.1	2881
4	0.013265606138309466	0.013308562318764157	50	0.002	100	50	0.0	0.1	2881
5	0.013097150114039509	0.013172839089772213	50	0.002	100	50	0.0	0.1	2881
6	0.013037101510573013	0.013089909975062593	50	0.002	100	50	0.0	0.1	2881
7	0.01296413764086471	0.013086243028651004	50	0.002	100	50	0.0	0.1	2881
8	0.012930447351166493	0.013062920718744084	50	0.002	100	50	0.0	0.1	2881
9	0.012899768365924814	0.013062951536083427	50	0.002	100	50	0.0	0.1	2881
10	0.01289354583372567	0.013037035642387649	50	0.002	100	50	0.0	0.1	2881
11	0.012882321255540197	0.013034016127211983	50	0.002	100	50	0.0	0.1	2881
12	0.01286472484305569	0.01300036868019952	50	0.002	100	50	0.0	0.1	2881
13	0.012858117674633228	0.012936256484023472	50	0.002	100	50	0.0	0.1	2881
14	0.012851194790826173	0.013151334048414436	50	0.002	100	50	0.0	0.1	2881
15	0.012844563909741704	0.012950438071206126	50	0.002	100	50	0.0	0.1	2881
16	0.01282572466583263	0.012906827297895064	50	0.002	100	50	0.0	0.1	2881
17	0.012819050355117562	0.012949636585326656	50	0.002	100	50	0.0	0.1	2881
18	0.0127991058941961	0.012921511350523673	50	0.002	100	50	0.0	0.1	2881
19	0.012804523906263373	0.012941876317714528	50	0.002	100	50	0.0	0.1	2881
20	0.012787293340497509	0.012962851003809596	50	0.002	100	50	0.0	0.1	2881
21	0.012808048413486843	0.012968087933929085	50	0.002	100	50	0.0	0.1	2881
22	0.012795970667540254	0.012892254282779151	50	0.002	100	50	0.0	0.1	2881
23	0.012787580391666968	0.012891493597019812	50	0.002	100	50	0.0	0.1	2881
24	0.012771974098478349	0.012941300010675455	50	0.002	100	50	0.0	0.1	2881
25	0.01278527430815229	0.012918786054929401	50	0.002	100	50	0.0	0.1	2881
26	0.012751835336835285	0.01302662374270122	50	0.002	100	50	0.0	0.1	2881
27	0.01278345678816908	0.012875938401637638	50	0.002	100	50	0.0	0.1	2881
28	0.012754122326604672	0.012854447898171828	50	0.002	100	50	0.0	0.1	2881
29	0.012744603827686735	0.013025346605630723	50	0.002	100	50	0.0	0.1	2881
30	0.01278731672002841	0.012883925929765287	50	0.002	100	50	0.0	0.1	2881
31	0.012756672766782691	0.012957134378457844	50	0.002	100	50	0.0	0.1	2881
32	0.012776629943873555	0.012885713648855913	50	0.002	100	50	0.0	0.1	2881
33	0.012727458563074352	0.012882158507452298	50	0.002	100	50	0.0	0.1	2881
34	0.012758315540256523	0.012843895817520969	50	0.002	100	50	0.0	0.1	2881
35	0.01273329675062647	0.012842103233471883	50	0.002	100	50	0.0	0.1	2881
36	0.012719293562486621	0.013181816448188648	50	0.002	100	50	0.0	0.1	2881
37	0.01275851841650695	0.012872233620023864	50	0.002	100	50	0.0	0.1	2881
38	0.012738172369251738	0.012872029736951477	50	0.002	100	50	0.0	0.1	2881
39	0.012731229220150407	0.012864836550408522	50	0.002	100	50	0.0	0.1	2881
40	0.01272481467868093	0.012883131976380061	50	0.002	100	50	0.0	0.1	2881
41	0.012721845133846091	0.012900544139939444	50	0.002	100	50	0.0	0.1	2881
42	0.012713966695861913	0.012845548432512675	50	0.002	100	50	0.0	0.1	2881
43	0.012727821104898914	0.012821900880900898	50	0.002	100	50	0.0	0.1	2881
44	0.012721835121806859	0.012930681574626703	50	0.002	100	50	0.0	0.1	2881
45	0.01272085428706495	0.012796104796601185	50	0.002	100	50	0.0	0.1	2881
46	0.012677341894512095	0.012815346510414867	50	0.002	100	50	0.0	0.1	2881
47	0.012724421972017681	0.012929863214535535	50	0.002	100	50	0.0	0.1	2881
48	0.012713137341088004	0.012856584519546757	50	0.002	100	50	0.0	0.1	2881
49	0.012688836761149022	0.012807749129874528	50	0.002	100	50	0.0	0.1	2881
