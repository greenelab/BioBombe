	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.03166567676563224	0.022757518805036354	25	0.001	50	50	0.0	0.1	3778
1	0.02063217668859495	0.018131075042298144	25	0.001	50	50	0.0	0.1	3778
2	0.01820165748768996	0.01731088000704066	25	0.001	50	50	0.0	0.1	3778
3	0.01783788253069494	0.017151429536921572	25	0.001	50	50	0.0	0.1	3778
4	0.017724559251660308	0.01712237614568458	25	0.001	50	50	0.0	0.1	3778
5	0.017669498788256785	0.017170604816985176	25	0.001	50	50	0.0	0.1	3778
6	0.017626152372663066	0.01706192615383214	25	0.001	50	50	0.0	0.1	3778
7	0.017584171839130427	0.01699396986407486	25	0.001	50	50	0.0	0.1	3778
8	0.017560171862177867	0.017016385646312575	25	0.001	50	50	0.0	0.1	3778
9	0.017524181888802365	0.016952242290896737	25	0.001	50	50	0.0	0.1	3778
10	0.017498505240727547	0.016938942318949598	25	0.001	50	50	0.0	0.1	3778
11	0.017474499833154196	0.01687375309184393	25	0.001	50	50	0.0	0.1	3778
12	0.017447498427642833	0.016858653836735803	25	0.001	50	50	0.0	0.1	3778
13	0.01742478746297106	0.01681938173381138	25	0.001	50	50	0.0	0.1	3778
14	0.017405969259155697	0.016836920778051618	25	0.001	50	50	0.0	0.1	3778
15	0.017383639472752926	0.01682791350512671	25	0.001	50	50	0.0	0.1	3778
16	0.01736605014823378	0.016764802186897677	25	0.001	50	50	0.0	0.1	3778
17	0.017346566203618727	0.01675832168471574	25	0.001	50	50	0.0	0.1	3778
18	0.017327660626647614	0.016733276976511082	25	0.001	50	50	0.0	0.1	3778
19	0.017307555184051637	0.016720791203085596	25	0.001	50	50	0.0	0.1	3778
20	0.01729386694490685	0.016756538280337536	25	0.001	50	50	0.0	0.1	3778
21	0.017287234315156153	0.016723651479908317	25	0.001	50	50	0.0	0.1	3778
22	0.017272075015446413	0.0166590115764173	25	0.001	50	50	0.0	0.1	3778
23	0.017256250990259653	0.01665224629431165	25	0.001	50	50	0.0	0.1	3778
24	0.017239674606227818	0.016700142194974604	25	0.001	50	50	0.0	0.1	3778
25	0.017226230839506213	0.016665916245281128	25	0.001	50	50	0.0	0.1	3778
26	0.017210697076291012	0.016632865613992423	25	0.001	50	50	0.0	0.1	3778
27	0.01720134748513401	0.016656715041792187	25	0.001	50	50	0.0	0.1	3778
28	0.017194803770321673	0.016640632813992282	25	0.001	50	50	0.0	0.1	3778
29	0.017183637858532597	0.016636865519799194	25	0.001	50	50	0.0	0.1	3778
30	0.017181865023432243	0.016679752829981465	25	0.001	50	50	0.0	0.1	3778
31	0.01716943867769756	0.016628666588570033	25	0.001	50	50	0.0	0.1	3778
32	0.017164957849214856	0.01665912933619141	25	0.001	50	50	0.0	0.1	3778
33	0.017163620457333384	0.01659166349372319	25	0.001	50	50	0.0	0.1	3778
34	0.017157398676385945	0.016650479156915705	25	0.001	50	50	0.0	0.1	3778
35	0.01714374133661068	0.016610244702170273	25	0.001	50	50	0.0	0.1	3778
36	0.017139734578625904	0.01662243116846447	25	0.001	50	50	0.0	0.1	3778
37	0.01713009563812025	0.016564873036488636	25	0.001	50	50	0.0	0.1	3778
38	0.017120952388192737	0.01659120392966054	25	0.001	50	50	0.0	0.1	3778
39	0.017144556937433133	0.01656747970687329	25	0.001	50	50	0.0	0.1	3778
40	0.01712246835239696	0.016563471356837747	25	0.001	50	50	0.0	0.1	3778
41	0.01710187051808158	0.01655880337577477	25	0.001	50	50	0.0	0.1	3778
42	0.017112689813632433	0.01655696924547905	25	0.001	50	50	0.0	0.1	3778
43	0.017109603197503317	0.016576700591006768	25	0.001	50	50	0.0	0.1	3778
44	0.017106890240695036	0.01655820841201177	25	0.001	50	50	0.0	0.1	3778
45	0.017111577152371608	0.01668141128221103	25	0.001	50	50	0.0	0.1	3778
46	0.01710449337178059	0.016553129860151908	25	0.001	50	50	0.0	0.1	3778
47	0.01709890152899293	0.01659365409333437	25	0.001	50	50	0.0	0.1	3778
48	0.017094342096212134	0.016570971194248697	25	0.001	50	50	0.0	0.1	3778
49	0.01709103362268106	0.01653619000000833	25	0.001	50	50	0.0	0.1	3778
