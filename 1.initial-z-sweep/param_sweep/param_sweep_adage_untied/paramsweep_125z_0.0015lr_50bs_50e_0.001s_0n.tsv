	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	1.3964410404951049	1.5421415783935022	125	0.0015	50	50	0.001	0.0	7122
1	1.0562081381426878	1.371277303814204	125	0.0015	50	50	0.001	0.0	7122
2	1.0396096179174539	1.6160807584485406	125	0.0015	50	50	0.001	0.0	7122
3	1.0454607588172427	1.3474556681758816	125	0.0015	50	50	0.001	0.0	7122
4	1.0346214951515755	1.3833019345941782	125	0.0015	50	50	0.001	0.0	7122
5	1.042494697017623	1.3777946671381962	125	0.0015	50	50	0.001	0.0	7122
6	1.032748984448983	1.380872751057262	125	0.0015	50	50	0.001	0.0	7122
7	1.0568277531648864	1.5083726769879489	125	0.0015	50	50	0.001	0.0	7122
8	1.0198444675958513	1.7443767578606395	125	0.0015	50	50	0.001	0.0	7122
9	1.0625390743716647	1.3688082501263736	125	0.0015	50	50	0.001	0.0	7122
10	1.055300558064856	1.6405272989838346	125	0.0015	50	50	0.001	0.0	7122
11	1.0724159952185428	1.508381305643523	125	0.0015	50	50	0.001	0.0	7122
12	1.0263869754695416	1.4505102848687546	125	0.0015	50	50	0.001	0.0	7122
13	1.0337371683539918	1.5746608548592882	125	0.0015	50	50	0.001	0.0	7122
14	1.0537181874238684	1.506828558832464	125	0.0015	50	50	0.001	0.0	7122
15	1.0405089999219126	1.430226826758959	125	0.0015	50	50	0.001	0.0	7122
16	1.0682660339363168	1.405655203084417	125	0.0015	50	50	0.001	0.0	7122
17	1.0749563267174504	1.6575085891136476	125	0.0015	50	50	0.001	0.0	7122
18	1.0439961157809607	1.616995889643638	125	0.0015	50	50	0.001	0.0	7122
19	1.0711545223170533	1.4799289682855115	125	0.0015	50	50	0.001	0.0	7122
20	1.0647271628475057	1.3451144629181229	125	0.0015	50	50	0.001	0.0	7122
21	1.0772023417770349	1.3385387727452966	125	0.0015	50	50	0.001	0.0	7122
22	1.0572525977132223	1.6851428067934902	125	0.0015	50	50	0.001	0.0	7122
23	1.0723184202272833	1.608710181188857	125	0.0015	50	50	0.001	0.0	7122
24	1.0617690584484303	1.422957036964752	125	0.0015	50	50	0.001	0.0	7122
25	1.0652839528232683	1.5403030780259783	125	0.0015	50	50	0.001	0.0	7122
26	1.0944085749875192	1.4493948791040745	125	0.0015	50	50	0.001	0.0	7122
27	1.1045678777432804	1.4650338409507708	125	0.0015	50	50	0.001	0.0	7122
28	1.0645022034094183	1.4924836600943687	125	0.0015	50	50	0.001	0.0	7122
29	1.0422677989943456	1.699302519028775	125	0.0015	50	50	0.001	0.0	7122
30	1.1321360881088214	1.7566604639330512	125	0.0015	50	50	0.001	0.0	7122
31	1.1254447826661125	1.4665603072419906	125	0.0015	50	50	0.001	0.0	7122
32	1.1047411211255278	1.3494202135625806	125	0.0015	50	50	0.001	0.0	7122
33	1.045652757804933	1.527820371760921	125	0.0015	50	50	0.001	0.0	7122
34	1.1059528688980216	1.433547588652908	125	0.0015	50	50	0.001	0.0	7122
35	1.0979145336712153	1.7037046862833813	125	0.0015	50	50	0.001	0.0	7122
36	1.1106560753038455	1.4142250481344774	125	0.0015	50	50	0.001	0.0	7122
37	1.1099538752886537	1.5522227289571817	125	0.0015	50	50	0.001	0.0	7122
38	1.13188682808565	1.4844143206029277	125	0.0015	50	50	0.001	0.0	7122
39	1.0809875144552479	1.4818731628458086	125	0.0015	50	50	0.001	0.0	7122
40	1.069616901397097	1.3974839733845874	125	0.0015	50	50	0.001	0.0	7122
41	1.0714134218923776	1.6425255603133835	125	0.0015	50	50	0.001	0.0	7122
42	1.1196809569574575	1.419509961773743	125	0.0015	50	50	0.001	0.0	7122
43	1.0771012835012261	1.6541358159559407	125	0.0015	50	50	0.001	0.0	7122
44	1.097473211826306	1.5242922768766065	125	0.0015	50	50	0.001	0.0	7122
45	1.127829874624396	1.6191035133019005	125	0.0015	50	50	0.001	0.0	7122
46	1.0846916755593496	1.6321394664607587	125	0.0015	50	50	0.001	0.0	7122
47	1.1118356860001866	1.5794726448350838	125	0.0015	50	50	0.001	0.0	7122
48	1.1154745584984052	1.429879700020668	125	0.0015	50	50	0.001	0.0	7122
49	1.1062468552163895	1.6300387293613208	125	0.0015	50	50	0.001	0.0	7122
