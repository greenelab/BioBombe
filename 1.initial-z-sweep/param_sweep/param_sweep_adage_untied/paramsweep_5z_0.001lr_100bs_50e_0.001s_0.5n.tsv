	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.3213174696546691	0.1829340062451408	5	0.001	100	50	0.001	0.5	3748
1	0.2616346716139935	0.1693062557203136	5	0.001	100	50	0.001	0.5	3748
2	0.21470781349054904	0.14564957018108257	5	0.001	100	50	0.001	0.5	3748
3	0.17220972703973025	0.14252891800371684	5	0.001	100	50	0.001	0.5	3748
4	0.1427808263925124	0.13808527560352596	5	0.001	100	50	0.001	0.5	3748
5	0.12366575527685704	0.14038112172661046	5	0.001	100	50	0.001	0.5	3748
6	0.11640898923868583	0.14012380311867476	5	0.001	100	50	0.001	0.5	3748
7	0.10642930061340611	0.13034959334032487	5	0.001	100	50	0.001	0.5	3748
8	0.10875042952722994	0.1794856351659585	5	0.001	100	50	0.001	0.5	3748
9	0.10577973143860396	0.12092543728151012	5	0.001	100	50	0.001	0.5	3748
10	0.09619429486772149	0.11887028041236943	5	0.001	100	50	0.001	0.5	3748
11	0.0975434275760156	0.12170482730318438	5	0.001	100	50	0.001	0.5	3748
12	0.09032701751266518	0.1119941542811877	5	0.001	100	50	0.001	0.5	3748
13	0.10699127581650046	0.09366593052620642	5	0.001	100	50	0.001	0.5	3748
14	0.09162596950791702	0.15349627270525318	5	0.001	100	50	0.001	0.5	3748
15	0.0967395248129595	0.15014651084379302	5	0.001	100	50	0.001	0.5	3748
16	0.10769029885085638	0.08076169135950036	5	0.001	100	50	0.001	0.5	3748
17	0.08616377038765027	0.14419265929075317	5	0.001	100	50	0.001	0.5	3748
18	0.08596867250497646	0.1292978367887537	5	0.001	100	50	0.001	0.5	3748
19	0.07980966725030791	0.11953388648837748	5	0.001	100	50	0.001	0.5	3748
20	0.08406734735748789	0.10593198611620051	5	0.001	100	50	0.001	0.5	3748
21	0.08938893912468708	0.09492760170144288	5	0.001	100	50	0.001	0.5	3748
22	0.0850921993827631	0.10566828694785758	5	0.001	100	50	0.001	0.5	3748
23	0.08693912478723245	0.12732825133358316	5	0.001	100	50	0.001	0.5	3748
24	0.08342337238539117	0.09774457386928125	5	0.001	100	50	0.001	0.5	3748
25	0.08274758288443475	0.13960207802159835	5	0.001	100	50	0.001	0.5	3748
26	0.09124220963450747	0.10366899775159519	5	0.001	100	50	0.001	0.5	3748
27	0.08716210289249306	0.10109722591494967	5	0.001	100	50	0.001	0.5	3748
28	0.07845830947752779	0.073824802345915	5	0.001	100	50	0.001	0.5	3748
29	0.08759929002254242	0.0650009713126756	5	0.001	100	50	0.001	0.5	3748
30	0.07760141038997867	0.12669501202911082	5	0.001	100	50	0.001	0.5	3748
31	0.07745896893081788	0.07116599996390807	5	0.001	100	50	0.001	0.5	3748
32	0.07586796834635884	0.07972850151231822	5	0.001	100	50	0.001	0.5	3748
33	0.09755958668419827	0.14648923071290065	5	0.001	100	50	0.001	0.5	3748
34	0.10345804629853146	0.11397640803120104	5	0.001	100	50	0.001	0.5	3748
35	0.08660369784053082	0.0799064011122483	5	0.001	100	50	0.001	0.5	3748
36	0.08031090553606543	0.08577317311419584	5	0.001	100	50	0.001	0.5	3748
37	0.07531289415034087	0.0685883489923541	5	0.001	100	50	0.001	0.5	3748
38	0.08350020029386084	0.16304724236120458	5	0.001	100	50	0.001	0.5	3748
39	0.10133687295253126	0.06326095578946302	5	0.001	100	50	0.001	0.5	3748
40	0.07515217354296562	0.07816776460887825	5	0.001	100	50	0.001	0.5	3748
41	0.08201889708459308	0.10835131732159317	5	0.001	100	50	0.001	0.5	3748
42	0.08411951889606005	0.06931869067379895	5	0.001	100	50	0.001	0.5	3748
43	0.06993496290801955	0.10887964688113269	5	0.001	100	50	0.001	0.5	3748
44	0.09194465889904636	0.07671357996149228	5	0.001	100	50	0.001	0.5	3748
45	0.09161216159733375	0.05604000959410038	5	0.001	100	50	0.001	0.5	3748
46	0.07389184930404846	0.1256137764505173	5	0.001	100	50	0.001	0.5	3748
47	0.07744061805740826	0.08907147093781094	5	0.001	100	50	0.001	0.5	3748
48	0.08049927240093735	0.10960015077606898	5	0.001	100	50	0.001	0.5	3748
49	0.08648747460682941	0.10075475657305344	5	0.001	100	50	0.001	0.5	3748
