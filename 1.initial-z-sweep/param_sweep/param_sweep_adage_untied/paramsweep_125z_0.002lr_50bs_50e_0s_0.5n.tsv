	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.02349246257252601	0.015186239660754943	125	0.002	50	50	0.0	0.5	1726
1	0.014663953082290697	0.01299980560221476	125	0.002	50	50	0.0	0.5	1726
2	0.013394421071184564	0.012433871904648057	125	0.002	50	50	0.0	0.5	1726
3	0.012986457242083185	0.012155839623117653	125	0.002	50	50	0.0	0.5	1726
4	0.012799100801653421	0.011911723937262312	125	0.002	50	50	0.0	0.5	1726
5	0.012738468861774292	0.0119152694894268	125	0.002	50	50	0.0	0.5	1726
6	0.012721694586585827	0.012226612837789277	125	0.002	50	50	0.0	0.5	1726
7	0.012643469284939314	0.011706867273077796	125	0.002	50	50	0.0	0.5	1726
8	0.012628567457384313	0.011849376695305393	125	0.002	50	50	0.0	0.5	1726
9	0.01262843240878413	0.012005036390505831	125	0.002	50	50	0.0	0.5	1726
10	0.012627709250409198	0.011785171662473315	125	0.002	50	50	0.0	0.5	1726
11	0.012609931717994906	0.01184857613184484	125	0.002	50	50	0.0	0.5	1726
12	0.012604856366048448	0.011777938498508177	125	0.002	50	50	0.0	0.5	1726
13	0.012579182560520909	0.011957681823315287	125	0.002	50	50	0.0	0.5	1726
14	0.012574348475340415	0.011825347817850159	125	0.002	50	50	0.0	0.5	1726
15	0.01255948849645315	0.011872251820795052	125	0.002	50	50	0.0	0.5	1726
16	0.012538934039528021	0.011979119693700146	125	0.002	50	50	0.0	0.5	1726
17	0.012519126360735142	0.01192729749732845	125	0.002	50	50	0.0	0.5	1726
18	0.012505546543348655	0.011864980835873585	125	0.002	50	50	0.0	0.5	1726
19	0.012519626004759308	0.011679486330619961	125	0.002	50	50	0.0	0.5	1726
20	0.012484446340893048	0.0117474343364143	125	0.002	50	50	0.0	0.5	1726
21	0.012492172630767151	0.011768469782848887	125	0.002	50	50	0.0	0.5	1726
22	0.012465318168922001	0.011756791339663657	125	0.002	50	50	0.0	0.5	1726
23	0.012480014569552403	0.011806404191366688	125	0.002	50	50	0.0	0.5	1726
24	0.012485632028014757	0.011759688979794715	125	0.002	50	50	0.0	0.5	1726
25	0.012460294961541477	0.011681109419302662	125	0.002	50	50	0.0	0.5	1726
26	0.012486490405760378	0.011864315307063424	125	0.002	50	50	0.0	0.5	1726
27	0.01245279786280174	0.01179654718364231	125	0.002	50	50	0.0	0.5	1726
28	0.012476447116416179	0.011707701875220976	125	0.002	50	50	0.0	0.5	1726
29	0.012445726611383452	0.01166578193674181	125	0.002	50	50	0.0	0.5	1726
30	0.012487552760662225	0.0117127903065792	125	0.002	50	50	0.0	0.5	1726
31	0.012463956511501588	0.011801580528071573	125	0.002	50	50	0.0	0.5	1726
32	0.012439832685862169	0.011736899997191378	125	0.002	50	50	0.0	0.5	1726
33	0.0124300149670406	0.0117277648250072	125	0.002	50	50	0.0	0.5	1726
34	0.012452869492915514	0.011829783011007036	125	0.002	50	50	0.0	0.5	1726
35	0.01243305786404057	0.011745184672423007	125	0.002	50	50	0.0	0.5	1726
36	0.012475430286101286	0.01175258353523497	125	0.002	50	50	0.0	0.5	1726
37	0.01243389057901604	0.011863399902447688	125	0.002	50	50	0.0	0.5	1726
38	0.012444553272572085	0.01169943835151811	125	0.002	50	50	0.0	0.5	1726
39	0.012440837498326446	0.011909597635226428	125	0.002	50	50	0.0	0.5	1726
40	0.012485439507917011	0.011757830668945955	125	0.002	50	50	0.0	0.5	1726
41	0.012420810820311419	0.01185326827387281	125	0.002	50	50	0.0	0.5	1726
42	0.012450784321034972	0.011735895614764772	125	0.002	50	50	0.0	0.5	1726
43	0.012427405578388135	0.01170248718109573	125	0.002	50	50	0.0	0.5	1726
44	0.012477514161867334	0.011822797856640862	125	0.002	50	50	0.0	0.5	1726
45	0.012431666212749857	0.011773306491782971	125	0.002	50	50	0.0	0.5	1726
46	0.012471010583961136	0.01169834743444425	125	0.002	50	50	0.0	0.5	1726
47	0.012406890746453396	0.011751488843010329	125	0.002	50	50	0.0	0.5	1726
48	0.012411330810849058	0.011743311041941151	125	0.002	50	50	0.0	0.5	1726
49	0.012427252206785555	0.01172984360644227	125	0.002	50	50	0.0	0.5	1726
