	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	1.2461711275112763	0.4973946731701408	50	0.0005	50	50	0.001	0.5	6630
1	0.9851959584167859	0.40366213345618823	50	0.0005	50	50	0.001	0.5	6630
2	0.7748536933298561	0.39894934257859255	50	0.0005	50	50	0.001	0.5	6630
3	0.5902497236152188	0.318459488921594	50	0.0005	50	50	0.001	0.5	6630
4	0.4439429129495335	0.31968835959243047	50	0.0005	50	50	0.001	0.5	6630
5	0.3345246317915236	0.3268343261505404	50	0.0005	50	50	0.001	0.5	6630
6	0.27160799336394786	0.24342460511519393	50	0.0005	50	50	0.001	0.5	6630
7	0.2285726755203672	0.2501006280543927	50	0.0005	50	50	0.001	0.5	6630
8	0.21348152574419685	0.2292499998103592	50	0.0005	50	50	0.001	0.5	6630
9	0.19987123620493638	0.21274414219774207	50	0.0005	50	50	0.001	0.5	6630
10	0.19262358755851594	0.23243808273375605	50	0.0005	50	50	0.001	0.5	6630
11	0.19374357005602036	0.22631870663188838	50	0.0005	50	50	0.001	0.5	6630
12	0.18656144907044436	0.23942342614238624	50	0.0005	50	50	0.001	0.5	6630
13	0.18299738024311468	0.1806403655224047	50	0.0005	50	50	0.001	0.5	6630
14	0.17651761969806512	0.1960315112003177	50	0.0005	50	50	0.001	0.5	6630
15	0.1764907568414546	0.24599825444116646	50	0.0005	50	50	0.001	0.5	6630
16	0.17971436428767923	0.21863953868927966	50	0.0005	50	50	0.001	0.5	6630
17	0.17569576481171803	0.18135333725074965	50	0.0005	50	50	0.001	0.5	6630
18	0.17017548264393223	0.20035390997480024	50	0.0005	50	50	0.001	0.5	6630
19	0.1738875550164004	0.18789326608978768	50	0.0005	50	50	0.001	0.5	6630
20	0.167339431432815	0.20020318871816303	50	0.0005	50	50	0.001	0.5	6630
21	0.16866584181149202	0.23426105161811836	50	0.0005	50	50	0.001	0.5	6630
22	0.16823797429277884	0.22470928569026932	50	0.0005	50	50	0.001	0.5	6630
23	0.17018364427175303	0.18598412661092004	50	0.0005	50	50	0.001	0.5	6630
24	0.16855834237301145	0.20208793887102808	50	0.0005	50	50	0.001	0.5	6630
25	0.17178129115007668	0.21520913484903412	50	0.0005	50	50	0.001	0.5	6630
26	0.17140850040245978	0.1897780159862274	50	0.0005	50	50	0.001	0.5	6630
27	0.1705675506421145	0.20610218288565685	50	0.0005	50	50	0.001	0.5	6630
28	0.17124933693001934	0.18221083135267516	50	0.0005	50	50	0.001	0.5	6630
29	0.1660605487399358	0.18794263916421347	50	0.0005	50	50	0.001	0.5	6630
30	0.17066628223449914	0.16503271132878547	50	0.0005	50	50	0.001	0.5	6630
31	0.16280384629831854	0.22500652373976734	50	0.0005	50	50	0.001	0.5	6630
32	0.1703204297793351	0.19215317104674207	50	0.0005	50	50	0.001	0.5	6630
33	0.16769677609392045	0.219036531493951	50	0.0005	50	50	0.001	0.5	6630
34	0.16979720398607967	0.2089626001867236	50	0.0005	50	50	0.001	0.5	6630
35	0.1655640147842485	0.19830094166741088	50	0.0005	50	50	0.001	0.5	6630
36	0.1692106005726098	0.19124176115310443	50	0.0005	50	50	0.001	0.5	6630
37	0.16699971219855794	0.1804688908515879	50	0.0005	50	50	0.001	0.5	6630
38	0.16680912387734528	0.19315001801596546	50	0.0005	50	50	0.001	0.5	6630
39	0.1677542383196148	0.21597881555329318	50	0.0005	50	50	0.001	0.5	6630
40	0.16818188158083858	0.20195619576747742	50	0.0005	50	50	0.001	0.5	6630
41	0.1635614212265585	0.19234290753222333	50	0.0005	50	50	0.001	0.5	6630
42	0.16668509194958062	0.2063885326595197	50	0.0005	50	50	0.001	0.5	6630
43	0.16643832375500364	0.16398870244080888	50	0.0005	50	50	0.001	0.5	6630
44	0.16797095697626835	0.18115342295876424	50	0.0005	50	50	0.001	0.5	6630
45	0.16563456732940815	0.17447701825922352	50	0.0005	50	50	0.001	0.5	6630
46	0.16611240008559197	0.21406645765154128	50	0.0005	50	50	0.001	0.5	6630
47	0.16913997212619392	0.20110569256099642	50	0.0005	50	50	0.001	0.5	6630
48	0.16676961406661717	0.20806337152224882	50	0.0005	50	50	0.001	0.5	6630
49	0.16289525129780383	0.18544430594827202	50	0.0005	50	50	0.001	0.5	6630
