	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.13794965058261197	0.1121714437526453	5	0.002	50	50	0.001	0.0	5981
1	0.10486188723894585	0.08587294043421062	5	0.002	50	50	0.001	0.0	5981
2	0.09461936786569775	0.0876840335489687	5	0.002	50	50	0.001	0.0	5981
3	0.09927241085517689	0.1751449397884409	5	0.002	50	50	0.001	0.0	5981
4	0.09980130730606247	0.1037514335395729	5	0.002	50	50	0.001	0.0	5981
5	0.08365549382052284	0.08035491231693592	5	0.002	50	50	0.001	0.0	5981
6	0.08871797151237483	0.10630101945614495	5	0.002	50	50	0.001	0.0	5981
7	0.0980969170767576	0.07434409571879225	5	0.002	50	50	0.001	0.0	5981
8	0.09784418624141804	0.17206769495005816	5	0.002	50	50	0.001	0.0	5981
9	0.0961719015501396	0.1395378286592363	5	0.002	50	50	0.001	0.0	5981
10	0.10198855804354443	0.09388108929017305	5	0.002	50	50	0.001	0.0	5981
11	0.09118572149802114	0.13031753728141293	5	0.002	50	50	0.001	0.0	5981
12	0.08972895277125238	0.13807331866105702	5	0.002	50	50	0.001	0.0	5981
13	0.09585801418920158	0.10637620404847037	5	0.002	50	50	0.001	0.0	5981
14	0.08025936119224368	0.07217968862154743	5	0.002	50	50	0.001	0.0	5981
15	0.09769935717393244	0.12958035058204803	5	0.002	50	50	0.001	0.0	5981
16	0.08567879587597096	0.09611069019278422	5	0.002	50	50	0.001	0.0	5981
17	0.09804410665030562	0.07412555706945477	5	0.002	50	50	0.001	0.0	5981
18	0.0865060026759101	0.08345174920490549	5	0.002	50	50	0.001	0.0	5981
19	0.0777814258446029	0.07150110183550797	5	0.002	50	50	0.001	0.0	5981
20	0.08630615943431551	0.13786947744298392	5	0.002	50	50	0.001	0.0	5981
21	0.08460068670007966	0.09949734406706025	5	0.002	50	50	0.001	0.0	5981
22	0.09837551031395846	0.08527732951064411	5	0.002	50	50	0.001	0.0	5981
23	0.0808366900358401	0.09484911194324037	5	0.002	50	50	0.001	0.0	5981
24	0.09166344344571611	0.09685365858542988	5	0.002	50	50	0.001	0.0	5981
25	0.10195263425234741	0.14719316918922884	5	0.002	50	50	0.001	0.0	5981
26	0.0905251170255376	0.16882318984823974	5	0.002	50	50	0.001	0.0	5981
27	0.09155785644850999	0.08347765370548113	5	0.002	50	50	0.001	0.0	5981
28	0.09103466885244126	0.09942742582431943	5	0.002	50	50	0.001	0.0	5981
29	0.09257050868075091	0.12740264445486305	5	0.002	50	50	0.001	0.0	5981
30	0.09750831963249643	0.08389670035693203	5	0.002	50	50	0.001	0.0	5981
31	0.09215112623196536	0.10699464410657408	5	0.002	50	50	0.001	0.0	5981
32	0.10057421279684284	0.16253545925904414	5	0.002	50	50	0.001	0.0	5981
33	0.09671915810118696	0.20488076293787583	5	0.002	50	50	0.001	0.0	5981
34	0.09495777474702652	0.07022194542973721	5	0.002	50	50	0.001	0.0	5981
35	0.09509924147545208	0.1782793004642709	5	0.002	50	50	0.001	0.0	5981
36	0.10738084708499462	0.14386061814045586	5	0.002	50	50	0.001	0.0	5981
37	0.09007981072719097	0.1271466986484555	5	0.002	50	50	0.001	0.0	5981
38	0.10493577538600551	0.11437429416475971	5	0.002	50	50	0.001	0.0	5981
39	0.08930437585967615	0.1265000868766759	5	0.002	50	50	0.001	0.0	5981
40	0.09059260227557869	0.11336756460582322	5	0.002	50	50	0.001	0.0	5981
41	0.09751474378737572	0.10959483214420752	5	0.002	50	50	0.001	0.0	5981
42	0.09324201623892653	0.10690877880067716	5	0.002	50	50	0.001	0.0	5981
43	0.09021824389984234	0.1533638762299463	5	0.002	50	50	0.001	0.0	5981
44	0.08906088694399758	0.09637539140011112	5	0.002	50	50	0.001	0.0	5981
45	0.08980678180132715	0.07957648874810731	5	0.002	50	50	0.001	0.0	5981
46	0.09377386407825958	0.10700277066709435	5	0.002	50	50	0.001	0.0	5981
47	0.08913572352313469	0.13572872442907402	5	0.002	50	50	0.001	0.0	5981
48	0.09785459998116082	0.16786273533254006	5	0.002	50	50	0.001	0.0	5981
49	0.1009730736111703	0.08000077076441471	5	0.002	50	50	0.001	0.0	5981
