	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.043068563504071136	0.03391517926698433	5	0.0005	50	50	1e-06	0.1	6282
1	0.02962785616297816	0.026608413334643862	5	0.0005	50	50	1e-06	0.1	6282
2	0.025552180449561538	0.02475896051748305	5	0.0005	50	50	1e-06	0.1	6282
3	0.024419530706129303	0.02410271298674507	5	0.0005	50	50	1e-06	0.1	6282
4	0.02396514732301596	0.023770124322056316	5	0.0005	50	50	1e-06	0.1	6282
5	0.023685053437726603	0.023514360616813425	5	0.0005	50	50	1e-06	0.1	6282
6	0.023474644551176923	0.023336384894173185	5	0.0005	50	50	1e-06	0.1	6282
7	0.023306551056660844	0.02317717888287445	5	0.0005	50	50	1e-06	0.1	6282
8	0.02316406362857339	0.023063590867626507	5	0.0005	50	50	1e-06	0.1	6282
9	0.023040147966038507	0.022887952173445695	5	0.0005	50	50	1e-06	0.1	6282
10	0.02291846562057819	0.022789679877246314	5	0.0005	50	50	1e-06	0.1	6282
11	0.02281078710854465	0.022691273922901992	5	0.0005	50	50	1e-06	0.1	6282
12	0.0227105175926102	0.022571269376470526	5	0.0005	50	50	1e-06	0.1	6282
13	0.02261421298411293	0.022465772143285545	5	0.0005	50	50	1e-06	0.1	6282
14	0.02252483815109104	0.02242486953493172	5	0.0005	50	50	1e-06	0.1	6282
15	0.022444712685342552	0.02232925041826232	5	0.0005	50	50	1e-06	0.1	6282
16	0.02237024938559654	0.02223128112421209	5	0.0005	50	50	1e-06	0.1	6282
17	0.022295360309271203	0.022174466458321985	5	0.0005	50	50	1e-06	0.1	6282
18	0.022222991523423028	0.02209603031794496	5	0.0005	50	50	1e-06	0.1	6282
19	0.022168197158063545	0.02208127997046333	5	0.0005	50	50	1e-06	0.1	6282
20	0.02209994279110956	0.0219816382418798	5	0.0005	50	50	1e-06	0.1	6282
21	0.022038596669882993	0.02192181799325729	5	0.0005	50	50	1e-06	0.1	6282
22	0.02198040440522667	0.021869756505748055	5	0.0005	50	50	1e-06	0.1	6282
23	0.021934112687481903	0.021816990895634856	5	0.0005	50	50	1e-06	0.1	6282
24	0.02188784101934213	0.021768950054112175	5	0.0005	50	50	1e-06	0.1	6282
25	0.021839693171055972	0.021812868680284994	5	0.0005	50	50	1e-06	0.1	6282
26	0.021798070603667973	0.021691403506647788	5	0.0005	50	50	1e-06	0.1	6282
27	0.021759154596614823	0.021641238537362384	5	0.0005	50	50	1e-06	0.1	6282
28	0.02172667171394902	0.021634313867322345	5	0.0005	50	50	1e-06	0.1	6282
29	0.02169826546240458	0.021592466659259842	5	0.0005	50	50	1e-06	0.1	6282
30	0.02165473035559364	0.021544868956332452	5	0.0005	50	50	1e-06	0.1	6282
31	0.021613464443097963	0.0215282103947825	5	0.0005	50	50	1e-06	0.1	6282
32	0.021585929626316974	0.021498647185459192	5	0.0005	50	50	1e-06	0.1	6282
33	0.021567124318148244	0.021513630766029794	5	0.0005	50	50	1e-06	0.1	6282
34	0.021540240170631008	0.021512519162198096	5	0.0005	50	50	1e-06	0.1	6282
35	0.021507975133348636	0.021397824789153457	5	0.0005	50	50	1e-06	0.1	6282
36	0.021503281640972274	0.021402775999123005	5	0.0005	50	50	1e-06	0.1	6282
37	0.021458007814773247	0.021405996199177282	5	0.0005	50	50	1e-06	0.1	6282
38	0.021442851438345862	0.021341135454707803	5	0.0005	50	50	1e-06	0.1	6282
39	0.021417347301329208	0.021308187801341028	5	0.0005	50	50	1e-06	0.1	6282
40	0.021415999736037302	0.02129314839483789	5	0.0005	50	50	1e-06	0.1	6282
41	0.02138329505394841	0.02127279409244799	5	0.0005	50	50	1e-06	0.1	6282
42	0.021373207366152763	0.021260156636313317	5	0.0005	50	50	1e-06	0.1	6282
43	0.021354330865086285	0.0213941239091224	5	0.0005	50	50	1e-06	0.1	6282
44	0.021347342287963474	0.021227350529732028	5	0.0005	50	50	1e-06	0.1	6282
45	0.02132602637713031	0.02131919727712357	5	0.0005	50	50	1e-06	0.1	6282
46	0.0213081191579733	0.021255947496336004	5	0.0005	50	50	1e-06	0.1	6282
47	0.021294387014483614	0.021419008509977144	5	0.0005	50	50	1e-06	0.1	6282
48	0.021293742718739208	0.02116604833854772	5	0.0005	50	50	1e-06	0.1	6282
49	0.021286700208214583	0.021146540236205262	5	0.0005	50	50	1e-06	0.1	6282
