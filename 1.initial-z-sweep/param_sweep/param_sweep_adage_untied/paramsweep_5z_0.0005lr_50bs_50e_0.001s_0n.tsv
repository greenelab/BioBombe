	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.11118811629510744	0.09848894230152408	5	0.0005	50	50	0.001	0.0	5924
1	0.09485813758220149	0.1012472338390396	5	0.0005	50	50	0.001	0.0	5924
2	0.08653486913675001	0.08989262867213207	5	0.0005	50	50	0.001	0.0	5924
3	0.08014474876844756	0.08721097991810701	5	0.0005	50	50	0.001	0.0	5924
4	0.07465300576746128	0.07948240016660088	5	0.0005	50	50	0.001	0.0	5924
5	0.06998163405605967	0.07551678630521604	5	0.0005	50	50	0.001	0.0	5924
6	0.06729744589451926	0.0689785580077773	5	0.0005	50	50	0.001	0.0	5924
7	0.06460269003660105	0.0625485173688336	5	0.0005	50	50	0.001	0.0	5924
8	0.06180585320640431	0.06466147058552583	5	0.0005	50	50	0.001	0.0	5924
9	0.06022394367783682	0.0704475257894733	5	0.0005	50	50	0.001	0.0	5924
10	0.059730208554161376	0.06657068073806525	5	0.0005	50	50	0.001	0.0	5924
11	0.0576420472086926	0.06691898838625811	5	0.0005	50	50	0.001	0.0	5924
12	0.05581229478025821	0.058050175932864614	5	0.0005	50	50	0.001	0.0	5924
13	0.05514291923267168	0.062036815624733954	5	0.0005	50	50	0.001	0.0	5924
14	0.0540918360200006	0.058391555125182265	5	0.0005	50	50	0.001	0.0	5924
15	0.05386319033691534	0.06169167376812512	5	0.0005	50	50	0.001	0.0	5924
16	0.05310498256247	0.06141007006396299	5	0.0005	50	50	0.001	0.0	5924
17	0.05199301382333822	0.05304683549026914	5	0.0005	50	50	0.001	0.0	5924
18	0.05183187995173657	0.05757320630248373	5	0.0005	50	50	0.001	0.0	5924
19	0.051989653982316274	0.058947060777170025	5	0.0005	50	50	0.001	0.0	5924
20	0.051019047703057714	0.055924149967345405	5	0.0005	50	50	0.001	0.0	5924
21	0.05106157256223235	0.0560728620744914	5	0.0005	50	50	0.001	0.0	5924
22	0.050336266565158876	0.057227433098205875	5	0.0005	50	50	0.001	0.0	5924
23	0.04974422604280933	0.056433444027121166	5	0.0005	50	50	0.001	0.0	5924
24	0.04958112403262843	0.07111562778514384	5	0.0005	50	50	0.001	0.0	5924
25	0.05093264993856795	0.058012428684569683	5	0.0005	50	50	0.001	0.0	5924
26	0.0501604516430779	0.05400908162129996	5	0.0005	50	50	0.001	0.0	5924
27	0.049784510839375504	0.05245041875008415	5	0.0005	50	50	0.001	0.0	5924
28	0.04806637827852739	0.05337376356210353	5	0.0005	50	50	0.001	0.0	5924
29	0.049490259925268995	0.05025818489534677	5	0.0005	50	50	0.001	0.0	5924
30	0.049667035480317104	0.05289279686618262	5	0.0005	50	50	0.001	0.0	5924
31	0.04853086450922683	0.05490611513531687	5	0.0005	50	50	0.001	0.0	5924
32	0.05000726092267616	0.05895230716119305	5	0.0005	50	50	0.001	0.0	5924
33	0.04780933943999684	0.05134232574450582	5	0.0005	50	50	0.001	0.0	5924
34	0.04856274672059176	0.05071349016054182	5	0.0005	50	50	0.001	0.0	5924
35	0.047360296106773524	0.05324981804673576	5	0.0005	50	50	0.001	0.0	5924
36	0.05056797638282213	0.0537699444173171	5	0.0005	50	50	0.001	0.0	5924
37	0.04782535626251133	0.04815460889676789	5	0.0005	50	50	0.001	0.0	5924
38	0.048279217043949926	0.05124033127784957	5	0.0005	50	50	0.001	0.0	5924
39	0.04729861360287471	0.05056978702317232	5	0.0005	50	50	0.001	0.0	5924
40	0.047140430442179145	0.04863007457118417	5	0.0005	50	50	0.001	0.0	5924
41	0.04837994946984711	0.05058598554698505	5	0.0005	50	50	0.001	0.0	5924
42	0.04933036750576884	0.053877195496518114	5	0.0005	50	50	0.001	0.0	5924
43	0.04885836392775626	0.06029789915475745	5	0.0005	50	50	0.001	0.0	5924
44	0.04790806757502078	0.05943220417882471	5	0.0005	50	50	0.001	0.0	5924
45	0.04893951095948561	0.0509419349836004	5	0.0005	50	50	0.001	0.0	5924
46	0.04879002391612898	0.053149811830905835	5	0.0005	50	50	0.001	0.0	5924
47	0.04839723771973268	0.056329946765537244	5	0.0005	50	50	0.001	0.0	5924
48	0.04914854773589671	0.0532655176309509	5	0.0005	50	50	0.001	0.0	5924
49	0.04768447200793915	0.05186490271504021	5	0.0005	50	50	0.001	0.0	5924
