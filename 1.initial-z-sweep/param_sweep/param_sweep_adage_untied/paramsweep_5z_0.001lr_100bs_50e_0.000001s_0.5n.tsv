	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.045750433930324394	0.03577842918824739	5	0.001	100	50	1e-06	0.5	3662
1	0.031646127506344955	0.029349125252171183	5	0.001	100	50	1e-06	0.5	3662
2	0.02759191306982881	0.026417076220846315	5	0.001	100	50	1e-06	0.5	3662
3	0.02613681463848629	0.025597575542661247	5	0.001	100	50	1e-06	0.5	3662
4	0.025575826525914547	0.02516188224275413	5	0.001	100	50	1e-06	0.5	3662
5	0.025230569281154948	0.02483724880372361	5	0.001	100	50	1e-06	0.5	3662
6	0.024967827532125002	0.024753358521379432	5	0.001	100	50	1e-06	0.5	3662
7	0.024771396231991028	0.02440811181529986	5	0.001	100	50	1e-06	0.5	3662
8	0.024571208247093114	0.024220982659073905	5	0.001	100	50	1e-06	0.5	3662
9	0.02440117123403889	0.024177501565753615	5	0.001	100	50	1e-06	0.5	3662
10	0.02426279131863312	0.023986668131860903	5	0.001	100	50	1e-06	0.5	3662
11	0.02411483029911011	0.023883172754290912	5	0.001	100	50	1e-06	0.5	3662
12	0.024004996884335217	0.023778713968926134	5	0.001	100	50	1e-06	0.5	3662
13	0.023869862661049013	0.023540095285464427	5	0.001	100	50	1e-06	0.5	3662
14	0.02374980631734098	0.023458773836521982	5	0.001	100	50	1e-06	0.5	3662
15	0.023630937816460203	0.02334937521650048	5	0.001	100	50	1e-06	0.5	3662
16	0.02353233716983028	0.023216405951099233	5	0.001	100	50	1e-06	0.5	3662
17	0.023456060257638904	0.02316856815214367	5	0.001	100	50	1e-06	0.5	3662
18	0.023360737404619535	0.023100122609968167	5	0.001	100	50	1e-06	0.5	3662
19	0.023265791202867737	0.02302509803773682	5	0.001	100	50	1e-06	0.5	3662
20	0.023203596009305036	0.02294918980955166	5	0.001	100	50	1e-06	0.5	3662
21	0.023108749983154105	0.022847065798240227	5	0.001	100	50	1e-06	0.5	3662
22	0.023051613114847838	0.022859742359238648	5	0.001	100	50	1e-06	0.5	3662
23	0.02299091344111362	0.022967297167127265	5	0.001	100	50	1e-06	0.5	3662
24	0.022966054644054528	0.022821864529902803	5	0.001	100	50	1e-06	0.5	3662
25	0.022899088909352647	0.022673712680062873	5	0.001	100	50	1e-06	0.5	3662
26	0.022857286666460478	0.022580458506599895	5	0.001	100	50	1e-06	0.5	3662
27	0.022784712324966715	0.022475181175947875	5	0.001	100	50	1e-06	0.5	3662
28	0.022698066052982205	0.02247564383492187	5	0.001	100	50	1e-06	0.5	3662
29	0.022672613545845408	0.022458105453113754	5	0.001	100	50	1e-06	0.5	3662
30	0.022621304864726955	0.02233835435107379	5	0.001	100	50	1e-06	0.5	3662
31	0.022597222908235858	0.022434429911964253	5	0.001	100	50	1e-06	0.5	3662
32	0.022575486261224652	0.02243449143623759	5	0.001	100	50	1e-06	0.5	3662
33	0.02254350698493365	0.022299015278399104	5	0.001	100	50	1e-06	0.5	3662
34	0.022476238065899767	0.022280974420460644	5	0.001	100	50	1e-06	0.5	3662
35	0.022496794221526402	0.02231725311017173	5	0.001	100	50	1e-06	0.5	3662
36	0.022425920471294165	0.022199053858650803	5	0.001	100	50	1e-06	0.5	3662
37	0.02238971654246176	0.022134222820344208	5	0.001	100	50	1e-06	0.5	3662
38	0.0223606116515657	0.022127985879493946	5	0.001	100	50	1e-06	0.5	3662
39	0.022347303951933028	0.02223188136962472	5	0.001	100	50	1e-06	0.5	3662
40	0.022315975465810503	0.02238398120804453	5	0.001	100	50	1e-06	0.5	3662
41	0.022301281699755423	0.021986129983946195	5	0.001	100	50	1e-06	0.5	3662
42	0.022232185096232503	0.022067186221423386	5	0.001	100	50	1e-06	0.5	3662
43	0.022231059402392037	0.02210788857939708	5	0.001	100	50	1e-06	0.5	3662
44	0.02219653240390479	0.02197578639490085	5	0.001	100	50	1e-06	0.5	3662
45	0.022189830973725396	0.022019406474314728	5	0.001	100	50	1e-06	0.5	3662
46	0.022152959028076673	0.022083649992315994	5	0.001	100	50	1e-06	0.5	3662
47	0.022160601342198043	0.021863606051465295	5	0.001	100	50	1e-06	0.5	3662
48	0.02214887225065445	0.022015081732809885	5	0.001	100	50	1e-06	0.5	3662
49	0.022138410667269157	0.021864134682979913	5	0.001	100	50	1e-06	0.5	3662
