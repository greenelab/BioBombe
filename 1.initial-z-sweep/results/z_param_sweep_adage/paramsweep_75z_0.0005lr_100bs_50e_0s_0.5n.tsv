	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.037871315669670856	0.025830909538565358	75	0.0005	100	50	0.0	0.5	4304
1	0.02229708779025829	0.019133764709102035	75	0.0005	100	50	0.0	0.5	4304
2	0.017990251717730624	0.016498305498271554	75	0.0005	100	50	0.0	0.5	4304
3	0.016157551633757452	0.01513513909513932	75	0.0005	100	50	0.0	0.5	4304
4	0.01504489731704101	0.014193688581624633	75	0.0005	100	50	0.0	0.5	4304
5	0.014313672133372648	0.013539764389082306	75	0.0005	100	50	0.0	0.5	4304
6	0.013796064808658411	0.013057741035580862	75	0.0005	100	50	0.0	0.5	4304
7	0.013380837408592455	0.012737723361223537	75	0.0005	100	50	0.0	0.5	4304
8	0.013037437700905824	0.012336112364741973	75	0.0005	100	50	0.0	0.5	4304
9	0.012746302821858175	0.012066620729692694	75	0.0005	100	50	0.0	0.5	4304
10	0.012508738718208207	0.011816115257460232	75	0.0005	100	50	0.0	0.5	4304
11	0.012285776234491211	0.011615475516830415	75	0.0005	100	50	0.0	0.5	4304
12	0.01209997695541326	0.011407811682578711	75	0.0005	100	50	0.0	0.5	4304
13	0.011955686787005428	0.011267854515142582	75	0.0005	100	50	0.0	0.5	4304
14	0.011827774317874755	0.011165871571599867	75	0.0005	100	50	0.0	0.5	4304
15	0.011715042682555141	0.011035643154701813	75	0.0005	100	50	0.0	0.5	4304
16	0.011619286905330248	0.010992886658836278	75	0.0005	100	50	0.0	0.5	4304
17	0.011532913556174638	0.010831171345770586	75	0.0005	100	50	0.0	0.5	4304
18	0.011465133995832462	0.010769102033263298	75	0.0005	100	50	0.0	0.5	4304
19	0.011396104657188854	0.010722400104167584	75	0.0005	100	50	0.0	0.5	4304
20	0.01133740273478715	0.010705159651204573	75	0.0005	100	50	0.0	0.5	4304
21	0.01130125492009393	0.010584288134273447	75	0.0005	100	50	0.0	0.5	4304
22	0.011254721785095399	0.010530913337694755	75	0.0005	100	50	0.0	0.5	4304
23	0.011218615851918006	0.010491147012330492	75	0.0005	100	50	0.0	0.5	4304
24	0.011188490457854975	0.010476138895060546	75	0.0005	100	50	0.0	0.5	4304
25	0.011161635185097276	0.010454106068035613	75	0.0005	100	50	0.0	0.5	4304
26	0.011128878779927007	0.01046958012616771	75	0.0005	100	50	0.0	0.5	4304
27	0.011109342416781055	0.010404300569675963	75	0.0005	100	50	0.0	0.5	4304
28	0.011097838111066653	0.010361639269935698	75	0.0005	100	50	0.0	0.5	4304
29	0.011082860602891674	0.010354402695869739	75	0.0005	100	50	0.0	0.5	4304
30	0.011074650084247033	0.010365503964799653	75	0.0005	100	50	0.0	0.5	4304
31	0.011054989586576454	0.010363461271669167	75	0.0005	100	50	0.0	0.5	4304
32	0.011041498370488404	0.010325896591090563	75	0.0005	100	50	0.0	0.5	4304
33	0.011037031012098188	0.010322215277737232	75	0.0005	100	50	0.0	0.5	4304
34	0.011022573555913188	0.01030233976418726	75	0.0005	100	50	0.0	0.5	4304
35	0.01101404757546727	0.010299390087520302	75	0.0005	100	50	0.0	0.5	4304
36	0.011010833125841278	0.010279053715315878	75	0.0005	100	50	0.0	0.5	4304
37	0.01100421680051833	0.010299183216380457	75	0.0005	100	50	0.0	0.5	4304
38	0.010997360969661026	0.010391144167425299	75	0.0005	100	50	0.0	0.5	4304
39	0.01100507003288729	0.010288305256522865	75	0.0005	100	50	0.0	0.5	4304
40	0.01099359706385738	0.010251610700119408	75	0.0005	100	50	0.0	0.5	4304
41	0.010989042026487759	0.010265191772998975	75	0.0005	100	50	0.0	0.5	4304
42	0.010974783703651562	0.010251703438835209	75	0.0005	100	50	0.0	0.5	4304
43	0.010979294888916627	0.010259927494405104	75	0.0005	100	50	0.0	0.5	4304
44	0.010968535056526294	0.01026520894459283	75	0.0005	100	50	0.0	0.5	4304
45	0.010958761848453114	0.010221119268475026	75	0.0005	100	50	0.0	0.5	4304
46	0.01096636699535357	0.01025129300693538	75	0.0005	100	50	0.0	0.5	4304
47	0.0109667138434083	0.010237797824078262	75	0.0005	100	50	0.0	0.5	4304
48	0.010964307434002842	0.010263320396923199	75	0.0005	100	50	0.0	0.5	4304
49	0.010963031720054634	0.010240839094450666	75	0.0005	100	50	0.0	0.5	4304
