	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.030284946991953297	0.01978478996336004	100	0.001	50	50	1e-06	0.5	1812
1	0.019468213730039246	0.016985047380680338	100	0.001	50	50	1e-06	0.5	1812
2	0.017607107837674062	0.016080723737097607	100	0.001	50	50	1e-06	0.5	1812
3	0.016589307980460544	0.014977319764390047	100	0.001	50	50	1e-06	0.5	1812
4	0.015880531763099313	0.014973067731933088	100	0.001	50	50	1e-06	0.5	1812
5	0.015355762105241606	0.014142463792179556	100	0.001	50	50	1e-06	0.5	1812
6	0.014994526036086864	0.0138756696537251	100	0.001	50	50	1e-06	0.5	1812
7	0.01479003912891251	0.013708291286834111	100	0.001	50	50	1e-06	0.5	1812
8	0.014533521917992034	0.013441445398541528	100	0.001	50	50	1e-06	0.5	1812
9	0.014391587225746605	0.013819487430653882	100	0.001	50	50	1e-06	0.5	1812
10	0.01421471253614471	0.01333630969124645	100	0.001	50	50	1e-06	0.5	1812
11	0.014082382925244183	0.013272540335744676	100	0.001	50	50	1e-06	0.5	1812
12	0.014052004484416422	0.013017939911161623	100	0.001	50	50	1e-06	0.5	1812
13	0.013912921112070716	0.013109823432439372	100	0.001	50	50	1e-06	0.5	1812
14	0.0138306761125666	0.012771004597241519	100	0.001	50	50	1e-06	0.5	1812
15	0.013834735347951597	0.012699978240902748	100	0.001	50	50	1e-06	0.5	1812
16	0.013729764224875717	0.013248328521961691	100	0.001	50	50	1e-06	0.5	1812
17	0.01364419659945754	0.013326044388500043	100	0.001	50	50	1e-06	0.5	1812
18	0.013671957371242145	0.013014627300046142	100	0.001	50	50	1e-06	0.5	1812
19	0.013576484794935144	0.012508344767084541	100	0.001	50	50	1e-06	0.5	1812
20	0.013544161594465405	0.012917322485955222	100	0.001	50	50	1e-06	0.5	1812
21	0.013487507058348095	0.01289883310448941	100	0.001	50	50	1e-06	0.5	1812
22	0.013513936685523083	0.012184440172553405	100	0.001	50	50	1e-06	0.5	1812
23	0.013531420264809827	0.01290466753591429	100	0.001	50	50	1e-06	0.5	1812
24	0.013405712401542072	0.01272533007543071	100	0.001	50	50	1e-06	0.5	1812
25	0.013411609032479746	0.012230640076043842	100	0.001	50	50	1e-06	0.5	1812
26	0.01337358563830511	0.012219832675891214	100	0.001	50	50	1e-06	0.5	1812
27	0.013459269898691999	0.012449958399080637	100	0.001	50	50	1e-06	0.5	1812
28	0.013369546469542795	0.012222587298352563	100	0.001	50	50	1e-06	0.5	1812
29	0.013306826271744409	0.01266210019253693	100	0.001	50	50	1e-06	0.5	1812
30	0.013353236779075088	0.012428776971839126	100	0.001	50	50	1e-06	0.5	1812
31	0.013369148929955525	0.011929139318603517	100	0.001	50	50	1e-06	0.5	1812
32	0.013281530171987369	0.012349566829392604	100	0.001	50	50	1e-06	0.5	1812
33	0.013280252876185838	0.012290715161589888	100	0.001	50	50	1e-06	0.5	1812
34	0.013265787919752341	0.012232404025930406	100	0.001	50	50	1e-06	0.5	1812
35	0.013209713728496686	0.012208593396708569	100	0.001	50	50	1e-06	0.5	1812
36	0.013272698786797122	0.012735649599670567	100	0.001	50	50	1e-06	0.5	1812
37	0.013223876334069058	0.012492313603541135	100	0.001	50	50	1e-06	0.5	1812
38	0.013214175133071195	0.012448408583937708	100	0.001	50	50	1e-06	0.5	1812
39	0.013164891583654461	0.012230508512039143	100	0.001	50	50	1e-06	0.5	1812
40	0.013181316700340439	0.011912884484499293	100	0.001	50	50	1e-06	0.5	1812
41	0.013184963602129032	0.012134149462255306	100	0.001	50	50	1e-06	0.5	1812
42	0.013177054394386779	0.01219360945464947	100	0.001	50	50	1e-06	0.5	1812
43	0.01317095507864765	0.012078203659782447	100	0.001	50	50	1e-06	0.5	1812
44	0.013163580980282889	0.012233096849793002	100	0.001	50	50	1e-06	0.5	1812
45	0.013208167779128881	0.012070379868135512	100	0.001	50	50	1e-06	0.5	1812
46	0.013163948702805704	0.012348814644845447	100	0.001	50	50	1e-06	0.5	1812
47	0.0131718177345605	0.012292837834494976	100	0.001	50	50	1e-06	0.5	1812
48	0.013096177354981356	0.0123712815839377	100	0.001	50	50	1e-06	0.5	1812
49	0.013137035599002344	0.012188082179820332	100	0.001	50	50	1e-06	0.5	1812
