	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.02589630523407043	0.016924393756838647	75	0.001	50	50	0.0	0.1	175
1	0.015242073832846158	0.01407124225520324	75	0.001	50	50	0.0	0.1	175
2	0.013413120861979799	0.01292937216535923	75	0.001	50	50	0.0	0.1	175
3	0.012521994776780796	0.012166147941214176	75	0.001	50	50	0.0	0.1	175
4	0.011977509406972968	0.0117594741790575	75	0.001	50	50	0.0	0.1	175
5	0.011665058458985975	0.011564042684524168	75	0.001	50	50	0.0	0.1	175
6	0.011508551200351755	0.011430173173874446	75	0.001	50	50	0.0	0.1	175
7	0.01140924417904019	0.011368240445253953	75	0.001	50	50	0.0	0.1	175
8	0.011382438810549152	0.011358008962160202	75	0.001	50	50	0.0	0.1	175
9	0.011335230549002135	0.011294710355495632	75	0.001	50	50	0.0	0.1	175
10	0.011317911018135316	0.01130732297398734	75	0.001	50	50	0.0	0.1	175
11	0.011297482720641626	0.011301221349143048	75	0.001	50	50	0.0	0.1	175
12	0.01127889336038428	0.011314332828880154	75	0.001	50	50	0.0	0.1	175
13	0.01126967548414183	0.011245597251842286	75	0.001	50	50	0.0	0.1	175
14	0.011254544257381562	0.011234074335965554	75	0.001	50	50	0.0	0.1	175
15	0.011246459884613572	0.011238878437925138	75	0.001	50	50	0.0	0.1	175
16	0.01124466911762079	0.011227991850423426	75	0.001	50	50	0.0	0.1	175
17	0.011236283635392327	0.011196366844282095	75	0.001	50	50	0.0	0.1	175
18	0.011223015491294137	0.011200800596827189	75	0.001	50	50	0.0	0.1	175
19	0.011220210659558394	0.011281378036560794	75	0.001	50	50	0.0	0.1	175
20	0.011208585364227402	0.011353315653753098	75	0.001	50	50	0.0	0.1	175
21	0.01120373786070006	0.011238840964211447	75	0.001	50	50	0.0	0.1	175
22	0.011213636904868634	0.011193682284701623	75	0.001	50	50	0.0	0.1	175
23	0.011203529005503155	0.011181511059688336	75	0.001	50	50	0.0	0.1	175
24	0.011191601500201653	0.011221891443599478	75	0.001	50	50	0.0	0.1	175
25	0.011186844035769375	0.011161061276256127	75	0.001	50	50	0.0	0.1	175
26	0.01118400967765501	0.011189180401369332	75	0.001	50	50	0.0	0.1	175
27	0.011184675515020177	0.011214801500307443	75	0.001	50	50	0.0	0.1	175
28	0.011189395519369032	0.011192682852708587	75	0.001	50	50	0.0	0.1	175
29	0.011178811987044549	0.011166549882500737	75	0.001	50	50	0.0	0.1	175
30	0.011186398834292458	0.011179820928245383	75	0.001	50	50	0.0	0.1	175
31	0.011177487199827056	0.011152052822706234	75	0.001	50	50	0.0	0.1	175
32	0.011168099161263994	0.011208807444110883	75	0.001	50	50	0.0	0.1	175
33	0.011169343634103787	0.01117243369717158	75	0.001	50	50	0.0	0.1	175
34	0.011159130678425385	0.011197331981167168	75	0.001	50	50	0.0	0.1	175
35	0.01115969949212247	0.01115206007028344	75	0.001	50	50	0.0	0.1	175
36	0.011158819355285884	0.011247722433798058	75	0.001	50	50	0.0	0.1	175
37	0.011162172757685945	0.011169325394723316	75	0.001	50	50	0.0	0.1	175
38	0.011166499441052856	0.011195338568000219	75	0.001	50	50	0.0	0.1	175
39	0.011160665488134347	0.011215620116823945	75	0.001	50	50	0.0	0.1	175
40	0.011157415064207478	0.011159407421875297	75	0.001	50	50	0.0	0.1	175
41	0.011145005773459669	0.011195534817076663	75	0.001	50	50	0.0	0.1	175
42	0.01114918280724928	0.011246401670586539	75	0.001	50	50	0.0	0.1	175
43	0.01115526090668249	0.011167191606492204	75	0.001	50	50	0.0	0.1	175
44	0.011140125464186156	0.0111649621573649	75	0.001	50	50	0.0	0.1	175
45	0.011145250677558241	0.01119261982905933	75	0.001	50	50	0.0	0.1	175
46	0.011139385472450032	0.011129904807283477	75	0.001	50	50	0.0	0.1	175
47	0.011138514511312541	0.011142414323202055	75	0.001	50	50	0.0	0.1	175
48	0.011135737714038592	0.01116994752176462	75	0.001	50	50	0.0	0.1	175
49	0.011145469584469332	0.011136396715050673	75	0.001	50	50	0.0	0.1	175
