	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.02459175334874298	0.016632745562416874	50	0.002	50	50	0.0	0.1	7296
1	0.015211554516542576	0.014323532650777874	50	0.002	50	50	0.0	0.1	7296
2	0.014008474520706514	0.013937847295252475	50	0.002	50	50	0.0	0.1	7296
3	0.01379911752288468	0.0139300026583626	50	0.002	50	50	0.0	0.1	7296
4	0.013720627514983635	0.013791397470361188	50	0.002	50	50	0.0	0.1	7296
5	0.013678039012036123	0.013753891254759199	50	0.002	50	50	0.0	0.1	7296
6	0.01362891382891295	0.013751278994658367	50	0.002	50	50	0.0	0.1	7296
7	0.013611575188173615	0.013710827903241546	50	0.002	50	50	0.0	0.1	7296
8	0.013588127873154866	0.01368848662502907	50	0.002	50	50	0.0	0.1	7296
9	0.013574390250168013	0.013750971706288494	50	0.002	50	50	0.0	0.1	7296
10	0.013562382446912857	0.013601509165054412	50	0.002	50	50	0.0	0.1	7296
11	0.013550993048080467	0.013642042382027292	50	0.002	50	50	0.0	0.1	7296
12	0.013547148386725492	0.01360381764838789	50	0.002	50	50	0.0	0.1	7296
13	0.013545908728901573	0.01364351967153768	50	0.002	50	50	0.0	0.1	7296
14	0.013498458324870318	0.013591663229918503	50	0.002	50	50	0.0	0.1	7296
15	0.013507530678918077	0.013759753291083796	50	0.002	50	50	0.0	0.1	7296
16	0.013513310853869568	0.013622328918605302	50	0.002	50	50	0.0	0.1	7296
17	0.013505773663142467	0.01374805675210506	50	0.002	50	50	0.0	0.1	7296
18	0.01349257972427041	0.013547459549589322	50	0.002	50	50	0.0	0.1	7296
19	0.013498523938143582	0.013670884306056435	50	0.002	50	50	0.0	0.1	7296
20	0.013488970237349641	0.013512934910678384	50	0.002	50	50	0.0	0.1	7296
21	0.01347865120033953	0.013576996081774024	50	0.002	50	50	0.0	0.1	7296
22	0.013492817540304682	0.013562632309732314	50	0.002	50	50	0.0	0.1	7296
23	0.013455847056314838	0.013519919131941253	50	0.002	50	50	0.0	0.1	7296
24	0.01346922145894635	0.013585324433007159	50	0.002	50	50	0.0	0.1	7296
25	0.013442064708572296	0.013511707292189448	50	0.002	50	50	0.0	0.1	7296
26	0.013468847516261245	0.013611191207005234	50	0.002	50	50	0.0	0.1	7296
27	0.013468812188335634	0.013518522557647576	50	0.002	50	50	0.0	0.1	7296
28	0.013462515687574924	0.013569626394466962	50	0.002	50	50	0.0	0.1	7296
29	0.01342723346711579	0.013643108253112601	50	0.002	50	50	0.0	0.1	7296
30	0.013458646532129522	0.01353443215065146	50	0.002	50	50	0.0	0.1	7296
31	0.013434199910758532	0.013595155256855557	50	0.002	50	50	0.0	0.1	7296
32	0.013432539731555395	0.013526723492199673	50	0.002	50	50	0.0	0.1	7296
33	0.013432034142323303	0.013489492768225888	50	0.002	50	50	0.0	0.1	7296
34	0.013431123413820708	0.013494867587508367	50	0.002	50	50	0.0	0.1	7296
35	0.013421902346069464	0.013684441997931404	50	0.002	50	50	0.0	0.1	7296
36	0.01342120148185322	0.013473392289708837	50	0.002	50	50	0.0	0.1	7296
37	0.013403819676246828	0.013475198467862196	50	0.002	50	50	0.0	0.1	7296
38	0.013423768210925401	0.013569320562735456	50	0.002	50	50	0.0	0.1	7296
39	0.013421614802574379	0.013630053089009189	50	0.002	50	50	0.0	0.1	7296
40	0.01343097025127843	0.013502463814134693	50	0.002	50	50	0.0	0.1	7296
41	0.013406782681343059	0.013455492736376381	50	0.002	50	50	0.0	0.1	7296
42	0.013399609175099015	0.013664525053882349	50	0.002	50	50	0.0	0.1	7296
43	0.013420421143062314	0.013439521446368206	50	0.002	50	50	0.0	0.1	7296
44	0.013386895414887055	0.01351882851937248	50	0.002	50	50	0.0	0.1	7296
45	0.013424010039868662	0.013440100730790348	50	0.002	50	50	0.0	0.1	7296
46	0.013407031635651013	0.013485957608410436	50	0.002	50	50	0.0	0.1	7296
47	0.013401301429178267	0.013398840483883484	50	0.002	50	50	0.0	0.1	7296
48	0.013392536097841272	0.013462598172032469	50	0.002	50	50	0.0	0.1	7296
49	0.013397946632910957	0.013445296465467313	50	0.002	50	50	0.0	0.1	7296
