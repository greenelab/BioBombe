	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.042663202868293885	0.03334180700875833	5	0.001	100	50	0.0	0.1	3432
1	0.03007037153541345	0.026945306436936895	5	0.001	100	50	0.0	0.1	3432
2	0.02633366986264632	0.02576114658629575	5	0.001	100	50	0.0	0.1	3432
3	0.025683938746154468	0.02543674140142893	5	0.001	100	50	0.0	0.1	3432
4	0.025460377133908606	0.02525930710663987	5	0.001	100	50	0.0	0.1	3432
5	0.02531446618065879	0.025108892712777706	5	0.001	100	50	0.0	0.1	3432
6	0.025186705235920193	0.025036556250905444	5	0.001	100	50	0.0	0.1	3432
7	0.02507570169709364	0.024894400847003745	5	0.001	100	50	0.0	0.1	3432
8	0.02495883834014711	0.024822210273340372	5	0.001	100	50	0.0	0.1	3432
9	0.024859336229462903	0.024693189470193583	5	0.001	100	50	0.0	0.1	3432
10	0.02475413379971677	0.02458624344810587	5	0.001	100	50	0.0	0.1	3432
11	0.02465773887815947	0.024539196543238814	5	0.001	100	50	0.0	0.1	3432
12	0.024552869459011216	0.024433574160243995	5	0.001	100	50	0.0	0.1	3432
13	0.02445701247463663	0.024337547615768805	5	0.001	100	50	0.0	0.1	3432
14	0.024372556231877167	0.024269163775939788	5	0.001	100	50	0.0	0.1	3432
15	0.024294685828640486	0.024236539186443244	5	0.001	100	50	0.0	0.1	3432
16	0.024226988061730632	0.024111945566723043	5	0.001	100	50	0.0	0.1	3432
17	0.024159818496303782	0.024105632823694278	5	0.001	100	50	0.0	0.1	3432
18	0.02411099127723834	0.023995075260874875	5	0.001	100	50	0.0	0.1	3432
19	0.02405809275220225	0.023959117298714288	5	0.001	100	50	0.0	0.1	3432
20	0.023993087785046805	0.023912360966490513	5	0.001	100	50	0.0	0.1	3432
21	0.02395271034775727	0.023913789853937995	5	0.001	100	50	0.0	0.1	3432
22	0.023915603910261662	0.023902288654081907	5	0.001	100	50	0.0	0.1	3432
23	0.023883866170941865	0.023800986354198327	5	0.001	100	50	0.0	0.1	3432
24	0.02383796793139476	0.023824948910089568	5	0.001	100	50	0.0	0.1	3432
25	0.023826665371936617	0.023774257912718998	5	0.001	100	50	0.0	0.1	3432
26	0.023786124096474737	0.023730437134180653	5	0.001	100	50	0.0	0.1	3432
27	0.02376694534210201	0.023740884433028575	5	0.001	100	50	0.0	0.1	3432
28	0.02374497863773641	0.02369713473416879	5	0.001	100	50	0.0	0.1	3432
29	0.023735939016812833	0.023701121339691985	5	0.001	100	50	0.0	0.1	3432
30	0.02370811494942535	0.02366138811990704	5	0.001	100	50	0.0	0.1	3432
31	0.02369148450772301	0.023635850044013664	5	0.001	100	50	0.0	0.1	3432
32	0.023676373600179337	0.023633742416509024	5	0.001	100	50	0.0	0.1	3432
33	0.0236676742292962	0.02360701580918314	5	0.001	100	50	0.0	0.1	3432
34	0.02364866355089551	0.023580390347406468	5	0.001	100	50	0.0	0.1	3432
35	0.023626739626817037	0.023628251164097402	5	0.001	100	50	0.0	0.1	3432
36	0.023609408541237917	0.0235760795846439	5	0.001	100	50	0.0	0.1	3432
37	0.023597606236836766	0.023594981789531944	5	0.001	100	50	0.0	0.1	3432
38	0.023595521503557412	0.023566705023381953	5	0.001	100	50	0.0	0.1	3432
39	0.023583584595390488	0.02353638466839353	5	0.001	100	50	0.0	0.1	3432
40	0.023573191066920712	0.023585759466567414	5	0.001	100	50	0.0	0.1	3432
41	0.023563233585797688	0.023536013339576712	5	0.001	100	50	0.0	0.1	3432
42	0.02355723233230022	0.023518457887676432	5	0.001	100	50	0.0	0.1	3432
43	0.023545151080314453	0.023491217044269378	5	0.001	100	50	0.0	0.1	3432
44	0.023538008630853535	0.023505467779036917	5	0.001	100	50	0.0	0.1	3432
45	0.023521084433804785	0.02349458495956306	5	0.001	100	50	0.0	0.1	3432
46	0.023520617098452042	0.023513209124596122	5	0.001	100	50	0.0	0.1	3432
47	0.023510169973965978	0.023476693002831183	5	0.001	100	50	0.0	0.1	3432
48	0.02351052114738233	0.023490792076258312	5	0.001	100	50	0.0	0.1	3432
49	0.02350962870369128	0.023461136083700918	5	0.001	100	50	0.0	0.1	3432
