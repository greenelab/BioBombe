	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.028575937667244	0.018504904903628175	125	0.001	50	50	1e-06	0.1	531
1	0.01756494767484225	0.015908087616212964	125	0.001	50	50	1e-06	0.1	531
2	0.01581333456866694	0.014805885826025593	125	0.001	50	50	1e-06	0.1	531
3	0.014792051765872633	0.014190561973256546	125	0.001	50	50	1e-06	0.1	531
4	0.014270181553635197	0.013710893827702415	125	0.001	50	50	1e-06	0.1	531
5	0.01377234666388726	0.013829072511774518	125	0.001	50	50	1e-06	0.1	531
6	0.013515997707426649	0.013369292738432525	125	0.001	50	50	1e-06	0.1	531
7	0.013366841200573321	0.012893935051135876	125	0.001	50	50	1e-06	0.1	531
8	0.012926241483182763	0.01248745665481282	125	0.001	50	50	1e-06	0.1	531
9	0.012756508128680143	0.01266126867818217	125	0.001	50	50	1e-06	0.1	531
10	0.012602470354417977	0.012405371838329399	125	0.001	50	50	1e-06	0.1	531
11	0.012380367390016756	0.012608260799548366	125	0.001	50	50	1e-06	0.1	531
12	0.012358314445259897	0.012193763569837889	125	0.001	50	50	1e-06	0.1	531
13	0.012126991363921195	0.011905649643085084	125	0.001	50	50	1e-06	0.1	531
14	0.012116979221296616	0.011814188887053535	125	0.001	50	50	1e-06	0.1	531
15	0.012102526340494718	0.011806076435268952	125	0.001	50	50	1e-06	0.1	531
16	0.011865524457672425	0.011395317482731766	125	0.001	50	50	1e-06	0.1	531
17	0.011848604587766223	0.01180716128539059	125	0.001	50	50	1e-06	0.1	531
18	0.01170210691979619	0.011519573612875852	125	0.001	50	50	1e-06	0.1	531
19	0.011663412251798136	0.011825298669660752	125	0.001	50	50	1e-06	0.1	531
20	0.011641826119396983	0.011917798471838293	125	0.001	50	50	1e-06	0.1	531
21	0.011596461054257053	0.011661724885480469	125	0.001	50	50	1e-06	0.1	531
22	0.011634073324278306	0.013354811961646859	125	0.001	50	50	1e-06	0.1	531
23	0.011491481409772549	0.011587586631396533	125	0.001	50	50	1e-06	0.1	531
24	0.011355832714417669	0.011131390334457786	125	0.001	50	50	1e-06	0.1	531
25	0.011443200068421481	0.011141184094160738	125	0.001	50	50	1e-06	0.1	531
26	0.011431779463703329	0.01120354564251453	125	0.001	50	50	1e-06	0.1	531
27	0.011366515835232833	0.011467858897896045	125	0.001	50	50	1e-06	0.1	531
28	0.011323038449446226	0.011399381998819557	125	0.001	50	50	1e-06	0.1	531
29	0.011374608907105755	0.012341612907229828	125	0.001	50	50	1e-06	0.1	531
30	0.011199908161651223	0.011078319143696223	125	0.001	50	50	1e-06	0.1	531
31	0.011108859638372529	0.011300387810096572	125	0.001	50	50	1e-06	0.1	531
32	0.011274371166160164	0.011313027666657309	125	0.001	50	50	1e-06	0.1	531
33	0.01130734242437136	0.011620588995957921	125	0.001	50	50	1e-06	0.1	531
34	0.011194005655456233	0.010928992531039747	125	0.001	50	50	1e-06	0.1	531
35	0.011039994442438701	0.011228779840138857	125	0.001	50	50	1e-06	0.1	531
36	0.011078897121477258	0.011102349739557357	125	0.001	50	50	1e-06	0.1	531
37	0.01104492970924236	0.011669528161319788	125	0.001	50	50	1e-06	0.1	531
38	0.011106364128219325	0.012045977637171745	125	0.001	50	50	1e-06	0.1	531
39	0.010990212969169294	0.010830051276341337	125	0.001	50	50	1e-06	0.1	531
40	0.011234483324445632	0.010874565069280551	125	0.001	50	50	1e-06	0.1	531
41	0.010987589197405672	0.010711452361003961	125	0.001	50	50	1e-06	0.1	531
42	0.011029005427027084	0.011093102653740583	125	0.001	50	50	1e-06	0.1	531
43	0.011016693104639876	0.011746608203430134	125	0.001	50	50	1e-06	0.1	531
44	0.01108510249826539	0.010750415503451632	125	0.001	50	50	1e-06	0.1	531
45	0.011115592825731574	0.011159393512581548	125	0.001	50	50	1e-06	0.1	531
46	0.010973677332750986	0.010867962663562302	125	0.001	50	50	1e-06	0.1	531
47	0.011128907131491622	0.011769486852987433	125	0.001	50	50	1e-06	0.1	531
48	0.01096530970034419	0.011009851349499895	125	0.001	50	50	1e-06	0.1	531
49	0.011031841375503615	0.011358007010478477	125	0.001	50	50	1e-06	0.1	531
