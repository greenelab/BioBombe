	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.03773272125206553	0.02549027109493717	75	0.0005	100	50	0.0	0.0	2076
1	0.022003769031999392	0.019041617805170285	75	0.0005	100	50	0.0	0.0	2076
2	0.01746797890383677	0.01624985419954556	75	0.0005	100	50	0.0	0.0	2076
3	0.01570309781176839	0.01510668944845236	75	0.0005	100	50	0.0	0.0	2076
4	0.014703958171412774	0.014238667015492005	75	0.0005	100	50	0.0	0.0	2076
5	0.0139624673653935	0.013576945856242062	75	0.0005	100	50	0.0	0.0	2076
6	0.013420012792791829	0.013113533036274048	75	0.0005	100	50	0.0	0.0	2076
7	0.012979736284405376	0.012747756173446005	75	0.0005	100	50	0.0	0.0	2076
8	0.012630901063247149	0.012422247061480984	75	0.0005	100	50	0.0	0.0	2076
9	0.01234026433798882	0.012170746500459616	75	0.0005	100	50	0.0	0.0	2076
10	0.012100544602508362	0.01197120571334492	75	0.0005	100	50	0.0	0.0	2076
11	0.011883326835216396	0.011761627532185605	75	0.0005	100	50	0.0	0.0	2076
12	0.011694984974075038	0.01162998207504674	75	0.0005	100	50	0.0	0.0	2076
13	0.011533588180602433	0.01146698840689021	75	0.0005	100	50	0.0	0.0	2076
14	0.011395385101121753	0.011342593356539596	75	0.0005	100	50	0.0	0.0	2076
15	0.011276415361727283	0.011237048337424805	75	0.0005	100	50	0.0	0.0	2076
16	0.011174013523146878	0.01114744758571767	75	0.0005	100	50	0.0	0.0	2076
17	0.011088015246076905	0.01107180469899116	75	0.0005	100	50	0.0	0.0	2076
18	0.01100765322043686	0.011027181716938547	75	0.0005	100	50	0.0	0.0	2076
19	0.010953526581504685	0.010960692917326213	75	0.0005	100	50	0.0	0.0	2076
20	0.0109075627387762	0.010926209240581975	75	0.0005	100	50	0.0	0.0	2076
21	0.010872928127167577	0.010901149141514962	75	0.0005	100	50	0.0	0.0	2076
22	0.01084419062873037	0.010869923309488917	75	0.0005	100	50	0.0	0.0	2076
23	0.010822266577316067	0.010857980865735853	75	0.0005	100	50	0.0	0.0	2076
24	0.010804356322085061	0.010827403408733427	75	0.0005	100	50	0.0	0.0	2076
25	0.010781875092322105	0.010845533990609259	75	0.0005	100	50	0.0	0.0	2076
26	0.010774992650651209	0.010820295195136198	75	0.0005	100	50	0.0	0.0	2076
27	0.010758531427579402	0.01079916395781202	75	0.0005	100	50	0.0	0.0	2076
28	0.010750150857822752	0.010790766936230043	75	0.0005	100	50	0.0	0.0	2076
29	0.01073794932304803	0.010780675215628817	75	0.0005	100	50	0.0	0.0	2076
30	0.010733029232359928	0.010804211656717907	75	0.0005	100	50	0.0	0.0	2076
31	0.01072575612644498	0.010760892622429259	75	0.0005	100	50	0.0	0.0	2076
32	0.010718302277067092	0.010749779570399005	75	0.0005	100	50	0.0	0.0	2076
33	0.010706217693572379	0.010771033651485726	75	0.0005	100	50	0.0	0.0	2076
34	0.010703600718296766	0.01076551446295833	75	0.0005	100	50	0.0	0.0	2076
35	0.01070025843606436	0.010773333872225043	75	0.0005	100	50	0.0	0.0	2076
36	0.010692781769332863	0.01074000554476254	75	0.0005	100	50	0.0	0.0	2076
37	0.010686117994445589	0.010724763804423422	75	0.0005	100	50	0.0	0.0	2076
38	0.010682861308306915	0.010725254716483402	75	0.0005	100	50	0.0	0.0	2076
39	0.010674413434688576	0.010714475729682591	75	0.0005	100	50	0.0	0.0	2076
40	0.010672388654125049	0.010718940080537052	75	0.0005	100	50	0.0	0.0	2076
41	0.010670071181028995	0.01074633756064833	75	0.0005	100	50	0.0	0.0	2076
42	0.010668852426068956	0.010736597623554972	75	0.0005	100	50	0.0	0.0	2076
43	0.010659273529996544	0.010716453954990575	75	0.0005	100	50	0.0	0.0	2076
44	0.010659074541693835	0.010709522336536225	75	0.0005	100	50	0.0	0.0	2076
45	0.010656661260111241	0.010702256681344136	75	0.0005	100	50	0.0	0.0	2076
46	0.01064876106620218	0.010710760504078569	75	0.0005	100	50	0.0	0.0	2076
47	0.010648885933872485	0.01070790883531192	75	0.0005	100	50	0.0	0.0	2076
48	0.010645765727996338	0.010727565151498605	75	0.0005	100	50	0.0	0.0	2076
49	0.010644670303574178	0.010696395538946753	75	0.0005	100	50	0.0	0.0	2076
