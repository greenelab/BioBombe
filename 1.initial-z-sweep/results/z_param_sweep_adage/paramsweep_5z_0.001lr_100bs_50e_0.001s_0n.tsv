	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.17692026902933272	0.18082759416809957	5	0.001	100	50	0.001	0.0	3696
1	0.12829472060463423	0.15494301171535288	5	0.001	100	50	0.001	0.0	3696
2	0.12222846172624144	0.15543666484820912	5	0.001	100	50	0.001	0.0	3696
3	0.11202251811906684	0.1374424872617193	5	0.001	100	50	0.001	0.0	3696
4	0.11394966312143015	0.14483201218836622	5	0.001	100	50	0.001	0.0	3696
5	0.1094873149225382	0.11345467284806143	5	0.001	100	50	0.001	0.0	3696
6	0.10027609694332382	0.11676423478137922	5	0.001	100	50	0.001	0.0	3696
7	0.10246678233553509	0.12559026733297235	5	0.001	100	50	0.001	0.0	3696
8	0.0937660945327904	0.1097727988634693	5	0.001	100	50	0.001	0.0	3696
9	0.09692644392506584	0.13221727542393977	5	0.001	100	50	0.001	0.0	3696
10	0.10190270261610085	0.15067845387793863	5	0.001	100	50	0.001	0.0	3696
11	0.10211705820947414	0.07950535536268245	5	0.001	100	50	0.001	0.0	3696
12	0.08648684722528022	0.11883061246707836	5	0.001	100	50	0.001	0.0	3696
13	0.09920150990652618	0.10955255699431235	5	0.001	100	50	0.001	0.0	3696
14	0.10534917767214355	0.0911609202366942	5	0.001	100	50	0.001	0.0	3696
15	0.09536758458728012	0.09214129494093572	5	0.001	100	50	0.001	0.0	3696
16	0.08654406297907216	0.10660466224126104	5	0.001	100	50	0.001	0.0	3696
17	0.08861630287309907	0.07561693338403054	5	0.001	100	50	0.001	0.0	3696
18	0.07748604787207493	0.1095031924531519	5	0.001	100	50	0.001	0.0	3696
19	0.08810335586260473	0.13185610868620826	5	0.001	100	50	0.001	0.0	3696
20	0.09963210345202661	0.14700643940477937	5	0.001	100	50	0.001	0.0	3696
21	0.08506025593503432	0.08153439612336186	5	0.001	100	50	0.001	0.0	3696
22	0.08092278584127129	0.12585970525759813	5	0.001	100	50	0.001	0.0	3696
23	0.08746887307622399	0.08274765982938997	5	0.001	100	50	0.001	0.0	3696
24	0.08279515188719658	0.09220580874904848	5	0.001	100	50	0.001	0.0	3696
25	0.07535214337635962	0.09494799560730134	5	0.001	100	50	0.001	0.0	3696
26	0.089912624620665	0.09776734120531247	5	0.001	100	50	0.001	0.0	3696
27	0.08393696897720462	0.10365748362718986	5	0.001	100	50	0.001	0.0	3696
28	0.10366383617832697	0.08739902066284111	5	0.001	100	50	0.001	0.0	3696
29	0.08079034708496502	0.12165078157505615	5	0.001	100	50	0.001	0.0	3696
30	0.08868531645188091	0.13390397313220095	5	0.001	100	50	0.001	0.0	3696
31	0.08166972885115499	0.11162882526164757	5	0.001	100	50	0.001	0.0	3696
32	0.09626987250378316	0.08320603432778419	5	0.001	100	50	0.001	0.0	3696
33	0.08550554643107387	0.1295916238375877	5	0.001	100	50	0.001	0.0	3696
34	0.08017474909557504	0.10073053621710144	5	0.001	100	50	0.001	0.0	3696
35	0.11266968390381667	0.13565252648655818	5	0.001	100	50	0.001	0.0	3696
36	0.07724135810374567	0.08009778869197656	5	0.001	100	50	0.001	0.0	3696
37	0.08400103597598313	0.0773747770852956	5	0.001	100	50	0.001	0.0	3696
38	0.08167786557853861	0.1143651424727294	5	0.001	100	50	0.001	0.0	3696
39	0.08294498328106456	0.08599957349366485	5	0.001	100	50	0.001	0.0	3696
40	0.08955849849521119	0.10282939017160901	5	0.001	100	50	0.001	0.0	3696
41	0.10022379587403737	0.11839786203254021	5	0.001	100	50	0.001	0.0	3696
42	0.07820140263292269	0.13622639930840888	5	0.001	100	50	0.001	0.0	3696
43	0.09007482684362736	0.11973027997502406	5	0.001	100	50	0.001	0.0	3696
44	0.09307330042839329	0.0950333733204218	5	0.001	100	50	0.001	0.0	3696
45	0.0822785002027373	0.10173701487809249	5	0.001	100	50	0.001	0.0	3696
46	0.10869428528731806	0.13199082880243518	5	0.001	100	50	0.001	0.0	3696
47	0.08511004425624054	0.07147348343072385	5	0.001	100	50	0.001	0.0	3696
48	0.0807386700352453	0.0884900890205262	5	0.001	100	50	0.001	0.0	3696
49	0.08050266576759318	0.12286788497269724	5	0.001	100	50	0.001	0.0	3696
