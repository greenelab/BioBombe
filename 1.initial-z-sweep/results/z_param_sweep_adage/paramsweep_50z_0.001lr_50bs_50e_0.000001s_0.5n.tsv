	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.030834698808574087	0.02046755407126638	50	0.001	50	50	1e-06	0.5	535
1	0.01945119741763874	0.01743364483153672	50	0.001	50	50	1e-06	0.5	535
2	0.017432291201082025	0.016006269071956323	50	0.001	50	50	1e-06	0.5	535
3	0.016396295326063088	0.01572039511845399	50	0.001	50	50	1e-06	0.5	535
4	0.01578364558595106	0.014569982702899048	50	0.001	50	50	1e-06	0.5	535
5	0.015334587123015064	0.014506688432315682	50	0.001	50	50	1e-06	0.5	535
6	0.014975857213127662	0.01404475711863025	50	0.001	50	50	1e-06	0.5	535
7	0.014715462552816305	0.014174337484597817	50	0.001	50	50	1e-06	0.5	535
8	0.01456818266649147	0.013521552182035965	50	0.001	50	50	1e-06	0.5	535
9	0.014333456945341902	0.013365626167755282	50	0.001	50	50	1e-06	0.5	535
10	0.014189778223992325	0.013148118522780347	50	0.001	50	50	1e-06	0.5	535
11	0.014121460515725161	0.013489574881316828	50	0.001	50	50	1e-06	0.5	535
12	0.014001788642219064	0.013286756873344486	50	0.001	50	50	1e-06	0.5	535
13	0.013902361410443707	0.013324183890913003	50	0.001	50	50	1e-06	0.5	535
14	0.01389022807414649	0.013073050983278633	50	0.001	50	50	1e-06	0.5	535
15	0.013780232809399313	0.013288789516026385	50	0.001	50	50	1e-06	0.5	535
16	0.013742392771397192	0.013028348274315293	50	0.001	50	50	1e-06	0.5	535
17	0.013627625236929439	0.012982271601006132	50	0.001	50	50	1e-06	0.5	535
18	0.013667479558056028	0.012577519796603497	50	0.001	50	50	1e-06	0.5	535
19	0.013631538029581634	0.012762750997555302	50	0.001	50	50	1e-06	0.5	535
20	0.013564680464242022	0.013055425719580618	50	0.001	50	50	1e-06	0.5	535
21	0.013529921754419765	0.01278383802109706	50	0.001	50	50	1e-06	0.5	535
22	0.013539200093908637	0.012873570103533067	50	0.001	50	50	1e-06	0.5	535
23	0.013478519895432493	0.01239229747259822	50	0.001	50	50	1e-06	0.5	535
24	0.013459431400791113	0.013011269882164653	50	0.001	50	50	1e-06	0.5	535
25	0.013458510911260163	0.012628055154479484	50	0.001	50	50	1e-06	0.5	535
26	0.013396544371884244	0.012434525016417466	50	0.001	50	50	1e-06	0.5	535
27	0.013324092672998278	0.012286220552545775	50	0.001	50	50	1e-06	0.5	535
28	0.013377330869473465	0.012749943342665299	50	0.001	50	50	1e-06	0.5	535
29	0.013380396746880225	0.012817146844207443	50	0.001	50	50	1e-06	0.5	535
30	0.013345800698932205	0.012450763971738901	50	0.001	50	50	1e-06	0.5	535
31	0.013298447476972033	0.012529611290142253	50	0.001	50	50	1e-06	0.5	535
32	0.01335538687342955	0.012605359092226561	50	0.001	50	50	1e-06	0.5	535
33	0.013269068456970137	0.012756731970160915	50	0.001	50	50	1e-06	0.5	535
34	0.01324253546130033	0.012454685553851364	50	0.001	50	50	1e-06	0.5	535
35	0.013308058774422683	0.012857532839203541	50	0.001	50	50	1e-06	0.5	535
36	0.013298582271395258	0.01273800750186464	50	0.001	50	50	1e-06	0.5	535
37	0.013216065853940216	0.012486868265510516	50	0.001	50	50	1e-06	0.5	535
38	0.013218518756159836	0.012695255007302784	50	0.001	50	50	1e-06	0.5	535
39	0.01323411033013799	0.01292378460208442	50	0.001	50	50	1e-06	0.5	535
40	0.013194963745107962	0.012881045165626655	50	0.001	50	50	1e-06	0.5	535
41	0.013175633358399578	0.01222667261694574	50	0.001	50	50	1e-06	0.5	535
42	0.01324533404042145	0.012442977769553205	50	0.001	50	50	1e-06	0.5	535
43	0.013173694148996894	0.012345249233963271	50	0.001	50	50	1e-06	0.5	535
44	0.013131775491475477	0.012706780316482652	50	0.001	50	50	1e-06	0.5	535
45	0.013121261191057193	0.012825325955895006	50	0.001	50	50	1e-06	0.5	535
46	0.013147558137563922	0.012722846790150975	50	0.001	50	50	1e-06	0.5	535
47	0.013169767791764472	0.012516783201358286	50	0.001	50	50	1e-06	0.5	535
48	0.013095945117582167	0.012493318895921538	50	0.001	50	50	1e-06	0.5	535
49	0.013079500205468152	0.012978916464241695	50	0.001	50	50	1e-06	0.5	535
