	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.03571279332378928	0.026511719934713546	25	0.0005	50	50	0.0	0.5	9099
1	0.023248667220950037	0.02017862107212981	25	0.0005	50	50	0.0	0.5	9099
2	0.019032173382305735	0.017221534752908448	25	0.0005	50	50	0.0	0.5	9099
3	0.017106746009272075	0.01593892338078462	25	0.0005	50	50	0.0	0.5	9099
4	0.016193340473117646	0.015221328410474907	25	0.0005	50	50	0.0	0.5	9099
5	0.015668329313412447	0.014815101423167248	25	0.0005	50	50	0.0	0.5	9099
6	0.01540526521051714	0.014681795871964377	25	0.0005	50	50	0.0	0.5	9099
7	0.015290111709181502	0.014579715584734202	25	0.0005	50	50	0.0	0.5	9099
8	0.015226010834323503	0.014505984737087276	25	0.0005	50	50	0.0	0.5	9099
9	0.015183915971718672	0.014464817146982563	25	0.0005	50	50	0.0	0.5	9099
10	0.01515116688029493	0.014434381156632708	25	0.0005	50	50	0.0	0.5	9099
11	0.015127704392326705	0.014421214055747193	25	0.0005	50	50	0.0	0.5	9099
12	0.015105445988489733	0.014395956021251004	25	0.0005	50	50	0.0	0.5	9099
13	0.015090073226638115	0.014366157500725061	25	0.0005	50	50	0.0	0.5	9099
14	0.01507640128351117	0.014416180275038711	25	0.0005	50	50	0.0	0.5	9099
15	0.015066797330577399	0.014415084735185877	25	0.0005	50	50	0.0	0.5	9099
16	0.015054067544354954	0.014337267003682786	25	0.0005	50	50	0.0	0.5	9099
17	0.01503767494698374	0.014363811589976912	25	0.0005	50	50	0.0	0.5	9099
18	0.015045103087188599	0.014315135997807319	25	0.0005	50	50	0.0	0.5	9099
19	0.015029260548935627	0.014362885182221237	25	0.0005	50	50	0.0	0.5	9099
20	0.015025382042667266	0.014298045001639122	25	0.0005	50	50	0.0	0.5	9099
21	0.015001006097331267	0.014315507932072844	25	0.0005	50	50	0.0	0.5	9099
22	0.014997877598103284	0.014316623855959162	25	0.0005	50	50	0.0	0.5	9099
23	0.014998201494344892	0.014297383132232193	25	0.0005	50	50	0.0	0.5	9099
24	0.014988646205662287	0.014298426948957872	25	0.0005	50	50	0.0	0.5	9099
25	0.014980716971467009	0.014289844996628866	25	0.0005	50	50	0.0	0.5	9099
26	0.014971049690082262	0.014293741548779361	25	0.0005	50	50	0.0	0.5	9099
27	0.014956833180295387	0.014277303375902071	25	0.0005	50	50	0.0	0.5	9099
28	0.0149622923229236	0.014251156097516617	25	0.0005	50	50	0.0	0.5	9099
29	0.01495444069571083	0.014279698222932579	25	0.0005	50	50	0.0	0.5	9099
30	0.01495400777556185	0.014218682991287335	25	0.0005	50	50	0.0	0.5	9099
31	0.014940716363042419	0.014271614150665914	25	0.0005	50	50	0.0	0.5	9099
32	0.014929899672978517	0.014287727984669218	25	0.0005	50	50	0.0	0.5	9099
33	0.01491772013593813	0.014250354494108866	25	0.0005	50	50	0.0	0.5	9099
34	0.014922392438128741	0.014225460861383958	25	0.0005	50	50	0.0	0.5	9099
35	0.014920275453167426	0.014221253001752593	25	0.0005	50	50	0.0	0.5	9099
36	0.014911181311237151	0.0142405697502495	25	0.0005	50	50	0.0	0.5	9099
37	0.014905346987293502	0.014199573096122955	25	0.0005	50	50	0.0	0.5	9099
38	0.014892544604708877	0.014194849780609343	25	0.0005	50	50	0.0	0.5	9099
39	0.014890520177361284	0.01419138791570244	25	0.0005	50	50	0.0	0.5	9099
40	0.014877120931479955	0.014180492882191224	25	0.0005	50	50	0.0	0.5	9099
41	0.014877526540616696	0.014183312885990335	25	0.0005	50	50	0.0	0.5	9099
42	0.014879272792013029	0.014170241355183704	25	0.0005	50	50	0.0	0.5	9099
43	0.014864848289687435	0.014182148593875009	25	0.0005	50	50	0.0	0.5	9099
44	0.014868628956724984	0.014182967192584196	25	0.0005	50	50	0.0	0.5	9099
45	0.014854815183350856	0.014161103367663023	25	0.0005	50	50	0.0	0.5	9099
46	0.014858746075994604	0.014166788328047237	25	0.0005	50	50	0.0	0.5	9099
47	0.014851205695440687	0.014148274634254252	25	0.0005	50	50	0.0	0.5	9099
48	0.014855909428506706	0.01413813045330303	25	0.0005	50	50	0.0	0.5	9099
49	0.014852873681903259	0.01418610155959943	25	0.0005	50	50	0.0	0.5	9099
