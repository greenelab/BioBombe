	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.693385301643232	0.541145153870774	25	0.002	50	50	0.001	0.5	9581
1	0.47832704852076424	0.5152763017732828	25	0.002	50	50	0.001	0.5	9581
2	0.38766407541883974	0.3165521311144528	25	0.002	50	50	0.001	0.5	9581
3	0.3519973303399633	0.4050426749266812	25	0.002	50	50	0.001	0.5	9581
4	0.33730186969374265	0.3412415988700568	25	0.002	50	50	0.001	0.5	9581
5	0.3206163034211889	0.2937961510216985	25	0.002	50	50	0.001	0.5	9581
6	0.3194613012398238	0.32275406078900254	25	0.002	50	50	0.001	0.5	9581
7	0.31474144793362213	0.3287009287404741	25	0.002	50	50	0.001	0.5	9581
8	0.31119418485687933	0.29989288151834026	25	0.002	50	50	0.001	0.5	9581
9	0.3063523701022969	0.39583570625540404	25	0.002	50	50	0.001	0.5	9581
10	0.31281035181586503	0.4008962310864866	25	0.002	50	50	0.001	0.5	9581
11	0.2991917177553538	0.2771060615493052	25	0.002	50	50	0.001	0.5	9581
12	0.30504963576435906	0.4014428212925307	25	0.002	50	50	0.001	0.5	9581
13	0.3085671773329369	0.30888270288990743	25	0.002	50	50	0.001	0.5	9581
14	0.29172468874443225	0.3199656185182969	25	0.002	50	50	0.001	0.5	9581
15	0.30432093140613664	0.4224484851209885	25	0.002	50	50	0.001	0.5	9581
16	0.29743053811042	0.34993103665102054	25	0.002	50	50	0.001	0.5	9581
17	0.3000706167824144	0.38127338031509866	25	0.002	50	50	0.001	0.5	9581
18	0.3020409441574922	0.26891955003911633	25	0.002	50	50	0.001	0.5	9581
19	0.29411340666434016	0.30976608891332125	25	0.002	50	50	0.001	0.5	9581
20	0.2961073948600132	0.33498900285414485	25	0.002	50	50	0.001	0.5	9581
21	0.29925556452073215	0.29258051115741696	25	0.002	50	50	0.001	0.5	9581
22	0.3027080905373515	0.35961405457091833	25	0.002	50	50	0.001	0.5	9581
23	0.3013152012257777	0.3613068178780448	25	0.002	50	50	0.001	0.5	9581
24	0.30154729561307764	0.40418569666705667	25	0.002	50	50	0.001	0.5	9581
25	0.29301172161658257	0.35159215188619053	25	0.002	50	50	0.001	0.5	9581
26	0.3062034607215375	0.31878674879356733	25	0.002	50	50	0.001	0.5	9581
27	0.2978453458995529	0.4388607951240831	25	0.002	50	50	0.001	0.5	9581
28	0.30249345889969004	0.39522170615925617	25	0.002	50	50	0.001	0.5	9581
29	0.30519558976265954	0.3688697841723608	25	0.002	50	50	0.001	0.5	9581
30	0.29420288002976674	0.31079216549319016	25	0.002	50	50	0.001	0.5	9581
31	0.29214245327427296	0.41590321491370924	25	0.002	50	50	0.001	0.5	9581
32	0.30049457605012	0.37406398922945755	25	0.002	50	50	0.001	0.5	9581
33	0.2979605702255315	0.28930270455307533	25	0.002	50	50	0.001	0.5	9581
34	0.2944980366417696	0.3573400457434171	25	0.002	50	50	0.001	0.5	9581
35	0.29378493636700903	0.32658503918301307	25	0.002	50	50	0.001	0.5	9581
36	0.2888786754065615	0.3977654571742902	25	0.002	50	50	0.001	0.5	9581
37	0.29095607814095575	0.336902314344738	25	0.002	50	50	0.001	0.5	9581
38	0.2946158616185112	0.41172833635291906	25	0.002	50	50	0.001	0.5	9581
39	0.29209130488175405	0.4357839303080484	25	0.002	50	50	0.001	0.5	9581
40	0.31236768671984527	0.3103493526720408	25	0.002	50	50	0.001	0.5	9581
41	0.29384134131312867	0.370469193613552	25	0.002	50	50	0.001	0.5	9581
42	0.2991680285326355	0.34817097702172245	25	0.002	50	50	0.001	0.5	9581
43	0.29667385542027364	0.3455367517972767	25	0.002	50	50	0.001	0.5	9581
44	0.29671773146515407	0.45659454500242125	25	0.002	50	50	0.001	0.5	9581
45	0.30399921847513095	0.31111069790036	25	0.002	50	50	0.001	0.5	9581
46	0.2970117320055588	0.3470158719993686	25	0.002	50	50	0.001	0.5	9581
47	0.30016641615776485	0.3503991974585371	25	0.002	50	50	0.001	0.5	9581
48	0.2945031486756361	0.4360814286577542	25	0.002	50	50	0.001	0.5	9581
49	0.2970929301251745	0.3299624388236161	25	0.002	50	50	0.001	0.5	9581
