	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.04099071823542549	0.030680769039442616	5	0.0005	50	50	0.0	0.1	7348
1	0.028546827269147562	0.026928187759297527	5	0.0005	50	50	0.0	0.1	7348
2	0.025727505720957906	0.025112714525846406	5	0.0005	50	50	0.0	0.1	7348
3	0.024374823459858128	0.02397685705632484	5	0.0005	50	50	0.0	0.1	7348
4	0.023645040231563833	0.02346111393852398	5	0.0005	50	50	0.0	0.1	7348
5	0.0232973334048144	0.023264241484964327	5	0.0005	50	50	0.0	0.1	7348
6	0.023128931337098226	0.023161776563291568	5	0.0005	50	50	0.0	0.1	7348
7	0.02303810233485144	0.02309531241256466	5	0.0005	50	50	0.0	0.1	7348
8	0.022983852260208125	0.023062245350466404	5	0.0005	50	50	0.0	0.1	7348
9	0.02293281684850552	0.0230442834750929	5	0.0005	50	50	0.0	0.1	7348
10	0.022898545045661682	0.022998247420269263	5	0.0005	50	50	0.0	0.1	7348
11	0.0228642974967808	0.02295742712088684	5	0.0005	50	50	0.0	0.1	7348
12	0.02283626930224399	0.02287779795094954	5	0.0005	50	50	0.0	0.1	7348
13	0.022794853075887602	0.022879908377764102	5	0.0005	50	50	0.0	0.1	7348
14	0.022764051495925103	0.022810630375665414	5	0.0005	50	50	0.0	0.1	7348
15	0.022727672885092226	0.02284085014425432	5	0.0005	50	50	0.0	0.1	7348
16	0.022702741047727	0.022784864298472214	5	0.0005	50	50	0.0	0.1	7348
17	0.022671169606822528	0.022734231691287535	5	0.0005	50	50	0.0	0.1	7348
18	0.02263362705826278	0.02270081904262703	5	0.0005	50	50	0.0	0.1	7348
19	0.022603964690120215	0.02268179023485225	5	0.0005	50	50	0.0	0.1	7348
20	0.02257666453674814	0.02264478363196435	5	0.0005	50	50	0.0	0.1	7348
21	0.0225560771667269	0.022596894601363524	5	0.0005	50	50	0.0	0.1	7348
22	0.022521783554926317	0.022578962560365578	5	0.0005	50	50	0.0	0.1	7348
23	0.022493671486149253	0.022545543351490227	5	0.0005	50	50	0.0	0.1	7348
24	0.022469577971285074	0.022529391358191608	5	0.0005	50	50	0.0	0.1	7348
25	0.02244675487836331	0.022510253865250438	5	0.0005	50	50	0.0	0.1	7348
26	0.02242549696756539	0.022501359218250725	5	0.0005	50	50	0.0	0.1	7348
27	0.022398737340438925	0.022435056476588458	5	0.0005	50	50	0.0	0.1	7348
28	0.0223768066575686	0.022470433079774702	5	0.0005	50	50	0.0	0.1	7348
29	0.022357448841317813	0.022413322951352618	5	0.0005	50	50	0.0	0.1	7348
30	0.02233390547085819	0.022390736982824698	5	0.0005	50	50	0.0	0.1	7348
31	0.022316049416167102	0.022365349222038717	5	0.0005	50	50	0.0	0.1	7348
32	0.022302994116132374	0.022349205705022038	5	0.0005	50	50	0.0	0.1	7348
33	0.022291556919664602	0.022340282074836425	5	0.0005	50	50	0.0	0.1	7348
34	0.022274274062802607	0.02234446435425979	5	0.0005	50	50	0.0	0.1	7348
35	0.022260924573470463	0.022310226820907903	5	0.0005	50	50	0.0	0.1	7348
36	0.022245903724513044	0.022288370304108806	5	0.0005	50	50	0.0	0.1	7348
37	0.02223101289641885	0.022301277719138913	5	0.0005	50	50	0.0	0.1	7348
38	0.022224788654832673	0.022260470351428648	5	0.0005	50	50	0.0	0.1	7348
39	0.022205244871282837	0.02224829829659448	5	0.0005	50	50	0.0	0.1	7348
40	0.02219860586276897	0.022271522856807162	5	0.0005	50	50	0.0	0.1	7348
41	0.02219314911369815	0.02224290529782412	5	0.0005	50	50	0.0	0.1	7348
42	0.022179937297845384	0.02223333020838793	5	0.0005	50	50	0.0	0.1	7348
43	0.02217019624845053	0.022218483829617955	5	0.0005	50	50	0.0	0.1	7348
44	0.022165937883080692	0.022204787376021565	5	0.0005	50	50	0.0	0.1	7348
45	0.022152054959524835	0.022221558127217492	5	0.0005	50	50	0.0	0.1	7348
46	0.02215199916545667	0.02218965656457052	5	0.0005	50	50	0.0	0.1	7348
47	0.02214537427291586	0.022179078100601757	5	0.0005	50	50	0.0	0.1	7348
48	0.022133671435704903	0.022175299409727067	5	0.0005	50	50	0.0	0.1	7348
49	0.02212704471851192	0.022172232263545234	5	0.0005	50	50	0.0	0.1	7348
