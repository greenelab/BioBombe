	loss	val_loss	num_components	learning_rate	batch_size	epochs	kappa	seed	depth	first_layer
0	3164.5467242568457	2970.857904087745	100	0.0005	150	50	0.0	8831	1	100
1	2912.6921578649126	2877.479843227175	100	0.0005	150	50	0.0	8831	1	100
2	2852.701814297091	2829.4935795216898	100	0.0005	150	50	0.0	8831	1	100
3	2822.300522481168	2809.6169349568295	100	0.0005	150	50	0.0	8831	1	100
4	2801.7713334762266	2794.854932387518	100	0.0005	150	50	0.0	8831	1	100
5	2788.460245098202	2806.7706497221557	100	0.0005	150	50	0.0	8831	1	100
6	2779.9061771183306	2781.859272302223	100	0.0005	150	50	0.0	8831	1	100
7	2771.5448346504254	2774.363123935678	100	0.0005	150	50	0.0	8831	1	100
8	2765.061183124195	2761.8307960758248	100	0.0005	150	50	0.0	8831	1	100
9	2760.2789667288175	2759.523133607941	100	0.0005	150	50	0.0	8831	1	100
10	2755.4154888020557	2759.960716699779	100	0.0005	150	50	0.0	8831	1	100
11	2751.185972778878	2752.7335496833175	100	0.0005	150	50	0.0	8831	1	100
12	2747.8718119586524	2747.0298691817043	100	0.0005	150	50	0.0	8831	1	100
13	2744.355092333035	2746.4589601009798	100	0.0005	150	50	0.0	8831	1	100
14	2742.011357376227	2742.518018791826	100	0.0005	150	50	0.0	8831	1	100
15	2739.5180936136776	2744.1341909842554	100	0.0005	150	50	0.0	8831	1	100
16	2737.0880020743007	2736.9034440166406	100	0.0005	150	50	0.0	8831	1	100
17	2734.91168925497	2734.5678608239723	100	0.0005	150	50	0.0	8831	1	100
18	2732.415095422595	2734.0137759732015	100	0.0005	150	50	0.0	8831	1	100
19	2730.76816460198	2733.049500795441	100	0.0005	150	50	0.0	8831	1	100
20	2728.658581046284	2729.061850669963	100	0.0005	150	50	0.0	8831	1	100
21	2726.6020617524055	2730.0659039645075	100	0.0005	150	50	0.0	8831	1	100
22	2724.7882897727463	2727.4014843563277	100	0.0005	150	50	0.0	8831	1	100
23	2723.595188881276	2729.267442283849	100	0.0005	150	50	0.0	8831	1	100
24	2721.8940082397266	2722.8727532527187	100	0.0005	150	50	0.0	8831	1	100
25	2719.9534538752923	2723.8177240492055	100	0.0005	150	50	0.0	8831	1	100
26	2718.5297116261668	2721.749000097096	100	0.0005	150	50	0.0	8831	1	100
27	2717.208352042222	2717.8792288143823	100	0.0005	150	50	0.0	8831	1	100
28	2715.7630357554876	2720.29349344228	100	0.0005	150	50	0.0	8831	1	100
29	2714.1684909821774	2718.199878816623	100	0.0005	150	50	0.0	8831	1	100
30	2712.466475391621	2715.5997442825346	100	0.0005	150	50	0.0	8831	1	100
31	2712.282550898898	2712.9161159887367	100	0.0005	150	50	0.0	8831	1	100
32	2710.6423429843535	2718.2677592465343	100	0.0005	150	50	0.0	8831	1	100
33	2709.4839788972035	2711.7035581978967	100	0.0005	150	50	0.0	8831	1	100
34	2708.622954800293	2711.2491695484287	100	0.0005	150	50	0.0	8831	1	100
35	2707.1821629609235	2709.287532769927	100	0.0005	150	50	0.0	8831	1	100
36	2706.068010243272	2709.7746614707817	100	0.0005	150	50	0.0	8831	1	100
37	2704.8979947373728	2708.215135038241	100	0.0005	150	50	0.0	8831	1	100
38	2704.260871273646	2706.137136076422	100	0.0005	150	50	0.0	8831	1	100
39	2703.205159436044	2705.8823578289316	100	0.0005	150	50	0.0	8831	1	100
40	2702.5115743612973	2704.270574099247	100	0.0005	150	50	0.0	8831	1	100
41	2701.213378569075	2704.3954639325407	100	0.0005	150	50	0.0	8831	1	100
42	2700.532954056433	2703.1030049369624	100	0.0005	150	50	0.0	8831	1	100
43	2699.848758864071	2701.379263824988	100	0.0005	150	50	0.0	8831	1	100
44	2698.958082535664	2701.0255236653024	100	0.0005	150	50	0.0	8831	1	100
45	2698.127997900593	2704.896476906071	100	0.0005	150	50	0.0	8831	1	100
46	2697.304133521501	2703.6997093652903	100	0.0005	150	50	0.0	8831	1	100
47	2696.5448183104068	2700.6048119510338	100	0.0005	150	50	0.0	8831	1	100
48	2695.770284862026	2699.8629204073554	100	0.0005	150	50	0.0	8831	1	100
49	2694.821657231646	2697.365854296128	100	0.0005	150	50	0.0	8831	1	100
