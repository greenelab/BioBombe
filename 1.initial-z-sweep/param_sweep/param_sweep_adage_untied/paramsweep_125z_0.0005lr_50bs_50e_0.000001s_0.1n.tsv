	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.033094031797795395	0.02191904359577263	125	0.0005	50	50	1e-06	0.1	1627
1	0.019717603377917933	0.017911916776750785	125	0.0005	50	50	1e-06	0.1	1627
2	0.017260573410992918	0.016282742358672914	125	0.0005	50	50	1e-06	0.1	1627
3	0.016029776000875566	0.015476032429112987	125	0.0005	50	50	1e-06	0.1	1627
4	0.015247848005105563	0.014651983349546647	125	0.0005	50	50	1e-06	0.1	1627
5	0.014659626102796254	0.014207735356748331	125	0.0005	50	50	1e-06	0.1	1627
6	0.014179287235528899	0.013750936800389628	125	0.0005	50	50	1e-06	0.1	1627
7	0.013816072285578207	0.0134516089271405	125	0.0005	50	50	1e-06	0.1	1627
8	0.0135137654930388	0.013088935804526618	125	0.0005	50	50	1e-06	0.1	1627
9	0.013303113235070673	0.012914201871529364	125	0.0005	50	50	1e-06	0.1	1627
10	0.013025335204515171	0.012809290012868253	125	0.0005	50	50	1e-06	0.1	1627
11	0.012844860864017413	0.01255899348276637	125	0.0005	50	50	1e-06	0.1	1627
12	0.01272261896465814	0.012424418749020614	125	0.0005	50	50	1e-06	0.1	1627
13	0.012461176607411516	0.012153209528990844	125	0.0005	50	50	1e-06	0.1	1627
14	0.012332564960497542	0.012061451973097957	125	0.0005	50	50	1e-06	0.1	1627
15	0.012183497408059645	0.012033462873437437	125	0.0005	50	50	1e-06	0.1	1627
16	0.01208618350402605	0.01185805574380018	125	0.0005	50	50	1e-06	0.1	1627
17	0.01192700126246259	0.011806317421662877	125	0.0005	50	50	1e-06	0.1	1627
18	0.011920879141737359	0.011883326738460228	125	0.0005	50	50	1e-06	0.1	1627
19	0.011741332487668892	0.01191069751650266	125	0.0005	50	50	1e-06	0.1	1627
20	0.011669728467053933	0.012343457191256561	125	0.0005	50	50	1e-06	0.1	1627
21	0.011539343861364557	0.01145947684514306	125	0.0005	50	50	1e-06	0.1	1627
22	0.0114330830768623	0.011374548237849148	125	0.0005	50	50	1e-06	0.1	1627
23	0.011350570379354793	0.011398443620986737	125	0.0005	50	50	1e-06	0.1	1627
24	0.011376458702714413	0.011181852495365458	125	0.0005	50	50	1e-06	0.1	1627
25	0.011218210611926543	0.011085542609797609	125	0.0005	50	50	1e-06	0.1	1627
26	0.011119934175376031	0.011220443183574007	125	0.0005	50	50	1e-06	0.1	1627
27	0.011077770178320937	0.010987936935777532	125	0.0005	50	50	1e-06	0.1	1627
28	0.011028889765232582	0.0110348480883594	125	0.0005	50	50	1e-06	0.1	1627
29	0.010995749083881796	0.010868197387123541	125	0.0005	50	50	1e-06	0.1	1627
30	0.01090442335050449	0.011156818190194226	125	0.0005	50	50	1e-06	0.1	1627
31	0.01098398904537852	0.010962203561718332	125	0.0005	50	50	1e-06	0.1	1627
32	0.010819270632607795	0.010878344128766662	125	0.0005	50	50	1e-06	0.1	1627
33	0.01078979073799367	0.010669294342284677	125	0.0005	50	50	1e-06	0.1	1627
34	0.010664661779218503	0.010680635021661139	125	0.0005	50	50	1e-06	0.1	1627
35	0.01073900275622986	0.010860570022626201	125	0.0005	50	50	1e-06	0.1	1627
36	0.010747906501117718	0.010658408563235066	125	0.0005	50	50	1e-06	0.1	1627
37	0.010561607060460264	0.010648668709836088	125	0.0005	50	50	1e-06	0.1	1627
38	0.010581902144394651	0.010829481490341016	125	0.0005	50	50	1e-06	0.1	1627
39	0.010526592488534504	0.010467607371266896	125	0.0005	50	50	1e-06	0.1	1627
40	0.010487262069154759	0.010431601956173294	125	0.0005	50	50	1e-06	0.1	1627
41	0.01049960767546534	0.010780565143272594	125	0.0005	50	50	1e-06	0.1	1627
42	0.010408717823017642	0.010406137914192039	125	0.0005	50	50	1e-06	0.1	1627
43	0.010415033375968826	0.010453491138711031	125	0.0005	50	50	1e-06	0.1	1627
44	0.010403237996183033	0.010504568024159161	125	0.0005	50	50	1e-06	0.1	1627
45	0.010385326535961307	0.010348191637951832	125	0.0005	50	50	1e-06	0.1	1627
46	0.010459850707971858	0.010988745544583005	125	0.0005	50	50	1e-06	0.1	1627
47	0.010446371663784064	0.010747361203466843	125	0.0005	50	50	1e-06	0.1	1627
48	0.010387523550847714	0.01043710115777033	125	0.0005	50	50	1e-06	0.1	1627
49	0.010265614780913304	0.010382213218433224	125	0.0005	50	50	1e-06	0.1	1627
