	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.03629772825738259	0.028302842637178548	5	0.001	50	50	0.0	0.5	3810
1	0.025036684324784612	0.02379659925503781	5	0.001	50	50	0.0	0.5	3810
2	0.023619138256655698	0.02346172434122909	5	0.001	50	50	0.0	0.5	3810
3	0.023441629369723282	0.023405312701176503	5	0.001	50	50	0.0	0.5	3810
4	0.02337138735737011	0.023226748510881773	5	0.001	50	50	0.0	0.5	3810
5	0.02330075018127679	0.023204858829739217	5	0.001	50	50	0.0	0.5	3810
6	0.023281591369653815	0.02317762320743692	5	0.001	50	50	0.0	0.5	3810
7	0.023213441698673135	0.023106839525625537	5	0.001	50	50	0.0	0.5	3810
8	0.023187968172318975	0.023079401761806263	5	0.001	50	50	0.0	0.5	3810
9	0.0231276000963189	0.02308170071466475	5	0.001	50	50	0.0	0.5	3810
10	0.023081578437781518	0.022972656342683515	5	0.001	50	50	0.0	0.5	3810
11	0.0230339641386874	0.022978199977092943	5	0.001	50	50	0.0	0.5	3810
12	0.02300354998871806	0.022896406769638535	5	0.001	50	50	0.0	0.5	3810
13	0.022954122617193304	0.022845285052494155	5	0.001	50	50	0.0	0.5	3810
14	0.02292218121218052	0.022802633577049577	5	0.001	50	50	0.0	0.5	3810
15	0.022886674567616973	0.022746141547654145	5	0.001	50	50	0.0	0.5	3810
16	0.02284702705056137	0.022800421937018006	5	0.001	50	50	0.0	0.5	3810
17	0.022824473837171885	0.022697299352026124	5	0.001	50	50	0.0	0.5	3810
18	0.02278113786182988	0.022662429580639472	5	0.001	50	50	0.0	0.5	3810
19	0.022753071598134778	0.022637755366088554	5	0.001	50	50	0.0	0.5	3810
20	0.022735872241915457	0.022660287823634894	5	0.001	50	50	0.0	0.5	3810
21	0.022722559029739645	0.022605799936313703	5	0.001	50	50	0.0	0.5	3810
22	0.022700039377404578	0.022667515880462088	5	0.001	50	50	0.0	0.5	3810
23	0.02267951559060491	0.022641791657582067	5	0.001	50	50	0.0	0.5	3810
24	0.02265963385618323	0.022559679635082788	5	0.001	50	50	0.0	0.5	3810
25	0.022667205853421947	0.02252940433616278	5	0.001	50	50	0.0	0.5	3810
26	0.02263316230979626	0.02256683501313453	5	0.001	50	50	0.0	0.5	3810
27	0.02260970369058139	0.022501528530201768	5	0.001	50	50	0.0	0.5	3810
28	0.02261662427215271	0.022569374111881677	5	0.001	50	50	0.0	0.5	3810
29	0.02257835389712811	0.02252765456089896	5	0.001	50	50	0.0	0.5	3810
30	0.022597415275965944	0.022495897497490303	5	0.001	50	50	0.0	0.5	3810
31	0.022577525327542338	0.022466359453464556	5	0.001	50	50	0.0	0.5	3810
32	0.02255753777734401	0.022508190855754263	5	0.001	50	50	0.0	0.5	3810
33	0.0225566417171967	0.022486675605462796	5	0.001	50	50	0.0	0.5	3810
34	0.022556395193449714	0.02247459484160972	5	0.001	50	50	0.0	0.5	3810
35	0.022542997443145994	0.02251509972714443	5	0.001	50	50	0.0	0.5	3810
36	0.022533391559496324	0.022468507475082552	5	0.001	50	50	0.0	0.5	3810
37	0.02252410837491381	0.022521091692762212	5	0.001	50	50	0.0	0.5	3810
38	0.022517536995081775	0.022442742113743412	5	0.001	50	50	0.0	0.5	3810
39	0.022523349157149566	0.022445292958195532	5	0.001	50	50	0.0	0.5	3810
40	0.022520760617834416	0.022463750945364996	5	0.001	50	50	0.0	0.5	3810
41	0.02250097085708236	0.02241601602995259	5	0.001	50	50	0.0	0.5	3810
42	0.022502850324016797	0.02242149386989455	5	0.001	50	50	0.0	0.5	3810
43	0.022502122339643646	0.022482067581629434	5	0.001	50	50	0.0	0.5	3810
44	0.022485391910920156	0.022402384284577453	5	0.001	50	50	0.0	0.5	3810
45	0.02250345057046915	0.022406388832751242	5	0.001	50	50	0.0	0.5	3810
46	0.0224962604008429	0.022414661744470578	5	0.001	50	50	0.0	0.5	3810
47	0.022488157365312424	0.022438683474069573	5	0.001	50	50	0.0	0.5	3810
48	0.022481362229419113	0.022453242186350076	5	0.001	50	50	0.0	0.5	3810
49	0.02248292846940984	0.02240654535905011	5	0.001	50	50	0.0	0.5	3810
