	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.04042255269749587	0.028040429691198222	100	0.001	100	50	1e-06	0.1	9423
1	0.02427076573745738	0.022038965078202535	100	0.001	100	50	1e-06	0.1	9423
2	0.02077604845679903	0.019086801876130568	100	0.001	100	50	1e-06	0.1	9423
3	0.019118644036514896	0.018444320454082345	100	0.001	100	50	1e-06	0.1	9423
4	0.018232865025453893	0.017161045285800106	100	0.001	100	50	1e-06	0.1	9423
5	0.01738814022686876	0.017096349340908045	100	0.001	100	50	1e-06	0.1	9423
6	0.01692774438717854	0.016727941520298415	100	0.001	100	50	1e-06	0.1	9423
7	0.016676847861155045	0.016026152506200007	100	0.001	100	50	1e-06	0.1	9423
8	0.016004514594541674	0.016321583341158942	100	0.001	100	50	1e-06	0.1	9423
9	0.01576428340644461	0.015387718528366682	100	0.001	100	50	1e-06	0.1	9423
10	0.01565293837538545	0.015652867073253737	100	0.001	100	50	1e-06	0.1	9423
11	0.015365745684470949	0.01531693647592462	100	0.001	100	50	1e-06	0.1	9423
12	0.01509596261368093	0.014820698536505092	100	0.001	100	50	1e-06	0.1	9423
13	0.014931244443807999	0.014454475669884772	100	0.001	100	50	1e-06	0.1	9423
14	0.014757231409382164	0.014764410164029147	100	0.001	100	50	1e-06	0.1	9423
15	0.014564220789983404	0.014210854033738318	100	0.001	100	50	1e-06	0.1	9423
16	0.014411742357315722	0.014949350309759435	100	0.001	100	50	1e-06	0.1	9423
17	0.01440494307256981	0.014010871776573744	100	0.001	100	50	1e-06	0.1	9423
18	0.014173236298104231	0.014238235822043616	100	0.001	100	50	1e-06	0.1	9423
19	0.01408645870528334	0.014012580525564531	100	0.001	100	50	1e-06	0.1	9423
20	0.01384345728349549	0.013871726654754883	100	0.001	100	50	1e-06	0.1	9423
21	0.013905361896796527	0.014928083259605198	100	0.001	100	50	1e-06	0.1	9423
22	0.013799700094985523	0.014388883393792075	100	0.001	100	50	1e-06	0.1	9423
23	0.01388898292386426	0.01332131051859083	100	0.001	100	50	1e-06	0.1	9423
24	0.013507059051447558	0.015295894198603999	100	0.001	100	50	1e-06	0.1	9423
25	0.013971857788114647	0.013389755642294427	100	0.001	100	50	1e-06	0.1	9423
26	0.01339942182570658	0.013046423197647353	100	0.001	100	50	1e-06	0.1	9423
27	0.013390426752337085	0.013418232254598495	100	0.001	100	50	1e-06	0.1	9423
28	0.01345286291594458	0.013487996253938223	100	0.001	100	50	1e-06	0.1	9423
29	0.013179891477507663	0.013745224828089287	100	0.001	100	50	1e-06	0.1	9423
30	0.013424232127998785	0.013525557205665065	100	0.001	100	50	1e-06	0.1	9423
31	0.013156912080103781	0.01318523472613062	100	0.001	100	50	1e-06	0.1	9423
32	0.013467152514023506	0.013487530590870184	100	0.001	100	50	1e-06	0.1	9423
33	0.01295078918535702	0.013437627932238419	100	0.001	100	50	1e-06	0.1	9423
34	0.013077442795667481	0.01358485703728737	100	0.001	100	50	1e-06	0.1	9423
35	0.012882624150175768	0.013042582006658468	100	0.001	100	50	1e-06	0.1	9423
36	0.013030904105680535	0.013475400703757945	100	0.001	100	50	1e-06	0.1	9423
37	0.013138591508663741	0.01277912254258278	100	0.001	100	50	1e-06	0.1	9423
38	0.013128944595075149	0.01337009210524151	100	0.001	100	50	1e-06	0.1	9423
39	0.012884269199963046	0.012835915449714684	100	0.001	100	50	1e-06	0.1	9423
40	0.012633814390748344	0.013373935944178137	100	0.001	100	50	1e-06	0.1	9423
41	0.012808024512146183	0.015301342480183788	100	0.001	100	50	1e-06	0.1	9423
42	0.013149739570482738	0.0134178836069588	100	0.001	100	50	1e-06	0.1	9423
43	0.012820596283609018	0.012596834548900392	100	0.001	100	50	1e-06	0.1	9423
44	0.012711547152463275	0.012702193164603205	100	0.001	100	50	1e-06	0.1	9423
45	0.013207030000851156	0.013285293432582975	100	0.001	100	50	1e-06	0.1	9423
46	0.012624294555051558	0.013579042870586963	100	0.001	100	50	1e-06	0.1	9423
47	0.012452943587625626	0.012990954843123601	100	0.001	100	50	1e-06	0.1	9423
48	0.012748484108642552	0.01263816802482874	100	0.001	100	50	1e-06	0.1	9423
49	0.012622226784744844	0.012650752436533484	100	0.001	100	50	1e-06	0.1	9423
