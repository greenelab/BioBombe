	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.027426610125647673	0.018084393960226108	50	0.001	50	50	0.0	0.5	740
1	0.01679472022146797	0.014863483248061249	50	0.001	50	50	0.0	0.5	740
2	0.014729744047904026	0.013606416214663486	50	0.001	50	50	0.0	0.5	740
3	0.013825065867426633	0.013006676914416126	50	0.001	50	50	0.0	0.5	740
4	0.013373448871907995	0.012749580759020883	50	0.001	50	50	0.0	0.5	740
5	0.013133248195632332	0.012502530026988591	50	0.001	50	50	0.0	0.5	740
6	0.01297868412220727	0.012284004660127381	50	0.001	50	50	0.0	0.5	740
7	0.01291920228645682	0.01222323785477227	50	0.001	50	50	0.0	0.5	740
8	0.012866687936286649	0.012175122699762621	50	0.001	50	50	0.0	0.5	740
9	0.012845241331204363	0.012203984929473062	50	0.001	50	50	0.0	0.5	740
10	0.012804480106695975	0.01212412166279201	50	0.001	50	50	0.0	0.5	740
11	0.012791407103716066	0.012111435898973198	50	0.001	50	50	0.0	0.5	740
12	0.012787904996022425	0.012159734417686157	50	0.001	50	50	0.0	0.5	740
13	0.012776849746686688	0.012153621248359548	50	0.001	50	50	0.0	0.5	740
14	0.012753040903583002	0.0121652567011249	50	0.001	50	50	0.0	0.5	740
15	0.012763473893693165	0.012131768620678047	50	0.001	50	50	0.0	0.5	740
16	0.012739336332801955	0.01210170947941266	50	0.001	50	50	0.0	0.5	740
17	0.012740050209513016	0.01208865076987283	50	0.001	50	50	0.0	0.5	740
18	0.01273522278744936	0.012144432422735267	50	0.001	50	50	0.0	0.5	740
19	0.012727646119548287	0.012106360751871968	50	0.001	50	50	0.0	0.5	740
20	0.012724666848511982	0.012173208345732087	50	0.001	50	50	0.0	0.5	740
21	0.01272212900824882	0.01210601834747691	50	0.001	50	50	0.0	0.5	740
22	0.01271724518957217	0.012127334606365423	50	0.001	50	50	0.0	0.5	740
23	0.012706022171572153	0.01204188792907542	50	0.001	50	50	0.0	0.5	740
24	0.0127174510601439	0.012288078108364377	50	0.001	50	50	0.0	0.5	740
25	0.012695298569539515	0.012096231840693358	50	0.001	50	50	0.0	0.5	740
26	0.012686097525767796	0.012094872412458775	50	0.001	50	50	0.0	0.5	740
27	0.012689589275033133	0.012078262707058262	50	0.001	50	50	0.0	0.5	740
28	0.012693266392317713	0.012098011126239601	50	0.001	50	50	0.0	0.5	740
29	0.01268194426895122	0.012088399927130051	50	0.001	50	50	0.0	0.5	740
30	0.01268407051598628	0.012130815092381625	50	0.001	50	50	0.0	0.5	740
31	0.012669414593308332	0.012099851528271663	50	0.001	50	50	0.0	0.5	740
32	0.012671297684218468	0.012083863923201484	50	0.001	50	50	0.0	0.5	740
33	0.01266771433013197	0.012057940609197544	50	0.001	50	50	0.0	0.5	740
34	0.012655092394684873	0.012120911666329231	50	0.001	50	50	0.0	0.5	740
35	0.012641638398948536	0.012054982278175495	50	0.001	50	50	0.0	0.5	740
36	0.012654069473324439	0.012041474468151311	50	0.001	50	50	0.0	0.5	740
37	0.012641351611948978	0.012076126780168618	50	0.001	50	50	0.0	0.5	740
38	0.012640691784498517	0.012131809646951082	50	0.001	50	50	0.0	0.5	740
39	0.012639354809154603	0.0120373947837926	50	0.001	50	50	0.0	0.5	740
40	0.012631971458016459	0.012037876656859486	50	0.001	50	50	0.0	0.5	740
41	0.012625392381638893	0.012107451287869286	50	0.001	50	50	0.0	0.5	740
42	0.012621205898877805	0.012109290913502413	50	0.001	50	50	0.0	0.5	740
43	0.012613259711900712	0.012043241575274822	50	0.001	50	50	0.0	0.5	740
44	0.01260573699303398	0.012227498961836954	50	0.001	50	50	0.0	0.5	740
45	0.012606220695938218	0.01204924119447659	50	0.001	50	50	0.0	0.5	740
46	0.012606311490242588	0.012096751148297842	50	0.001	50	50	0.0	0.5	740
47	0.012600978099511797	0.01207966437424403	50	0.001	50	50	0.0	0.5	740
48	0.012607882871652376	0.012058794487759214	50	0.001	50	50	0.0	0.5	740
49	0.012604639721797078	0.012080239801601743	50	0.001	50	50	0.0	0.5	740
