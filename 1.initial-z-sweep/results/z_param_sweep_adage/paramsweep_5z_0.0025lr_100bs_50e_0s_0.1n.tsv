	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.03940949162819947	0.03223546932008025	5	0.0025	100	50	0.0	0.1	5705
1	0.02986824198802194	0.028376073400217534	5	0.0025	100	50	0.0	0.1	5705
2	0.028755849536595785	0.028023856964468043	5	0.0025	100	50	0.0	0.1	5705
3	0.028484691536370822	0.027955982228652015	5	0.0025	100	50	0.0	0.1	5705
4	0.028272616252830274	0.027657998038409546	5	0.0025	100	50	0.0	0.1	5705
5	0.028050678480496874	0.027486940949129558	5	0.0025	100	50	0.0	0.1	5705
6	0.027862773997247896	0.027290994832096318	5	0.0025	100	50	0.0	0.1	5705
7	0.02771698062117277	0.02710456856620813	5	0.0025	100	50	0.0	0.1	5705
8	0.027610783996019926	0.027048382701540995	5	0.0025	100	50	0.0	0.1	5705
9	0.027489014059735778	0.02695622859989252	5	0.0025	100	50	0.0	0.1	5705
10	0.027388357063744508	0.026989041031632095	5	0.0025	100	50	0.0	0.1	5705
11	0.027317720684316375	0.02680536058248799	5	0.0025	100	50	0.0	0.1	5705
12	0.027265387863390923	0.02693193142318361	5	0.0025	100	50	0.0	0.1	5705
13	0.02724752301490929	0.02670016949978545	5	0.0025	100	50	0.0	0.1	5705
14	0.027163012912359397	0.026849276163609943	5	0.0025	100	50	0.0	0.1	5705
15	0.027135474589143477	0.026687482770810164	5	0.0025	100	50	0.0	0.1	5705
16	0.027114031974708668	0.026620594955567647	5	0.0025	100	50	0.0	0.1	5705
17	0.02707590018598424	0.02675676626824626	5	0.0025	100	50	0.0	0.1	5705
18	0.027066172905282907	0.02655657267208651	5	0.0025	100	50	0.0	0.1	5705
19	0.027026512845796605	0.02659606353075281	5	0.0025	100	50	0.0	0.1	5705
20	0.027027607347800794	0.02654305572690973	5	0.0025	100	50	0.0	0.1	5705
21	0.027008224360215022	0.02654962546867007	5	0.0025	100	50	0.0	0.1	5705
22	0.026980281889305655	0.02648763648139929	5	0.0025	100	50	0.0	0.1	5705
23	0.026955105135969055	0.02660926458484584	5	0.0025	100	50	0.0	0.1	5705
24	0.026946000534988458	0.026464255412695058	5	0.0025	100	50	0.0	0.1	5705
25	0.0269209249456637	0.026457678604992124	5	0.0025	100	50	0.0	0.1	5705
26	0.02691513177295946	0.026512034778727173	5	0.0025	100	50	0.0	0.1	5705
27	0.026911675983055054	0.026559562384939787	5	0.0025	100	50	0.0	0.1	5705
28	0.026894666512556033	0.026503163762034466	5	0.0025	100	50	0.0	0.1	5705
29	0.026883322707370746	0.02640768111706578	5	0.0025	100	50	0.0	0.1	5705
30	0.02686568550764723	0.02647995547414624	5	0.0025	100	50	0.0	0.1	5705
31	0.026854176344768495	0.02640302407681714	5	0.0025	100	50	0.0	0.1	5705
32	0.02686331342162918	0.02636965820797315	5	0.0025	100	50	0.0	0.1	5705
33	0.02684481234774413	0.026383344920968235	5	0.0025	100	50	0.0	0.1	5705
34	0.026846042458151233	0.026364694572059193	5	0.0025	100	50	0.0	0.1	5705
35	0.026822032614502354	0.02634901251736494	5	0.0025	100	50	0.0	0.1	5705
36	0.026830954203918587	0.026399594131522378	5	0.0025	100	50	0.0	0.1	5705
37	0.026826618166661573	0.026407873802898493	5	0.0025	100	50	0.0	0.1	5705
38	0.026811807033976207	0.02636560384205491	5	0.0025	100	50	0.0	0.1	5705
39	0.026799948080862845	0.026329072466543937	5	0.0025	100	50	0.0	0.1	5705
40	0.02680536585626555	0.026413363481143464	5	0.0025	100	50	0.0	0.1	5705
41	0.026810642699499787	0.026328432781490038	5	0.0025	100	50	0.0	0.1	5705
42	0.02681028561402042	0.026359340172424826	5	0.0025	100	50	0.0	0.1	5705
43	0.026788602458940585	0.02633091847966096	5	0.0025	100	50	0.0	0.1	5705
44	0.026791536207566614	0.026311941519664532	5	0.0025	100	50	0.0	0.1	5705
45	0.026771712384727787	0.026276224380070577	5	0.0025	100	50	0.0	0.1	5705
46	0.026762181159449627	0.026281804344964074	5	0.0025	100	50	0.0	0.1	5705
47	0.026753564629872748	0.026281289044005465	5	0.0025	100	50	0.0	0.1	5705
48	0.02675254770140934	0.026455250531292555	5	0.0025	100	50	0.0	0.1	5705
49	0.0267720972687959	0.0262903047415711	5	0.0025	100	50	0.0	0.1	5705
