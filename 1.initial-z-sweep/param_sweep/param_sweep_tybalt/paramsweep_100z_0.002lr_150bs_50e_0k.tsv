	loss	val_loss	num_components	learning_rate	batch_size	epochs	kappa	seed	depth	first_layer
0	3165.5780818618587	3197.667792085427	100	0.002	150	50	0.0	416	1	100
1	2653.7522721237897	2780.2498601405464	100	0.002	150	50	0.0	416	1	100
2	2612.0357748449533	2650.271605831894	100	0.002	150	50	0.0	416	1	100
3	2589.3360892601454	2610.9738389211684	100	0.002	150	50	0.0	416	1	100
4	2573.3711006989743	2574.5201790201004	100	0.002	150	50	0.0	416	1	100
5	2561.1613789151884	2557.874404983904	100	0.002	150	50	0.0	416	1	100
6	2552.9465493083944	2560.7514157702576	100	0.002	150	50	0.0	416	1	100
7	2543.6064614177694	2548.520885678392	100	0.002	150	50	0.0	416	1	100
8	2539.6600612534357	2540.479941209956	100	0.002	150	50	0.0	416	1	100
9	2533.7549750294747	2536.093840785961	100	0.002	150	50	0.0	416	1	100
10	2529.193290675534	2535.812346645336	100	0.002	150	50	0.0	416	1	100
11	2525.8462726956222	2524.8702177881596	100	0.002	150	50	0.0	416	1	100
12	2522.570255055147	2524.329372693546	100	0.002	150	50	0.0	416	1	100
13	2518.8130944779255	2518.1861786962154	100	0.002	150	50	0.0	416	1	100
14	2516.6009064895898	2536.9224565208856	100	0.002	150	50	0.0	416	1	100
15	2514.1675136875715	2524.2097315189226	100	0.002	150	50	0.0	416	1	100
16	2511.78643755908	2522.4502051271984	100	0.002	150	50	0.0	416	1	100
17	2509.286810678115	2510.1520971557	100	0.002	150	50	0.0	416	1	100
18	2507.570049937781	2507.671363408841	100	0.002	150	50	0.0	416	1	100
19	2505.8614649789142	2507.8883479899496	100	0.002	150	50	0.0	416	1	100
20	2504.2656252725087	2505.2223434064854	100	0.002	150	50	0.0	416	1	100
21	2502.0155549924916	2503.351953861102	100	0.002	150	50	0.0	416	1	100
22	2501.2809908713916	2501.996220114243	100	0.002	150	50	0.0	416	1	100
23	2499.4745901086285	2499.810602082679	100	0.002	150	50	0.0	416	1	100
24	2498.1733007932403	2500.186408114793	100	0.002	150	50	0.0	416	1	100
25	2497.575167625607	2499.3215000785176	100	0.002	150	50	0.0	416	1	100
26	2495.7539470718166	2502.2339088018216	100	0.002	150	50	0.0	416	1	100
27	2494.7285367171803	2495.3238261620604	100	0.002	150	50	0.0	416	1	100
28	2493.434109064122	2494.2947034979584	100	0.002	150	50	0.0	416	1	100
29	2492.695502983644	2494.883493394708	100	0.002	150	50	0.0	416	1	100
30	2491.277549112624	2492.7918363791614	100	0.002	150	50	0.0	416	1	100
31	2490.5754857251177	2492.350707394394	100	0.002	150	50	0.0	416	1	100
32	2488.820193522662	2491.1417365146044	100	0.002	150	50	0.0	416	1	100
33	2488.4364295854725	2490.824554903423	100	0.002	150	50	0.0	416	1	100
34	2487.7057410843845	2490.3479016174624	100	0.002	150	50	0.0	416	1	100
35	2486.9286613409004	2492.260517676272	100	0.002	150	50	0.0	416	1	100
36	2485.949857837614	2488.337190100895	100	0.002	150	50	0.0	416	1	100
37	2485.188240270128	2487.0111065581814	100	0.002	150	50	0.0	416	1	100
38	2484.593290359424	2487.5372725443626	100	0.002	150	50	0.0	416	1	100
39	2483.983980679781	2487.452072373587	100	0.002	150	50	0.0	416	1	100
40	2483.3675420611867	2484.8369079283134	100	0.002	150	50	0.0	416	1	100
41	2482.1586261948964	2488.153617207129	100	0.002	150	50	0.0	416	1	100
42	2481.699204606794	2489.299635383951	100	0.002	150	50	0.0	416	1	100
43	2481.493152099364	2485.500824434673	100	0.002	150	50	0.0	416	1	100
44	2480.479451229429	2484.22190787924	100	0.002	150	50	0.0	416	1	100
45	2479.896363871613	2487.6464119915986	100	0.002	150	50	0.0	416	1	100
46	2479.281233376964	2483.817440473854	100	0.002	150	50	0.0	416	1	100
47	2478.7519546783	2482.9776641999056	100	0.002	150	50	0.0	416	1	100
48	2478.0322691828746	2483.8018461447864	100	0.002	150	50	0.0	416	1	100
49	2477.4445217067423	2482.326909204224	100	0.002	150	50	0.0	416	1	100
