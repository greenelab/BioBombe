	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.025546667810450716	0.016305009946654448	100	0.0025	100	50	0.0	0.1	1349
1	0.014531432449640357	0.013547387716661334	100	0.0025	100	50	0.0	0.1	1349
2	0.012862362505797434	0.012461278683739228	100	0.0025	100	50	0.0	0.1	1349
3	0.012030084775937873	0.011888274216016551	100	0.0025	100	50	0.0	0.1	1349
4	0.011515264882473893	0.011494367301506818	100	0.0025	100	50	0.0	0.1	1349
5	0.011228162832407766	0.011249293069253688	100	0.0025	100	50	0.0	0.1	1349
6	0.011032641749850029	0.011026332429102684	100	0.0025	100	50	0.0	0.1	1349
7	0.01092365017271784	0.011068048030422932	100	0.0025	100	50	0.0	0.1	1349
8	0.01085667064854503	0.010977751856765944	100	0.0025	100	50	0.0	0.1	1349
9	0.010836310683988359	0.010975102413210655	100	0.0025	100	50	0.0	0.1	1349
10	0.010784813627469277	0.01085523066661155	100	0.0025	100	50	0.0	0.1	1349
11	0.010740590601162977	0.010903220579213325	100	0.0025	100	50	0.0	0.1	1349
12	0.010737443585208001	0.010876780863758711	100	0.0025	100	50	0.0	0.1	1349
13	0.010751234988635372	0.010841001614030756	100	0.0025	100	50	0.0	0.1	1349
14	0.01070596162943332	0.010887201136444655	100	0.0025	100	50	0.0	0.1	1349
15	0.010668032271432329	0.010992294677798537	100	0.0025	100	50	0.0	0.1	1349
16	0.010720584952259317	0.010815763683993205	100	0.0025	100	50	0.0	0.1	1349
17	0.010700391420973236	0.011003423170551628	100	0.0025	100	50	0.0	0.1	1349
18	0.010719207751655805	0.010925311539998817	100	0.0025	100	50	0.0	0.1	1349
19	0.01067270283861044	0.010911550875005257	100	0.0025	100	50	0.0	0.1	1349
20	0.010706349290550407	0.010928945476990585	100	0.0025	100	50	0.0	0.1	1349
21	0.01066366727610827	0.010862815119041198	100	0.0025	100	50	0.0	0.1	1349
22	0.010688728825643803	0.01077891721872766	100	0.0025	100	50	0.0	0.1	1349
23	0.010654020479268923	0.010748368750253326	100	0.0025	100	50	0.0	0.1	1349
24	0.010646321277000452	0.01079802210825579	100	0.0025	100	50	0.0	0.1	1349
25	0.010667108900371721	0.010807323454742107	100	0.0025	100	50	0.0	0.1	1349
26	0.010658009192965388	0.01084584449498022	100	0.0025	100	50	0.0	0.1	1349
27	0.010623113635912004	0.011195073582687867	100	0.0025	100	50	0.0	0.1	1349
28	0.01068990849651864	0.010832594499262637	100	0.0025	100	50	0.0	0.1	1349
29	0.010666597418270987	0.010967513813457343	100	0.0025	100	50	0.0	0.1	1349
30	0.010648388307730386	0.010884513412504305	100	0.0025	100	50	0.0	0.1	1349
31	0.010623848587246848	0.01074116872748214	100	0.0025	100	50	0.0	0.1	1349
32	0.010641247095910399	0.010865925907390637	100	0.0025	100	50	0.0	0.1	1349
33	0.010655217837555355	0.010727454430956115	100	0.0025	100	50	0.0	0.1	1349
34	0.010632090374208416	0.010883768758670663	100	0.0025	100	50	0.0	0.1	1349
35	0.01066327619849274	0.010910710898614409	100	0.0025	100	50	0.0	0.1	1349
36	0.01065229386796477	0.010771764583002427	100	0.0025	100	50	0.0	0.1	1349
37	0.010582252895831746	0.010844674313985822	100	0.0025	100	50	0.0	0.1	1349
38	0.010645316698331483	0.010821520575245639	100	0.0025	100	50	0.0	0.1	1349
39	0.010654797964827023	0.010819442938820924	100	0.0025	100	50	0.0	0.1	1349
40	0.010646715048258508	0.010812666568100225	100	0.0025	100	50	0.0	0.1	1349
41	0.010687059952183794	0.010788774676977107	100	0.0025	100	50	0.0	0.1	1349
42	0.010620207568630774	0.010937158826802702	100	0.0025	100	50	0.0	0.1	1349
43	0.010628551394036234	0.010841193699756954	100	0.0025	100	50	0.0	0.1	1349
44	0.010649174240492082	0.010878954479830557	100	0.0025	100	50	0.0	0.1	1349
45	0.010624733449459633	0.011350595055728524	100	0.0025	100	50	0.0	0.1	1349
46	0.010652890448391907	0.010798764628773095	100	0.0025	100	50	0.0	0.1	1349
47	0.010622385283481913	0.0107552807877841	100	0.0025	100	50	0.0	0.1	1349
48	0.01065525637766823	0.01091913067972569	100	0.0025	100	50	0.0	0.1	1349
49	0.010613394304350118	0.01115058864116042	100	0.0025	100	50	0.0	0.1	1349
