	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.03206553747787443	0.0216978772349271	25	0.001	50	50	1e-06	0.0	1937
1	0.019228546433273454	0.017662227093233205	25	0.001	50	50	1e-06	0.0	1937
2	0.016795543491231683	0.016252325931439323	25	0.001	50	50	1e-06	0.0	1937
3	0.01571793828393465	0.015391401481773726	25	0.001	50	50	1e-06	0.0	1937
4	0.015119635975816469	0.01489507523231764	25	0.001	50	50	1e-06	0.0	1937
5	0.014733474180426871	0.014808197812057932	25	0.001	50	50	1e-06	0.0	1937
6	0.014518598512703157	0.014390694591827534	25	0.001	50	50	1e-06	0.0	1937
7	0.01426440091505069	0.014258996277235548	25	0.001	50	50	1e-06	0.0	1937
8	0.014130557752301934	0.014106401477372327	25	0.001	50	50	1e-06	0.0	1937
9	0.014021905891824437	0.014020828480331893	25	0.001	50	50	1e-06	0.0	1937
10	0.013850085083884007	0.01384538176859485	25	0.001	50	50	1e-06	0.0	1937
11	0.01380566740829035	0.01392183717817467	25	0.001	50	50	1e-06	0.0	1937
12	0.01370509245565394	0.014083187573056946	25	0.001	50	50	1e-06	0.0	1937
13	0.013688297280470857	0.013970608790948217	25	0.001	50	50	1e-06	0.0	1937
14	0.013570724933164907	0.013554279357693506	25	0.001	50	50	1e-06	0.0	1937
15	0.013511071782244527	0.013548810729475596	25	0.001	50	50	1e-06	0.0	1937
16	0.013460133065630143	0.013442996818123538	25	0.001	50	50	1e-06	0.0	1937
17	0.013416360167420994	0.013488944537980378	25	0.001	50	50	1e-06	0.0	1937
18	0.013354692942139625	0.013463431248088754	25	0.001	50	50	1e-06	0.0	1937
19	0.013440322283385101	0.013354584147323842	25	0.001	50	50	1e-06	0.0	1937
20	0.013280510596185369	0.013339616121442893	25	0.001	50	50	1e-06	0.0	1937
21	0.013241066744921691	0.013262392709078	25	0.001	50	50	1e-06	0.0	1937
22	0.013298955170757666	0.013191641123171177	25	0.001	50	50	1e-06	0.0	1937
23	0.013308562501207506	0.0131697042490824	25	0.001	50	50	1e-06	0.0	1937
24	0.013287989305632884	0.013489636327237974	25	0.001	50	50	1e-06	0.0	1937
25	0.013113632378194425	0.013220455869676163	25	0.001	50	50	1e-06	0.0	1937
26	0.013163520774874204	0.013311179598747088	25	0.001	50	50	1e-06	0.0	1937
27	0.013111781217905828	0.013423822891415875	25	0.001	50	50	1e-06	0.0	1937
28	0.013169812047940144	0.013273393282983773	25	0.001	50	50	1e-06	0.0	1937
29	0.013077125874896409	0.013100465056246029	25	0.001	50	50	1e-06	0.0	1937
30	0.01311264083497436	0.0133396442854923	25	0.001	50	50	1e-06	0.0	1937
31	0.013089073787174322	0.013261403404105006	25	0.001	50	50	1e-06	0.0	1937
32	0.013076548599055783	0.013089708485293342	25	0.001	50	50	1e-06	0.0	1937
33	0.01298641930956108	0.013046673759034556	25	0.001	50	50	1e-06	0.0	1937
34	0.012975489696956562	0.013270272082697251	25	0.001	50	50	1e-06	0.0	1937
35	0.013129787415489246	0.013556828861254807	25	0.001	50	50	1e-06	0.0	1937
36	0.013143156821450975	0.013664225769900569	25	0.001	50	50	1e-06	0.0	1937
37	0.012983980422791438	0.013712873744705326	25	0.001	50	50	1e-06	0.0	1937
38	0.012968179962450269	0.0129350427588017	25	0.001	50	50	1e-06	0.0	1937
39	0.012909750599371763	0.013368982681025168	25	0.001	50	50	1e-06	0.0	1937
40	0.012988350830630258	0.012872306973696552	25	0.001	50	50	1e-06	0.0	1937
41	0.012907703504168961	0.012928036388800431	25	0.001	50	50	1e-06	0.0	1937
42	0.01310323667531944	0.013116695941292306	25	0.001	50	50	1e-06	0.0	1937
43	0.012981135414375657	0.012953718947905542	25	0.001	50	50	1e-06	0.0	1937
44	0.013038258885112482	0.012992977588499823	25	0.001	50	50	1e-06	0.0	1937
45	0.012900173112700187	0.013152327856857394	25	0.001	50	50	1e-06	0.0	1937
46	0.012916839839078301	0.01293177162092286	25	0.001	50	50	1e-06	0.0	1937
47	0.012941896051788202	0.012888705708713309	25	0.001	50	50	1e-06	0.0	1937
48	0.01284588077304946	0.012992460729401153	25	0.001	50	50	1e-06	0.0	1937
49	0.012906688062576435	0.013144875625522369	25	0.001	50	50	1e-06	0.0	1937
