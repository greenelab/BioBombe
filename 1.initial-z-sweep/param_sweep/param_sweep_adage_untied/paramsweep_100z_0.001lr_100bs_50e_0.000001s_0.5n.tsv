	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.041554572721821566	0.027642076542996313	100	0.001	100	50	1e-06	0.5	6595
1	0.026272215064297215	0.022238569622627862	100	0.001	100	50	1e-06	0.5	6595
2	0.022786553124353508	0.019883102521898642	100	0.001	100	50	1e-06	0.5	6595
3	0.02094603264754806	0.019471300926137837	100	0.001	100	50	1e-06	0.5	6595
4	0.019638903823723818	0.018133373357654758	100	0.001	100	50	1e-06	0.5	6595
5	0.018720383427480728	0.017132765540486313	100	0.001	100	50	1e-06	0.5	6595
6	0.018127189837946252	0.01739487319785824	100	0.001	100	50	1e-06	0.5	6595
7	0.01772035761296743	0.01626646043430038	100	0.001	100	50	1e-06	0.5	6595
8	0.017098185959912526	0.017000903614064818	100	0.001	100	50	1e-06	0.5	6595
9	0.01699417517328049	0.015794429345765144	100	0.001	100	50	1e-06	0.5	6595
10	0.01641227338218884	0.015615090090304214	100	0.001	100	50	1e-06	0.5	6595
11	0.016306813754153996	0.015263823475368164	100	0.001	100	50	1e-06	0.5	6595
12	0.016179209121812716	0.015616902858944855	100	0.001	100	50	1e-06	0.5	6595
13	0.015823139961538616	0.014839348445573455	100	0.001	100	50	1e-06	0.5	6595
14	0.015765035873629027	0.014701985729142426	100	0.001	100	50	1e-06	0.5	6595
15	0.01547630143077888	0.015299156023257094	100	0.001	100	50	1e-06	0.5	6595
16	0.015248260668172291	0.014818529975929976	100	0.001	100	50	1e-06	0.5	6595
17	0.015259333055703473	0.0147763189092193	100	0.001	100	50	1e-06	0.5	6595
18	0.015159288874022844	0.015340492439173148	100	0.001	100	50	1e-06	0.5	6595
19	0.015067995393514779	0.014140232339729315	100	0.001	100	50	1e-06	0.5	6595
20	0.015118428685335415	0.014722089017839323	100	0.001	100	50	1e-06	0.5	6595
21	0.015145327274536309	0.014126964980098872	100	0.001	100	50	1e-06	0.5	6595
22	0.014977175391051699	0.013729464230670755	100	0.001	100	50	1e-06	0.5	6595
23	0.01479472190113579	0.014237911004152854	100	0.001	100	50	1e-06	0.5	6595
24	0.014740329452866604	0.013645974931665064	100	0.001	100	50	1e-06	0.5	6595
25	0.014740175822535825	0.014270141238193553	100	0.001	100	50	1e-06	0.5	6595
26	0.014769639053767747	0.014150972056058352	100	0.001	100	50	1e-06	0.5	6595
27	0.014442788406139566	0.014325148970900143	100	0.001	100	50	1e-06	0.5	6595
28	0.014592554318423474	0.014559286708870536	100	0.001	100	50	1e-06	0.5	6595
29	0.014537085453201705	0.014200571911982892	100	0.001	100	50	1e-06	0.5	6595
30	0.014476417895106895	0.013896216536884554	100	0.001	100	50	1e-06	0.5	6595
31	0.014426966180078448	0.013496060585015476	100	0.001	100	50	1e-06	0.5	6595
32	0.014319809124488722	0.013647476072293167	100	0.001	100	50	1e-06	0.5	6595
33	0.01447080726677216	0.013900587634391812	100	0.001	100	50	1e-06	0.5	6595
34	0.014326048896791552	0.013582122645716595	100	0.001	100	50	1e-06	0.5	6595
35	0.014074580441152366	0.01510599519466237	100	0.001	100	50	1e-06	0.5	6595
36	0.014396733100272056	0.014655967764770095	100	0.001	100	50	1e-06	0.5	6595
37	0.014174583413713665	0.015208927747111476	100	0.001	100	50	1e-06	0.5	6595
38	0.014199313336525627	0.013898038045355398	100	0.001	100	50	1e-06	0.5	6595
39	0.014147231190772203	0.013686403822702272	100	0.001	100	50	1e-06	0.5	6595
40	0.014244976568451428	0.013514369717277373	100	0.001	100	50	1e-06	0.5	6595
41	0.014064193384053634	0.013508464654918268	100	0.001	100	50	1e-06	0.5	6595
42	0.014212072810794714	0.013208288118870036	100	0.001	100	50	1e-06	0.5	6595
43	0.014450104279974138	0.013836926522435011	100	0.001	100	50	1e-06	0.5	6595
44	0.014130744534273255	0.013573478827213808	100	0.001	100	50	1e-06	0.5	6595
45	0.013962298692714094	0.013189626437385724	100	0.001	100	50	1e-06	0.5	6595
46	0.014068297166498012	0.014098499427918153	100	0.001	100	50	1e-06	0.5	6595
47	0.014336307272081527	0.013347052096480051	100	0.001	100	50	1e-06	0.5	6595
48	0.013910109011309346	0.013386458671343714	100	0.001	100	50	1e-06	0.5	6595
49	0.01419144574622824	0.013569574217253274	100	0.001	100	50	1e-06	0.5	6595
