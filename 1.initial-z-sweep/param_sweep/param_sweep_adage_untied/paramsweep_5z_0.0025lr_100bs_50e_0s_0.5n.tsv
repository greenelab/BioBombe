	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.04272876770961719	0.034859900699347884	5	0.0025	100	50	0.0	0.5	3625
1	0.034078170771675055	0.034638082768846425	5	0.0025	100	50	0.0	0.5	3625
2	0.03390345452488906	0.03436922427288205	5	0.0025	100	50	0.0	0.5	3625
3	0.03369950049925937	0.03412774731592056	5	0.0025	100	50	0.0	0.5	3625
4	0.03346366938577566	0.03385692549224793	5	0.0025	100	50	0.0	0.5	3625
5	0.033225151624826976	0.033537982341550275	5	0.0025	100	50	0.0	0.5	3625
6	0.0329764896846851	0.03323359376471312	5	0.0025	100	50	0.0	0.5	3625
7	0.03272253462587066	0.03295996566490051	5	0.0025	100	50	0.0	0.5	3625
8	0.0324927196682329	0.032717253941593846	5	0.0025	100	50	0.0	0.5	3625
9	0.03222917407334744	0.032417459132053655	5	0.0025	100	50	0.0	0.5	3625
10	0.031974277659636445	0.032163339294849345	5	0.0025	100	50	0.0	0.5	3625
11	0.03174785277177458	0.03194549493135503	5	0.0025	100	50	0.0	0.5	3625
12	0.03154277993496921	0.03177340555202437	5	0.0025	100	50	0.0	0.5	3625
13	0.031346411089150976	0.03153428178900287	5	0.0025	100	50	0.0	0.5	3625
14	0.03114445484136973	0.031318288032912846	5	0.0025	100	50	0.0	0.5	3625
15	0.03095862735567432	0.03126376311706083	5	0.0025	100	50	0.0	0.5	3625
16	0.03080563433428766	0.03102056506885853	5	0.0025	100	50	0.0	0.5	3625
17	0.030666659577919548	0.03083222751179799	5	0.0025	100	50	0.0	0.5	3625
18	0.030544571568608653	0.030722672906819994	5	0.0025	100	50	0.0	0.5	3625
19	0.03044124539558849	0.03064720655291076	5	0.0025	100	50	0.0	0.5	3625
20	0.030342535661828512	0.03051790460431325	5	0.0025	100	50	0.0	0.5	3625
21	0.030234689092225785	0.030441445414240455	5	0.0025	100	50	0.0	0.5	3625
22	0.030182832442789964	0.030467343454322213	5	0.0025	100	50	0.0	0.5	3625
23	0.030107350338281665	0.03041361582894626	5	0.0025	100	50	0.0	0.5	3625
24	0.030076029877185592	0.0302864331930135	5	0.0025	100	50	0.0	0.5	3625
25	0.029998517557535378	0.03024685233973864	5	0.0025	100	50	0.0	0.5	3625
26	0.029957930623224917	0.030196981679071203	5	0.0025	100	50	0.0	0.5	3625
27	0.02991796931605891	0.030203076973415014	5	0.0025	100	50	0.0	0.5	3625
28	0.029889378030615737	0.03016982492536705	5	0.0025	100	50	0.0	0.5	3625
29	0.029872527443174094	0.030103443144156417	5	0.0025	100	50	0.0	0.5	3625
30	0.02982546747048204	0.030118018267658427	5	0.0025	100	50	0.0	0.5	3625
31	0.029822381115950383	0.030055801966450184	5	0.0025	100	50	0.0	0.5	3625
32	0.029792605726623983	0.030038349508498412	5	0.0025	100	50	0.0	0.5	3625
33	0.029772217593343888	0.030064598965257348	5	0.0025	100	50	0.0	0.5	3625
34	0.029747498062896664	0.030090337188248426	5	0.0025	100	50	0.0	0.5	3625
35	0.029742679952574652	0.030011540602885516	5	0.0025	100	50	0.0	0.5	3625
36	0.029715585700544656	0.02998142648865798	5	0.0025	100	50	0.0	0.5	3625
37	0.029716677598447053	0.02998279688976007	5	0.0025	100	50	0.0	0.5	3625
38	0.029698512878739515	0.02997359155497405	5	0.0025	100	50	0.0	0.5	3625
39	0.029701749062919343	0.030064281596166455	5	0.0025	100	50	0.0	0.5	3625
40	0.029685143412226486	0.029937754269425774	5	0.0025	100	50	0.0	0.5	3625
41	0.02968143032835835	0.029926263266038255	5	0.0025	100	50	0.0	0.5	3625
42	0.02966650481564667	0.029936206201180444	5	0.0025	100	50	0.0	0.5	3625
43	0.029665445913257437	0.029934830237073152	5	0.0025	100	50	0.0	0.5	3625
44	0.029653735123246254	0.029927727768115742	5	0.0025	100	50	0.0	0.5	3625
45	0.02964589338281463	0.029927009919633374	5	0.0025	100	50	0.0	0.5	3625
46	0.02963006426538201	0.030015368399212056	5	0.0025	100	50	0.0	0.5	3625
47	0.029652559174198814	0.02994137619182211	5	0.0025	100	50	0.0	0.5	3625
48	0.029632377903364322	0.029914772682903375	5	0.0025	100	50	0.0	0.5	3625
49	0.029621320851736858	0.029863205704531753	5	0.0025	100	50	0.0	0.5	3625
