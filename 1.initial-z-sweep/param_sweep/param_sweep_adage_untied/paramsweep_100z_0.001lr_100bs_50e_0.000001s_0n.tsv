	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.04055154876415235	0.02747443418800261	100	0.001	100	50	1e-06	0.0	176
1	0.02359100186089793	0.02171362474218837	100	0.001	100	50	1e-06	0.0	176
2	0.02003958910827532	0.019217926688335593	100	0.001	100	50	1e-06	0.0	176
3	0.018504086659161968	0.018447874235007093	100	0.001	100	50	1e-06	0.0	176
4	0.017380213239502795	0.017320956094600045	100	0.001	100	50	1e-06	0.0	176
5	0.016894751326639583	0.017853175505397424	100	0.001	100	50	1e-06	0.0	176
6	0.016381904042261503	0.016820085591086352	100	0.001	100	50	1e-06	0.0	176
7	0.01584511756375361	0.015747516969820737	100	0.001	100	50	1e-06	0.0	176
8	0.015482112633128304	0.01493707222126809	100	0.001	100	50	1e-06	0.0	176
9	0.015189336659718203	0.015413195446817414	100	0.001	100	50	1e-06	0.0	176
10	0.014844339172430332	0.014743447987572869	100	0.001	100	50	1e-06	0.0	176
11	0.014809765524605781	0.015090687157689499	100	0.001	100	50	1e-06	0.0	176
12	0.014579411460907708	0.014368218325263683	100	0.001	100	50	1e-06	0.0	176
13	0.014400894030877954	0.015051536993916016	100	0.001	100	50	1e-06	0.0	176
14	0.014246693460183101	0.014075118809738989	100	0.001	100	50	1e-06	0.0	176
15	0.014034339836055074	0.015018575990405182	100	0.001	100	50	1e-06	0.0	176
16	0.014068856464735914	0.014919361268770285	100	0.001	100	50	1e-06	0.0	176
17	0.014034925297996537	0.013882839799383175	100	0.001	100	50	1e-06	0.0	176
18	0.013772972988361103	0.01348904829408197	100	0.001	100	50	1e-06	0.0	176
19	0.013498803464923175	0.013588149159306208	100	0.001	100	50	1e-06	0.0	176
20	0.013557515939180958	0.013348447550693615	100	0.001	100	50	1e-06	0.0	176
21	0.013611863714835856	0.013546119394211764	100	0.001	100	50	1e-06	0.0	176
22	0.013361926403474056	0.01455803130384727	100	0.001	100	50	1e-06	0.0	176
23	0.013436388328349307	0.014097946806388763	100	0.001	100	50	1e-06	0.0	176
24	0.013237293137156892	0.013844248331214228	100	0.001	100	50	1e-06	0.0	176
25	0.013327445608104541	0.014110421687079662	100	0.001	100	50	1e-06	0.0	176
26	0.013439496573463239	0.013238633149454858	100	0.001	100	50	1e-06	0.0	176
27	0.013087835243217346	0.013654388699246069	100	0.001	100	50	1e-06	0.0	176
28	0.013109876315763326	0.012608813953516474	100	0.001	100	50	1e-06	0.0	176
29	0.012962876400854615	0.01307917571311414	100	0.001	100	50	1e-06	0.0	176
30	0.012850358763437184	0.013812694869522383	100	0.001	100	50	1e-06	0.0	176
31	0.01295055155918868	0.012450087947297279	100	0.001	100	50	1e-06	0.0	176
32	0.012812897747009121	0.013654372752795484	100	0.001	100	50	1e-06	0.0	176
33	0.012754454012989086	0.01319147766804604	100	0.001	100	50	1e-06	0.0	176
34	0.01296414081782932	0.013036741429929182	100	0.001	100	50	1e-06	0.0	176
35	0.01272656984892802	0.012915097946304663	100	0.001	100	50	1e-06	0.0	176
36	0.012899198019646545	0.012370097588028324	100	0.001	100	50	1e-06	0.0	176
37	0.012483343088730867	0.014135237142130249	100	0.001	100	50	1e-06	0.0	176
38	0.012742746881978375	0.013171678578149862	100	0.001	100	50	1e-06	0.0	176
39	0.012604233964250278	0.01296476780278448	100	0.001	100	50	1e-06	0.0	176
40	0.01279281456582268	0.01265611522697468	100	0.001	100	50	1e-06	0.0	176
41	0.012418505617264137	0.013225596606460744	100	0.001	100	50	1e-06	0.0	176
42	0.012827553556301788	0.012926944593825943	100	0.001	100	50	1e-06	0.0	176
43	0.012647720406414294	0.01316791645698178	100	0.001	100	50	1e-06	0.0	176
44	0.01242829135797295	0.012705344327477948	100	0.001	100	50	1e-06	0.0	176
45	0.012444228504470864	0.012786464601840618	100	0.001	100	50	1e-06	0.0	176
46	0.012469087140455574	0.01259129917352366	100	0.001	100	50	1e-06	0.0	176
47	0.012642683897139345	0.01230387037431191	100	0.001	100	50	1e-06	0.0	176
48	0.012413938602213556	0.0126530736414128	100	0.001	100	50	1e-06	0.0	176
49	0.012303006776214646	0.012836250396406217	100	0.001	100	50	1e-06	0.0	176
