	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.03913574176506562	0.03354379219175753	5	0.001	50	50	0.0	0.1	9742
1	0.030032851842002408	0.028823434074282873	5	0.001	50	50	0.0	0.1	9742
2	0.028753076838803356	0.028547182956970445	5	0.001	50	50	0.0	0.1	9742
3	0.028543028146824787	0.028337012620261705	5	0.001	50	50	0.0	0.1	9742
4	0.02837133624865096	0.028167694333378034	5	0.001	50	50	0.0	0.1	9742
5	0.028199692171561305	0.02801368454645742	5	0.001	50	50	0.0	0.1	9742
6	0.028053594710601957	0.027861773629403935	5	0.001	50	50	0.0	0.1	9742
7	0.027902939270093085	0.027720093591776223	5	0.001	50	50	0.0	0.1	9742
8	0.027762197088270123	0.027564925688317126	5	0.001	50	50	0.0	0.1	9742
9	0.02765511990252051	0.027429017492963524	5	0.001	50	50	0.0	0.1	9742
10	0.027539688017162712	0.027319141736620926	5	0.001	50	50	0.0	0.1	9742
11	0.027451823173356173	0.0272567294160506	5	0.001	50	50	0.0	0.1	9742
12	0.02737574164082751	0.027174186955133087	5	0.001	50	50	0.0	0.1	9742
13	0.027315848931143038	0.02709454623180981	5	0.001	50	50	0.0	0.1	9742
14	0.027248703352541037	0.027056726956487157	5	0.001	50	50	0.0	0.1	9742
15	0.02720008718761484	0.0269960992707805	5	0.001	50	50	0.0	0.1	9742
16	0.0271636507368317	0.02695770432413992	5	0.001	50	50	0.0	0.1	9742
17	0.027113192390128504	0.02690153036900506	5	0.001	50	50	0.0	0.1	9742
18	0.027079584797679853	0.026903897694830228	5	0.001	50	50	0.0	0.1	9742
19	0.027048707788009312	0.026859023139934924	5	0.001	50	50	0.0	0.1	9742
20	0.02703114920148849	0.02686923402174595	5	0.001	50	50	0.0	0.1	9742
21	0.02700565508234853	0.026810334831561686	5	0.001	50	50	0.0	0.1	9742
22	0.02697664084882383	0.026769634293495582	5	0.001	50	50	0.0	0.1	9742
23	0.026961721637207392	0.026714541484560837	5	0.001	50	50	0.0	0.1	9742
24	0.026939000672369193	0.026718946373229045	5	0.001	50	50	0.0	0.1	9742
25	0.026916539681780344	0.02667749466563274	5	0.001	50	50	0.0	0.1	9742
26	0.026908624492618112	0.02664885853005869	5	0.001	50	50	0.0	0.1	9742
27	0.026889146427811615	0.026654404169571787	5	0.001	50	50	0.0	0.1	9742
28	0.02688616519726787	0.026689069025061782	5	0.001	50	50	0.0	0.1	9742
29	0.026864078890425004	0.026657802823852626	5	0.001	50	50	0.0	0.1	9742
30	0.026850976604360026	0.026602185443471083	5	0.001	50	50	0.0	0.1	9742
31	0.02684243368419238	0.026590019884745433	5	0.001	50	50	0.0	0.1	9742
32	0.026831745132360665	0.026607180790651597	5	0.001	50	50	0.0	0.1	9742
33	0.026819192198388422	0.02661476693833763	5	0.001	50	50	0.0	0.1	9742
34	0.02682096607512949	0.026614487156927245	5	0.001	50	50	0.0	0.1	9742
35	0.02681092880658341	0.026584613185026907	5	0.001	50	50	0.0	0.1	9742
36	0.026796850823930556	0.02659863645271407	5	0.001	50	50	0.0	0.1	9742
37	0.02679978993431511	0.026560297232285056	5	0.001	50	50	0.0	0.1	9742
38	0.026795141979091087	0.026583432114859383	5	0.001	50	50	0.0	0.1	9742
39	0.026777702854552672	0.026580998025848807	5	0.001	50	50	0.0	0.1	9742
40	0.026769919995118387	0.026548317873967994	5	0.001	50	50	0.0	0.1	9742
41	0.02676265098314432	0.02649860798486332	5	0.001	50	50	0.0	0.1	9742
42	0.026760228008703053	0.026523301712670016	5	0.001	50	50	0.0	0.1	9742
43	0.026752505124345047	0.02650251191458442	5	0.001	50	50	0.0	0.1	9742
44	0.026756647470647908	0.026501240625436174	5	0.001	50	50	0.0	0.1	9742
45	0.026745863507969668	0.02651589160810009	5	0.001	50	50	0.0	0.1	9742
46	0.026743897565265625	0.026492735620296023	5	0.001	50	50	0.0	0.1	9742
47	0.026736927024911684	0.026497545693048328	5	0.001	50	50	0.0	0.1	9742
48	0.026735817409223102	0.02649452986754833	5	0.001	50	50	0.0	0.1	9742
49	0.026728284326486364	0.026487948554594704	5	0.001	50	50	0.0	0.1	9742
