	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.025880149891248774	0.019243455401142744	75	0.002	50	50	1e-06	0.0	3487
1	0.01628324163953569	0.015147211306139	75	0.002	50	50	1e-06	0.0	3487
2	0.014893385782124707	0.014047034451627595	75	0.002	50	50	1e-06	0.0	3487
3	0.014369399166792318	0.013969423301005113	75	0.002	50	50	1e-06	0.0	3487
4	0.013781808223901855	0.01344578045404322	75	0.002	50	50	1e-06	0.0	3487
5	0.013579289857102234	0.01401466903869725	75	0.002	50	50	1e-06	0.0	3487
6	0.013433301741308561	0.0148255576951212	75	0.002	50	50	1e-06	0.0	3487
7	0.013239613313888416	0.01300215122804587	75	0.002	50	50	1e-06	0.0	3487
8	0.013121212314183884	0.012928679133151048	75	0.002	50	50	1e-06	0.0	3487
9	0.01305079313455543	0.01336138092166607	75	0.002	50	50	1e-06	0.0	3487
10	0.012714803272071293	0.014599728173652867	75	0.002	50	50	1e-06	0.0	3487
11	0.012831370612297912	0.012640825430034565	75	0.002	50	50	1e-06	0.0	3487
12	0.012730555328175712	0.012972524355790696	75	0.002	50	50	1e-06	0.0	3487
13	0.01267348738525941	0.012706428297918225	75	0.002	50	50	1e-06	0.0	3487
14	0.01276992845630894	0.0124011574701244	75	0.002	50	50	1e-06	0.0	3487
15	0.012764453029634627	0.0137107804770195	75	0.002	50	50	1e-06	0.0	3487
16	0.01257774051778279	0.013490267304514835	75	0.002	50	50	1e-06	0.0	3487
17	0.012614508807219064	0.012746579512369679	75	0.002	50	50	1e-06	0.0	3487
18	0.012658428030917069	0.012938560406903579	75	0.002	50	50	1e-06	0.0	3487
19	0.012664582936215304	0.012922029317237337	75	0.002	50	50	1e-06	0.0	3487
20	0.012407525120391883	0.012687963068513752	75	0.002	50	50	1e-06	0.0	3487
21	0.012461223280989128	0.013847056368497658	75	0.002	50	50	1e-06	0.0	3487
22	0.013004679277259847	0.013125978488596174	75	0.002	50	50	1e-06	0.0	3487
23	0.012444494503772748	0.014318626482630893	75	0.002	50	50	1e-06	0.0	3487
24	0.012508938263345447	0.013895438318042864	75	0.002	50	50	1e-06	0.0	3487
25	0.012577317115962251	0.01461644825591469	75	0.002	50	50	1e-06	0.0	3487
26	0.012365129357683701	0.012398017438602265	75	0.002	50	50	1e-06	0.0	3487
27	0.012874225563932957	0.012737837600491471	75	0.002	50	50	1e-06	0.0	3487
28	0.012472627562678805	0.013152387587934106	75	0.002	50	50	1e-06	0.0	3487
29	0.012477409465795088	0.012472002638813756	75	0.002	50	50	1e-06	0.0	3487
30	0.01266840625026775	0.012790782621084048	75	0.002	50	50	1e-06	0.0	3487
31	0.012542887048535211	0.013797253147693596	75	0.002	50	50	1e-06	0.0	3487
32	0.01231296443552868	0.012361716318797199	75	0.002	50	50	1e-06	0.0	3487
33	0.012396724406967385	0.012193124623787563	75	0.002	50	50	1e-06	0.0	3487
34	0.012563362617303281	0.013762818553251701	75	0.002	50	50	1e-06	0.0	3487
35	0.012702221097855015	0.012638763894984075	75	0.002	50	50	1e-06	0.0	3487
36	0.012348837562302727	0.012523301764895309	75	0.002	50	50	1e-06	0.0	3487
37	0.01255665507361896	0.012391920899527138	75	0.002	50	50	1e-06	0.0	3487
38	0.012491962663781045	0.01250019446585192	75	0.002	50	50	1e-06	0.0	3487
39	0.01240448510680143	0.01221938060870818	75	0.002	50	50	1e-06	0.0	3487
40	0.01226547144918931	0.013645360782300879	75	0.002	50	50	1e-06	0.0	3487
41	0.01261295300767793	0.012335236369495068	75	0.002	50	50	1e-06	0.0	3487
42	0.012562245137959444	0.012925083120398037	75	0.002	50	50	1e-06	0.0	3487
43	0.012313615478093193	0.011954427041455277	75	0.002	50	50	1e-06	0.0	3487
44	0.01241596064807444	0.013109364929692694	75	0.002	50	50	1e-06	0.0	3487
45	0.012243247154633506	0.012348291679618463	75	0.002	50	50	1e-06	0.0	3487
46	0.012527593918770796	0.01439016327140835	75	0.002	50	50	1e-06	0.0	3487
47	0.012546514569553467	0.014896782533573717	75	0.002	50	50	1e-06	0.0	3487
48	0.01258634855197227	0.012175683997015881	75	0.002	50	50	1e-06	0.0	3487
49	0.01225825004834865	0.013245227529416235	75	0.002	50	50	1e-06	0.0	3487
