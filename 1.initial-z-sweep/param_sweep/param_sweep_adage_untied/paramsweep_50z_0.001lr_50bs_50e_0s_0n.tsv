	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.028803837740382036	0.02020458447930348	50	0.001	50	50	0.0	0.0	1440
1	0.01739543167122075	0.015948834515623678	50	0.001	50	50	0.0	0.0	1440
2	0.014992897502360075	0.014721952371626922	50	0.001	50	50	0.0	0.0	1440
3	0.014175381592679585	0.01420693276681533	50	0.001	50	50	0.0	0.0	1440
4	0.013848943977955993	0.0140456383456663	50	0.001	50	50	0.0	0.0	1440
5	0.013721668111388157	0.013928709346907887	50	0.001	50	50	0.0	0.0	1440
6	0.013663165468568631	0.013875049608358917	50	0.001	50	50	0.0	0.0	1440
7	0.013616984973079933	0.01384060273933479	50	0.001	50	50	0.0	0.0	1440
8	0.013590945486063615	0.013870426158048569	50	0.001	50	50	0.0	0.0	1440
9	0.013563295743404128	0.01377615848125224	50	0.001	50	50	0.0	0.0	1440
10	0.013538984204173994	0.013772431809106133	50	0.001	50	50	0.0	0.0	1440
11	0.013525573385276457	0.013743712196400812	50	0.001	50	50	0.0	0.0	1440
12	0.013503358413246763	0.013759725915898443	50	0.001	50	50	0.0	0.0	1440
13	0.013496428529036281	0.01375066227747936	50	0.001	50	50	0.0	0.0	1440
14	0.013482017362541548	0.013727598739912587	50	0.001	50	50	0.0	0.0	1440
15	0.013471814926761591	0.013718914794406175	50	0.001	50	50	0.0	0.0	1440
16	0.013461644789066475	0.013712641435816	50	0.001	50	50	0.0	0.0	1440
17	0.013453009659257215	0.01375648591054842	50	0.001	50	50	0.0	0.0	1440
18	0.01344445054497996	0.013687028521119865	50	0.001	50	50	0.0	0.0	1440
19	0.013435332915377322	0.013680907755192675	50	0.001	50	50	0.0	0.0	1440
20	0.013423769562050556	0.013677018662526434	50	0.001	50	50	0.0	0.0	1440
21	0.01342699906362236	0.013711442018771832	50	0.001	50	50	0.0	0.0	1440
22	0.013422669900818102	0.013681454655231755	50	0.001	50	50	0.0	0.0	1440
23	0.013401992342895982	0.013648518685244351	50	0.001	50	50	0.0	0.0	1440
24	0.01340223859970275	0.013670654620184611	50	0.001	50	50	0.0	0.0	1440
25	0.013393360567154	0.013665713743799959	50	0.001	50	50	0.0	0.0	1440
26	0.013385821887676152	0.013684546907947008	50	0.001	50	50	0.0	0.0	1440
27	0.013383128056273974	0.013671989112835996	50	0.001	50	50	0.0	0.0	1440
28	0.013377121238982425	0.013626933632058805	50	0.001	50	50	0.0	0.0	1440
29	0.013370799347140907	0.013610384968353388	50	0.001	50	50	0.0	0.0	1440
30	0.013369353401811942	0.013632762593076516	50	0.001	50	50	0.0	0.0	1440
31	0.013365176528404132	0.013625858070232671	50	0.001	50	50	0.0	0.0	1440
32	0.013358435975552922	0.013614039517312273	50	0.001	50	50	0.0	0.0	1440
33	0.013351480779512604	0.013629840793761195	50	0.001	50	50	0.0	0.0	1440
34	0.013350481606432592	0.013634878741381386	50	0.001	50	50	0.0	0.0	1440
35	0.013343095899532151	0.013591107392388023	50	0.001	50	50	0.0	0.0	1440
36	0.013337381641599838	0.013608132736547271	50	0.001	50	50	0.0	0.0	1440
37	0.01333781083388608	0.013583466704457599	50	0.001	50	50	0.0	0.0	1440
38	0.013324704101060049	0.013609925886868974	50	0.001	50	50	0.0	0.0	1440
39	0.013320243328217681	0.013617401094982547	50	0.001	50	50	0.0	0.0	1440
40	0.01331591806671805	0.013636383742635382	50	0.001	50	50	0.0	0.0	1440
41	0.013320080247530265	0.013657390891465698	50	0.001	50	50	0.0	0.0	1440
42	0.013321504229753908	0.0135665541927884	50	0.001	50	50	0.0	0.0	1440
43	0.013298932610549215	0.01357858516916946	50	0.001	50	50	0.0	0.0	1440
44	0.013307923121892511	0.01359530467803574	50	0.001	50	50	0.0	0.0	1440
45	0.013296592893556012	0.013591047495703282	50	0.001	50	50	0.0	0.0	1440
46	0.013300389525558039	0.01358449147091769	50	0.001	50	50	0.0	0.0	1440
47	0.013300092868003502	0.013621103547399519	50	0.001	50	50	0.0	0.0	1440
48	0.013288777900277353	0.013564136490069087	50	0.001	50	50	0.0	0.0	1440
49	0.013289414540635282	0.013578819557953177	50	0.001	50	50	0.0	0.0	1440
