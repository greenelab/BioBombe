	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.04142569125285947	0.03382953607528889	5	0.0015	100	50	0.0	0.1	2917
1	0.031962089664014356	0.029232822842967215	5	0.0015	100	50	0.0	0.1	2917
2	0.029062282414939685	0.028505490312840696	5	0.0015	100	50	0.0	0.1	2917
3	0.0286848037419066	0.028353011360245955	5	0.0015	100	50	0.0	0.1	2917
4	0.028522547001994074	0.028142937713696213	5	0.0015	100	50	0.0	0.1	2917
5	0.028381906566544015	0.028119614896280815	5	0.0015	100	50	0.0	0.1	2917
6	0.028253615333479143	0.0278871159387991	5	0.0015	100	50	0.0	0.1	2917
7	0.028120068872016422	0.027791286140224445	5	0.0015	100	50	0.0	0.1	2917
8	0.02798734678389459	0.027640089556489347	5	0.0015	100	50	0.0	0.1	2917
9	0.027869327590827237	0.02759916660862033	5	0.0015	100	50	0.0	0.1	2917
10	0.027767375978690386	0.02744703703910739	5	0.0015	100	50	0.0	0.1	2917
11	0.027660305456750186	0.027361037426879255	5	0.0015	100	50	0.0	0.1	2917
12	0.027573068874069788	0.027283453943482094	5	0.0015	100	50	0.0	0.1	2917
13	0.027491176675842468	0.027286073794841312	5	0.0015	100	50	0.0	0.1	2917
14	0.0274408966782533	0.02714367793876514	5	0.0015	100	50	0.0	0.1	2917
15	0.02736261702221511	0.02708706593080415	5	0.0015	100	50	0.0	0.1	2917
16	0.02731393981385811	0.027091692370962685	5	0.0015	100	50	0.0	0.1	2917
17	0.027280876057595094	0.02701315563350175	5	0.0015	100	50	0.0	0.1	2917
18	0.02721645127125872	0.026965469909016306	5	0.0015	100	50	0.0	0.1	2917
19	0.027198030055439918	0.02693905261475201	5	0.0015	100	50	0.0	0.1	2917
20	0.027148381428068635	0.026911887455995178	5	0.0015	100	50	0.0	0.1	2917
21	0.02713063014988804	0.026906729976773035	5	0.0015	100	50	0.0	0.1	2917
22	0.027101505488200013	0.026845140489491406	5	0.0015	100	50	0.0	0.1	2917
23	0.027073429975985948	0.026833711145712813	5	0.0015	100	50	0.0	0.1	2917
24	0.027048475082623747	0.026776318543414314	5	0.0015	100	50	0.0	0.1	2917
25	0.02702653767915242	0.026836273101929497	5	0.0015	100	50	0.0	0.1	2917
26	0.027015020865240578	0.026748627605874726	5	0.0015	100	50	0.0	0.1	2917
27	0.0269955517841895	0.0267549546517389	5	0.0015	100	50	0.0	0.1	2917
28	0.026965288721989854	0.026754806355981025	5	0.0015	100	50	0.0	0.1	2917
29	0.026965554717334136	0.026707005129689012	5	0.0015	100	50	0.0	0.1	2917
30	0.02694491155087017	0.026750068338748146	5	0.0015	100	50	0.0	0.1	2917
31	0.02693841508546646	0.026715320565276573	5	0.0015	100	50	0.0	0.1	2917
32	0.02691909030252393	0.026694698066915427	5	0.0015	100	50	0.0	0.1	2917
33	0.026915924949121314	0.02666710000876943	5	0.0015	100	50	0.0	0.1	2917
34	0.026897195419721076	0.026673321881069734	5	0.0015	100	50	0.0	0.1	2917
35	0.026900569758228868	0.026647978335846905	5	0.0015	100	50	0.0	0.1	2917
36	0.026873398175456947	0.02661856157744364	5	0.0015	100	50	0.0	0.1	2917
37	0.02686401193295239	0.026614971658353824	5	0.0015	100	50	0.0	0.1	2917
38	0.02684638945412132	0.026630558162557237	5	0.0015	100	50	0.0	0.1	2917
39	0.026850448620742987	0.026608092546548487	5	0.0015	100	50	0.0	0.1	2917
40	0.026839165604316845	0.02663251183870076	5	0.0015	100	50	0.0	0.1	2917
41	0.02683462650114135	0.02662227308488029	5	0.0015	100	50	0.0	0.1	2917
42	0.026820219423937315	0.026588397328501448	5	0.0015	100	50	0.0	0.1	2917
43	0.02680729187290467	0.02659709953897086	5	0.0015	100	50	0.0	0.1	2917
44	0.026810635912806843	0.026571190796692786	5	0.0015	100	50	0.0	0.1	2917
45	0.02680127760206432	0.026561232237412413	5	0.0015	100	50	0.0	0.1	2917
46	0.02681112780468118	0.026566854345097597	5	0.0015	100	50	0.0	0.1	2917
47	0.02679733041656881	0.026546454901164165	5	0.0015	100	50	0.0	0.1	2917
48	0.026794688767428722	0.026535877715760617	5	0.0015	100	50	0.0	0.1	2917
49	0.026779703392630288	0.02657308740395319	5	0.0015	100	50	0.0	0.1	2917
