	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.026048413153611536	0.017053782947033816	50	0.0015	50	50	0.0	0.5	333
1	0.016195047784485474	0.014542740183823651	50	0.0015	50	50	0.0	0.5	333
2	0.014565227808019002	0.013284688010583872	50	0.0015	50	50	0.0	0.5	333
3	0.013847370384741663	0.012966990079125301	50	0.0015	50	50	0.0	0.5	333
4	0.01364111769520966	0.012774432462641887	50	0.0015	50	50	0.0	0.5	333
5	0.013559112790823584	0.01274494125719679	50	0.0015	50	50	0.0	0.5	333
6	0.013533082314375437	0.012685945252202324	50	0.0015	50	50	0.0	0.5	333
7	0.013489924355115297	0.012959818922011734	50	0.0015	50	50	0.0	0.5	333
8	0.013464630852138485	0.012640802469282602	50	0.0015	50	50	0.0	0.5	333
9	0.013478150898166232	0.0127192298288726	50	0.0015	50	50	0.0	0.5	333
10	0.013457817622190022	0.012702622055565764	50	0.0015	50	50	0.0	0.5	333
11	0.01342966624780101	0.012715052496321343	50	0.0015	50	50	0.0	0.5	333
12	0.013425923590953496	0.012711883317786011	50	0.0015	50	50	0.0	0.5	333
13	0.013428298204889506	0.012699023085017733	50	0.0015	50	50	0.0	0.5	333
14	0.013424381825265185	0.012653533410259574	50	0.0015	50	50	0.0	0.5	333
15	0.013425243429643314	0.012600051917591584	50	0.0015	50	50	0.0	0.5	333
16	0.013411846732853115	0.012576722395722087	50	0.0015	50	50	0.0	0.5	333
17	0.013405757162114056	0.012632673812841366	50	0.0015	50	50	0.0	0.5	333
18	0.013388216115584172	0.012645430088285392	50	0.0015	50	50	0.0	0.5	333
19	0.013409031019790968	0.012634420081844863	50	0.0015	50	50	0.0	0.5	333
20	0.01339711119401731	0.012572445655615562	50	0.0015	50	50	0.0	0.5	333
21	0.013376353108996408	0.01260579938877438	50	0.0015	50	50	0.0	0.5	333
22	0.013389993144554843	0.012565142893540472	50	0.0015	50	50	0.0	0.5	333
23	0.013381638916198061	0.012522765431716952	50	0.0015	50	50	0.0	0.5	333
24	0.01338930434399845	0.012629580064311653	50	0.0015	50	50	0.0	0.5	333
25	0.013375407346123294	0.012594947352805967	50	0.0015	50	50	0.0	0.5	333
26	0.013368368320860436	0.012647643906151588	50	0.0015	50	50	0.0	0.5	333
27	0.013373724538344138	0.012577918849629038	50	0.0015	50	50	0.0	0.5	333
28	0.013360208882582684	0.01260098848798193	50	0.0015	50	50	0.0	0.5	333
29	0.013359581117344014	0.012635370930140378	50	0.0015	50	50	0.0	0.5	333
30	0.013380397894089962	0.012619064777135052	50	0.0015	50	50	0.0	0.5	333
31	0.013352056077937638	0.012662762583698186	50	0.0015	50	50	0.0	0.5	333
32	0.01336930087256714	0.012652172422104197	50	0.0015	50	50	0.0	0.5	333
33	0.013355053433234027	0.012729667663132598	50	0.0015	50	50	0.0	0.5	333
34	0.013362507442696896	0.012598684582909138	50	0.0015	50	50	0.0	0.5	333
35	0.013353162713849107	0.012581639262503922	50	0.0015	50	50	0.0	0.5	333
36	0.013324583401337771	0.012695653013258203	50	0.0015	50	50	0.0	0.5	333
37	0.013343185602626846	0.012622595759354404	50	0.0015	50	50	0.0	0.5	333
38	0.013321828145981405	0.012631110091966151	50	0.0015	50	50	0.0	0.5	333
39	0.013315992764566633	0.012712271307126741	50	0.0015	50	50	0.0	0.5	333
40	0.013317953981201896	0.01259361389297885	50	0.0015	50	50	0.0	0.5	333
41	0.013303087257077562	0.012720787945785782	50	0.0015	50	50	0.0	0.5	333
42	0.013316891032264062	0.012598339893835566	50	0.0015	50	50	0.0	0.5	333
43	0.013321876651631695	0.012597005588160988	50	0.0015	50	50	0.0	0.5	333
44	0.013313411734503526	0.012565839537072136	50	0.0015	50	50	0.0	0.5	333
45	0.013295325944309981	0.012715651174690253	50	0.0015	50	50	0.0	0.5	333
46	0.01331299358511277	0.012563294090017193	50	0.0015	50	50	0.0	0.5	333
47	0.013285257526966536	0.012575501102391438	50	0.0015	50	50	0.0	0.5	333
48	0.013293344286267175	0.012589071248702519	50	0.0015	50	50	0.0	0.5	333
49	0.013270707615273932	0.012597646706703745	50	0.0015	50	50	0.0	0.5	333
