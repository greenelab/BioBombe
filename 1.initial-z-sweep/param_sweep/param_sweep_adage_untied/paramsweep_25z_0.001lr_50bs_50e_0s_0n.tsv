	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.03347926687330093	0.023455374355981728	25	0.001	50	50	0.0	0.0	4815
1	0.020656738506049682	0.019100235351299007	25	0.001	50	50	0.0	0.0	4815
2	0.018753599186708783	0.018617050227198045	25	0.001	50	50	0.0	0.0	4815
3	0.018479520974833744	0.018450462449890476	25	0.001	50	50	0.0	0.0	4815
4	0.018362872040143217	0.018396201830207733	25	0.001	50	50	0.0	0.0	4815
5	0.018293602788629116	0.018333525915076355	25	0.001	50	50	0.0	0.0	4815
6	0.01824453516565378	0.018252302352944477	25	0.001	50	50	0.0	0.0	4815
7	0.018204589227635348	0.01822810081220152	25	0.001	50	50	0.0	0.0	4815
8	0.01816550202562441	0.01817490596744458	25	0.001	50	50	0.0	0.0	4815
9	0.01813744272869312	0.018145919611844915	25	0.001	50	50	0.0	0.0	4815
10	0.018104040183536143	0.018122678654656582	25	0.001	50	50	0.0	0.0	4815
11	0.018071876642704137	0.0181359265776027	25	0.001	50	50	0.0	0.0	4815
12	0.01803833127423882	0.018085416897874945	25	0.001	50	50	0.0	0.0	4815
13	0.01801319341126283	0.018058146099002595	25	0.001	50	50	0.0	0.0	4815
14	0.017991367686359026	0.018046083801335176	25	0.001	50	50	0.0	0.0	4815
15	0.017963343867742204	0.018011151700784555	25	0.001	50	50	0.0	0.0	4815
16	0.017936751855329322	0.018010844179138855	25	0.001	50	50	0.0	0.0	4815
17	0.017922139200712887	0.017965827731996148	25	0.001	50	50	0.0	0.0	4815
18	0.01789696181613885	0.017955156007557253	25	0.001	50	50	0.0	0.0	4815
19	0.01787937141109555	0.017925595041955636	25	0.001	50	50	0.0	0.0	4815
20	0.017859129618640016	0.01794488681747398	25	0.001	50	50	0.0	0.0	4815
21	0.017847904233796417	0.01788210284399371	25	0.001	50	50	0.0	0.0	4815
22	0.01782732041621723	0.017858975504598015	25	0.001	50	50	0.0	0.0	4815
23	0.017815098069108762	0.01785294754327369	25	0.001	50	50	0.0	0.0	4815
24	0.017805094755794205	0.017885948942678608	25	0.001	50	50	0.0	0.0	4815
25	0.01778352959422874	0.017908616878277484	25	0.001	50	50	0.0	0.0	4815
26	0.017777649250206425	0.01782276694365487	25	0.001	50	50	0.0	0.0	4815
27	0.017770300295077677	0.01783644294733071	25	0.001	50	50	0.0	0.0	4815
28	0.017760556442810493	0.017840176621313077	25	0.001	50	50	0.0	0.0	4815
29	0.01774256622750606	0.01782386784529025	25	0.001	50	50	0.0	0.0	4815
30	0.01773959880562761	0.017812688341702604	25	0.001	50	50	0.0	0.0	4815
31	0.0177339775196699	0.017806787410640578	25	0.001	50	50	0.0	0.0	4815
32	0.017724841782457326	0.017793993652579207	25	0.001	50	50	0.0	0.0	4815
33	0.01771677578592147	0.01781512988485524	25	0.001	50	50	0.0	0.0	4815
34	0.017706348081386002	0.01775721101229209	25	0.001	50	50	0.0	0.0	4815
35	0.01770010569577996	0.017776728524019795	25	0.001	50	50	0.0	0.0	4815
36	0.017700181526195152	0.017787543472693252	25	0.001	50	50	0.0	0.0	4815
37	0.017686290969613265	0.017768497705231662	25	0.001	50	50	0.0	0.0	4815
38	0.017690352959587853	0.01778209224400283	25	0.001	50	50	0.0	0.0	4815
39	0.017677195071596263	0.017813779014816247	25	0.001	50	50	0.0	0.0	4815
40	0.017672015889302888	0.017751151966518698	25	0.001	50	50	0.0	0.0	4815
41	0.017678763706529543	0.01776849890188323	25	0.001	50	50	0.0	0.0	4815
42	0.017660800650958035	0.017742466982845824	25	0.001	50	50	0.0	0.0	4815
43	0.01767007467270366	0.01775405942738398	25	0.001	50	50	0.0	0.0	4815
44	0.017654434005173514	0.017763893121771557	25	0.001	50	50	0.0	0.0	4815
45	0.017652812300189186	0.017757654175817626	25	0.001	50	50	0.0	0.0	4815
46	0.017657316512754033	0.017786675426631766	25	0.001	50	50	0.0	0.0	4815
47	0.01764328116494646	0.017745836094791072	25	0.001	50	50	0.0	0.0	4815
48	0.017649673157585588	0.017764673737477844	25	0.001	50	50	0.0	0.0	4815
49	0.017638098589405554	0.017744377490496316	25	0.001	50	50	0.0	0.0	4815
