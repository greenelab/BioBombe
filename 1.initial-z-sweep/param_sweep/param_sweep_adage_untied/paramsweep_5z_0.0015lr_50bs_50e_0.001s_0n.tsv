	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.11909463152433447	0.12336644621469778	5	0.0015	50	50	0.001	0.0	1572
1	0.09426817458614108	0.10054669658836854	5	0.0015	50	50	0.001	0.0	1572
2	0.08647233821411296	0.11289092070684834	5	0.0015	50	50	0.001	0.0	1572
3	0.08638415388342653	0.11696881369240653	5	0.0015	50	50	0.001	0.0	1572
4	0.07848449429806013	0.10439434428173999	5	0.0015	50	50	0.001	0.0	1572
5	0.07677819767825778	0.11793259072543102	5	0.0015	50	50	0.001	0.0	1572
6	0.07593774155746368	0.08571661720996149	5	0.0015	50	50	0.001	0.0	1572
7	0.08872619240725697	0.09625794325401404	5	0.0015	50	50	0.001	0.0	1572
8	0.07615050960569215	0.1270914667821979	5	0.0015	50	50	0.001	0.0	1572
9	0.07134014604326061	0.06958051268046946	5	0.0015	50	50	0.001	0.0	1572
10	0.07492751939307107	0.12234198840523769	5	0.0015	50	50	0.001	0.0	1572
11	0.0754427402724017	0.06911582438485345	5	0.0015	50	50	0.001	0.0	1572
12	0.07603732248595857	0.07003165586329783	5	0.0015	50	50	0.001	0.0	1572
13	0.0689573985886893	0.09237828025911324	5	0.0015	50	50	0.001	0.0	1572
14	0.07941458660040261	0.11274790406284095	5	0.0015	50	50	0.001	0.0	1572
15	0.07844802036423948	0.07459652683133149	5	0.0015	50	50	0.001	0.0	1572
16	0.07880662817974583	0.12152879138122781	5	0.0015	50	50	0.001	0.0	1572
17	0.07799205529521036	0.08045597194941505	5	0.0015	50	50	0.001	0.0	1572
18	0.07017026322205275	0.10287875854490364	5	0.0015	50	50	0.001	0.0	1572
19	0.07055706814688159	0.1030063372297679	5	0.0015	50	50	0.001	0.0	1572
20	0.07103775484032487	0.09940005048226216	5	0.0015	50	50	0.001	0.0	1572
21	0.0748465812352383	0.08885407134406198	5	0.0015	50	50	0.001	0.0	1572
22	0.07651438183894918	0.061992264692858574	5	0.0015	50	50	0.001	0.0	1572
23	0.08121337737299603	0.08452302530892264	5	0.0015	50	50	0.001	0.0	1572
24	0.08231316594721394	0.0704737456504747	5	0.0015	50	50	0.001	0.0	1572
25	0.07680721703390823	0.10227132786642297	5	0.0015	50	50	0.001	0.0	1572
26	0.08822782180548779	0.10598311888100312	5	0.0015	50	50	0.001	0.0	1572
27	0.07450837536563494	0.07752654335352932	5	0.0015	50	50	0.001	0.0	1572
28	0.06852619994016582	0.07710509113326355	5	0.0015	50	50	0.001	0.0	1572
29	0.07547284418302072	0.08538943996392974	5	0.0015	50	50	0.001	0.0	1572
30	0.07855152249538871	0.07470988618997042	5	0.0015	50	50	0.001	0.0	1572
31	0.07003006622516601	0.07500828811133113	5	0.0015	50	50	0.001	0.0	1572
32	0.08175886343956044	0.07975195483598381	5	0.0015	50	50	0.001	0.0	1572
33	0.06624703969092877	0.0771845664907368	5	0.0015	50	50	0.001	0.0	1572
34	0.08363623332406767	0.12802215843651993	5	0.0015	50	50	0.001	0.0	1572
35	0.09240879420170074	0.1122195984363328	5	0.0015	50	50	0.001	0.0	1572
36	0.08723384479980317	0.11078291614299522	5	0.0015	50	50	0.001	0.0	1572
37	0.07973162991187784	0.09318783605759733	5	0.0015	50	50	0.001	0.0	1572
38	0.08246154244524138	0.0765667050706497	5	0.0015	50	50	0.001	0.0	1572
39	0.07622596052885182	0.08285666352590229	5	0.0015	50	50	0.001	0.0	1572
40	0.08333999093696767	0.10801385288940561	5	0.0015	50	50	0.001	0.0	1572
41	0.07046159985774536	0.10018956249519242	5	0.0015	50	50	0.001	0.0	1572
42	0.06768490471128677	0.08878825298629801	5	0.0015	50	50	0.001	0.0	1572
43	0.07470217129872758	0.0697255664528214	5	0.0015	50	50	0.001	0.0	1572
44	0.07782185566628902	0.0653124070560727	5	0.0015	50	50	0.001	0.0	1572
45	0.07457529098859289	0.0878378561845701	5	0.0015	50	50	0.001	0.0	1572
46	0.08133222491283619	0.12772036276857437	5	0.0015	50	50	0.001	0.0	1572
47	0.0806075518688233	0.08216665941602186	5	0.0015	50	50	0.001	0.0	1572
48	0.07567862670365624	0.10971900146903317	5	0.0015	50	50	0.001	0.0	1572
49	0.07898559627650231	0.09170134198882156	5	0.0015	50	50	0.001	0.0	1572
