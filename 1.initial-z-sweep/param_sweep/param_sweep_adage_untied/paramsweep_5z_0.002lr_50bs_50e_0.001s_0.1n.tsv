	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.14132198177196514	0.10156401882151117	5	0.002	50	50	0.001	0.1	942
1	0.10860580076068453	0.09160884039522812	5	0.002	50	50	0.001	0.1	942
2	0.09583876689886688	0.15868744462101683	5	0.002	50	50	0.001	0.1	942
3	0.09978873478493097	0.14968990373565863	5	0.002	50	50	0.001	0.1	942
4	0.0929065584142264	0.11316192416513399	5	0.002	50	50	0.001	0.1	942
5	0.09386048580816773	0.14092330509230466	5	0.002	50	50	0.001	0.1	942
6	0.09181296688159316	0.17073383220751018	5	0.002	50	50	0.001	0.1	942
7	0.09067947081972179	0.07820515967121999	5	0.002	50	50	0.001	0.1	942
8	0.08247287484758734	0.11226153887993519	5	0.002	50	50	0.001	0.1	942
9	0.09913336623348845	0.09712623015587463	5	0.002	50	50	0.001	0.1	942
10	0.08229790246760213	0.07846817606436819	5	0.002	50	50	0.001	0.1	942
11	0.0839792127212163	0.11059466457389737	5	0.002	50	50	0.001	0.1	942
12	0.0925463393993868	0.1719970376325155	5	0.002	50	50	0.001	0.1	942
13	0.10822178696004285	0.15111435562315223	5	0.002	50	50	0.001	0.1	942
14	0.09044740715369932	0.085114918805901	5	0.002	50	50	0.001	0.1	942
15	0.09340554796508328	0.15576369889493655	5	0.002	50	50	0.001	0.1	942
16	0.0997938628427302	0.10341698224754224	5	0.002	50	50	0.001	0.1	942
17	0.08086801225490275	0.16679042395396626	5	0.002	50	50	0.001	0.1	942
18	0.09364184566395424	0.10960817381198273	5	0.002	50	50	0.001	0.1	942
19	0.09056465641973276	0.07985043460164881	5	0.002	50	50	0.001	0.1	942
20	0.09200328320358216	0.11680142023025461	5	0.002	50	50	0.001	0.1	942
21	0.08357524618579251	0.09597653367095423	5	0.002	50	50	0.001	0.1	942
22	0.08835080825366237	0.11214891727123388	5	0.002	50	50	0.001	0.1	942
23	0.08308362951712946	0.0817756598555335	5	0.002	50	50	0.001	0.1	942
24	0.09726816567323304	0.1124149043234083	5	0.002	50	50	0.001	0.1	942
25	0.09151658886907256	0.1795078113133775	5	0.002	50	50	0.001	0.1	942
26	0.09125884012825226	0.1092294810435968	5	0.002	50	50	0.001	0.1	942
27	0.08574788912364568	0.10084386842314645	5	0.002	50	50	0.001	0.1	942
28	0.09322650099728638	0.12856971005237808	5	0.002	50	50	0.001	0.1	942
29	0.09072300265458569	0.07322050646716732	5	0.002	50	50	0.001	0.1	942
30	0.082177711385372	0.13787615005760304	5	0.002	50	50	0.001	0.1	942
31	0.08666854250721391	0.10934833773406469	5	0.002	50	50	0.001	0.1	942
32	0.09875316172600755	0.10150240441467293	5	0.002	50	50	0.001	0.1	942
33	0.09742140588146282	0.09658811782730697	5	0.002	50	50	0.001	0.1	942
34	0.09256161709786931	0.0938755136631415	5	0.002	50	50	0.001	0.1	942
35	0.08453408479421434	0.1082534106380625	5	0.002	50	50	0.001	0.1	942
36	0.08568305523074118	0.11025785311458215	5	0.002	50	50	0.001	0.1	942
37	0.0868561658646144	0.1390942063033011	5	0.002	50	50	0.001	0.1	942
38	0.09675144630310248	0.11497516052558819	5	0.002	50	50	0.001	0.1	942
39	0.08382485119031692	0.0950619032318004	5	0.002	50	50	0.001	0.1	942
40	0.08425709205894988	0.14453466344859814	5	0.002	50	50	0.001	0.1	942
41	0.09898010332129036	0.11879763813479224	5	0.002	50	50	0.001	0.1	942
42	0.08875443971242242	0.11520318795230602	5	0.002	50	50	0.001	0.1	942
43	0.09317272877710273	0.126634317220511	5	0.002	50	50	0.001	0.1	942
44	0.08627857847091154	0.0727458146345547	5	0.002	50	50	0.001	0.1	942
45	0.09140447724258736	0.14731258322016458	5	0.002	50	50	0.001	0.1	942
46	0.08958692616173315	0.11272841193366005	5	0.002	50	50	0.001	0.1	942
47	0.0938455741086726	0.10204435994645605	5	0.002	50	50	0.001	0.1	942
48	0.08746491406145758	0.1217460580611776	5	0.002	50	50	0.001	0.1	942
49	0.09417940480746373	0.09025863022409936	5	0.002	50	50	0.001	0.1	942
