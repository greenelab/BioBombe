	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.02251320589819766	0.01505571537887959	125	0.0025	50	50	0.0	0.5	9515
1	0.014293739060053762	0.013212172385753911	125	0.0025	50	50	0.0	0.5	9515
2	0.013285867198743698	0.012792742237747855	125	0.0025	50	50	0.0	0.5	9515
3	0.012902957182858426	0.01256214109130104	125	0.0025	50	50	0.0	0.5	9515
4	0.01279543872988355	0.012346011819763119	125	0.0025	50	50	0.0	0.5	9515
5	0.012718158779123833	0.01259547115853822	125	0.0025	50	50	0.0	0.5	9515
6	0.012739436392445095	0.012285639597797484	125	0.0025	50	50	0.0	0.5	9515
7	0.012670287890222233	0.012347011987198266	125	0.0025	50	50	0.0	0.5	9515
8	0.012666123136177519	0.012226970640169617	125	0.0025	50	50	0.0	0.5	9515
9	0.012668065129752862	0.012311015397409978	125	0.0025	50	50	0.0	0.5	9515
10	0.012682988760625026	0.012434436136546828	125	0.0025	50	50	0.0	0.5	9515
11	0.012639931499369147	0.012279071877167399	125	0.0025	50	50	0.0	0.5	9515
12	0.012628399045214027	0.012194017459412263	125	0.0025	50	50	0.0	0.5	9515
13	0.012615467033964484	0.012240848247581527	125	0.0025	50	50	0.0	0.5	9515
14	0.012625207458553	0.012215110469773326	125	0.0025	50	50	0.0	0.5	9515
15	0.012629249305820017	0.012345045252950652	125	0.0025	50	50	0.0	0.5	9515
16	0.012617997735209227	0.012386594719144856	125	0.0025	50	50	0.0	0.5	9515
17	0.012581502462594887	0.012334442225571573	125	0.0025	50	50	0.0	0.5	9515
18	0.01261134905520774	0.012366635208490018	125	0.0025	50	50	0.0	0.5	9515
19	0.012586560873137635	0.012167102155092228	125	0.0025	50	50	0.0	0.5	9515
20	0.0125833319171212	0.012316278742900541	125	0.0025	50	50	0.0	0.5	9515
21	0.012589575958983476	0.012272512043397125	125	0.0025	50	50	0.0	0.5	9515
22	0.012539697036801705	0.012186544646382559	125	0.0025	50	50	0.0	0.5	9515
23	0.012559857837536041	0.012284426013253502	125	0.0025	50	50	0.0	0.5	9515
24	0.012535965519613033	0.012233425298595292	125	0.0025	50	50	0.0	0.5	9515
25	0.01249471615919202	0.012189186938520143	125	0.0025	50	50	0.0	0.5	9515
26	0.012528242095636058	0.012272145798568744	125	0.0025	50	50	0.0	0.5	9515
27	0.012531364137344604	0.012267052244045994	125	0.0025	50	50	0.0	0.5	9515
28	0.012498359050149366	0.012244156572476286	125	0.0025	50	50	0.0	0.5	9515
29	0.012544558327722237	0.01224546424909201	125	0.0025	50	50	0.0	0.5	9515
30	0.012523689886962114	0.012332249381160986	125	0.0025	50	50	0.0	0.5	9515
31	0.0125168204750016	0.012226146742003483	125	0.0025	50	50	0.0	0.5	9515
32	0.012519046976393795	0.012261808383319505	125	0.0025	50	50	0.0	0.5	9515
33	0.012562357037559011	0.0123357697163867	125	0.0025	50	50	0.0	0.5	9515
34	0.012544953691420198	0.012206420968384634	125	0.0025	50	50	0.0	0.5	9515
35	0.012539224340086199	0.012234764843181943	125	0.0025	50	50	0.0	0.5	9515
36	0.012496087518177827	0.012263992439820137	125	0.0025	50	50	0.0	0.5	9515
37	0.012521795503530778	0.012270751026375344	125	0.0025	50	50	0.0	0.5	9515
38	0.012492681401416154	0.01216831574853987	125	0.0025	50	50	0.0	0.5	9515
39	0.012503175844568877	0.012274690836055443	125	0.0025	50	50	0.0	0.5	9515
40	0.012520056585570039	0.012456546026508166	125	0.0025	50	50	0.0	0.5	9515
41	0.01253833080231621	0.012685519046582865	125	0.0025	50	50	0.0	0.5	9515
42	0.01255417577934217	0.012349543592627259	125	0.0025	50	50	0.0	0.5	9515
43	0.01253156642915623	0.012251678893403159	125	0.0025	50	50	0.0	0.5	9515
44	0.0125381072774778	0.012375460572569252	125	0.0025	50	50	0.0	0.5	9515
45	0.012533083397799719	0.012260396423505666	125	0.0025	50	50	0.0	0.5	9515
46	0.012566978958394098	0.012416320778144592	125	0.0025	50	50	0.0	0.5	9515
47	0.0125462707812017	0.01227339462735058	125	0.0025	50	50	0.0	0.5	9515
48	0.012527046047117844	0.012241317397321844	125	0.0025	50	50	0.0	0.5	9515
49	0.012513264947998579	0.01237627193082416	125	0.0025	50	50	0.0	0.5	9515
