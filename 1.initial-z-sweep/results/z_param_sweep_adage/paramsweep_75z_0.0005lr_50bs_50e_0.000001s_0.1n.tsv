	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.03434711042623407	0.02219214080254161	75	0.0005	50	50	1e-06	0.1	1130
1	0.020185153056452566	0.018070651168434617	75	0.0005	50	50	1e-06	0.1	1130
2	0.017597616152198917	0.016287874622737016	75	0.0005	50	50	1e-06	0.1	1130
3	0.016286649419281513	0.015286210968905267	75	0.0005	50	50	1e-06	0.1	1130
4	0.015455773706858291	0.014881037613715314	75	0.0005	50	50	1e-06	0.1	1130
5	0.014881540962793609	0.014134070097004023	75	0.0005	50	50	1e-06	0.1	1130
6	0.014420179454583038	0.013805805960132332	75	0.0005	50	50	1e-06	0.1	1130
7	0.014053135716920196	0.013406791054709578	75	0.0005	50	50	1e-06	0.1	1130
8	0.013743073930418714	0.013266221036062528	75	0.0005	50	50	1e-06	0.1	1130
9	0.013520999482811973	0.012925599313503127	75	0.0005	50	50	1e-06	0.1	1130
10	0.013254894036572108	0.012785455879771345	75	0.0005	50	50	1e-06	0.1	1130
11	0.013088268733359885	0.012540093594610007	75	0.0005	50	50	1e-06	0.1	1130
12	0.012912900389704335	0.012445415811787713	75	0.0005	50	50	1e-06	0.1	1130
13	0.01272767100039532	0.01233763765386995	75	0.0005	50	50	1e-06	0.1	1130
14	0.012615537049871544	0.012217436012514576	75	0.0005	50	50	1e-06	0.1	1130
15	0.012486938255565282	0.011974641397937306	75	0.0005	50	50	1e-06	0.1	1130
16	0.012333144195054095	0.012031133981140234	75	0.0005	50	50	1e-06	0.1	1130
17	0.012275696887142864	0.011820517165183907	75	0.0005	50	50	1e-06	0.1	1130
18	0.012138711150055305	0.011800518141877811	75	0.0005	50	50	1e-06	0.1	1130
19	0.012036587508896149	0.011632815272285537	75	0.0005	50	50	1e-06	0.1	1130
20	0.011929240270370248	0.011600171661015108	75	0.0005	50	50	1e-06	0.1	1130
21	0.011831597964167849	0.011437461722150702	75	0.0005	50	50	1e-06	0.1	1130
22	0.011789950742901265	0.01136004962703751	75	0.0005	50	50	1e-06	0.1	1130
23	0.011686119919392092	0.011339698332303113	75	0.0005	50	50	1e-06	0.1	1130
24	0.011626478719537802	0.011343127159298493	75	0.0005	50	50	1e-06	0.1	1130
25	0.011547912348726281	0.011155879299510733	75	0.0005	50	50	1e-06	0.1	1130
26	0.01151943300404173	0.011127846491795539	75	0.0005	50	50	1e-06	0.1	1130
27	0.011449896618779275	0.010986853784473744	75	0.0005	50	50	1e-06	0.1	1130
28	0.011368966909436317	0.01103199774623772	75	0.0005	50	50	1e-06	0.1	1130
29	0.011322312774531433	0.0110025455174437	75	0.0005	50	50	1e-06	0.1	1130
30	0.011286482063054715	0.01093654975964622	75	0.0005	50	50	1e-06	0.1	1130
31	0.011209191894559429	0.01087900918034078	75	0.0005	50	50	1e-06	0.1	1130
32	0.011171999431075622	0.010878777022813634	75	0.0005	50	50	1e-06	0.1	1130
33	0.011161355279278397	0.010801815992331642	75	0.0005	50	50	1e-06	0.1	1130
34	0.011203309861234913	0.010794437253566363	75	0.0005	50	50	1e-06	0.1	1130
35	0.011079299191330973	0.011007268359282733	75	0.0005	50	50	1e-06	0.1	1130
36	0.01103010144469371	0.010676423668234571	75	0.0005	50	50	1e-06	0.1	1130
37	0.010983947532711152	0.010675907165282201	75	0.0005	50	50	1e-06	0.1	1130
38	0.010997622069848004	0.010801721187967302	75	0.0005	50	50	1e-06	0.1	1130
39	0.010948916496074783	0.010873672062705625	75	0.0005	50	50	1e-06	0.1	1130
40	0.010868368102230656	0.010809543877341437	75	0.0005	50	50	1e-06	0.1	1130
41	0.010899577627996766	0.010670403230500837	75	0.0005	50	50	1e-06	0.1	1130
42	0.0108569163347646	0.010608923664213253	75	0.0005	50	50	1e-06	0.1	1130
43	0.010830425970279283	0.010721052482182847	75	0.0005	50	50	1e-06	0.1	1130
44	0.010828582700755509	0.01076777735600394	75	0.0005	50	50	1e-06	0.1	1130
45	0.010821335897356997	0.010722661581438883	75	0.0005	50	50	1e-06	0.1	1130
46	0.010748555495128752	0.010689128425335565	75	0.0005	50	50	1e-06	0.1	1130
47	0.010785754596400746	0.010830033260680749	75	0.0005	50	50	1e-06	0.1	1130
48	0.010764269088986107	0.010511067282785991	75	0.0005	50	50	1e-06	0.1	1130
49	0.010767505849986354	0.010470954097636457	75	0.0005	50	50	1e-06	0.1	1130
