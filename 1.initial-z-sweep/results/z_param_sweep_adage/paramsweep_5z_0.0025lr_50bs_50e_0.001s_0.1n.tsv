	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.15556931559700496	0.13281734843327028	5	0.0025	50	50	0.001	0.1	106
1	0.11194134244538387	0.1162795664219054	5	0.0025	50	50	0.001	0.1	106
2	0.10439583649396783	0.11332206929504986	5	0.0025	50	50	0.001	0.1	106
3	0.10414239418794102	0.1554656913414968	5	0.0025	50	50	0.001	0.1	106
4	0.11074364887213879	0.1364857910012196	5	0.0025	50	50	0.001	0.1	106
5	0.11627214744846967	0.16917836498006125	5	0.0025	50	50	0.001	0.1	106
6	0.10192953298871821	0.09568265705844868	5	0.0025	50	50	0.001	0.1	106
7	0.0922820244388532	0.1410665347687829	5	0.0025	50	50	0.001	0.1	106
8	0.1045689142137864	0.1581055002561263	5	0.0025	50	50	0.001	0.1	106
9	0.10025199081855184	0.11647254185854362	5	0.0025	50	50	0.001	0.1	106
10	0.10535748221251659	0.1284844649538939	5	0.0025	50	50	0.001	0.1	106
11	0.1009561017299704	0.09181081275696053	5	0.0025	50	50	0.001	0.1	106
12	0.10806088809596356	0.21068017845741877	5	0.0025	50	50	0.001	0.1	106
13	0.09951159372271963	0.18502917982652128	5	0.0025	50	50	0.001	0.1	106
14	0.11137023689968356	0.15811438790128973	5	0.0025	50	50	0.001	0.1	106
15	0.107574687912723	0.14292287917711538	5	0.0025	50	50	0.001	0.1	106
16	0.09533428472308364	0.1001833459187876	5	0.0025	50	50	0.001	0.1	106
17	0.09157877640526998	0.12142652644994838	5	0.0025	50	50	0.001	0.1	106
18	0.09522314401022701	0.1131828296822754	5	0.0025	50	50	0.001	0.1	106
19	0.1000552633273656	0.11506344322435715	5	0.0025	50	50	0.001	0.1	106
20	0.10094253104514515	0.14947285282338327	5	0.0025	50	50	0.001	0.1	106
21	0.11076483164411238	0.09983181335160199	5	0.0025	50	50	0.001	0.1	106
22	0.11070854756749615	0.1241091114983504	5	0.0025	50	50	0.001	0.1	106
23	0.11275645411224784	0.11019724147326632	5	0.0025	50	50	0.001	0.1	106
24	0.0977654371465619	0.113801794543321	5	0.0025	50	50	0.001	0.1	106
25	0.09800739339715576	0.09090411694396294	5	0.0025	50	50	0.001	0.1	106
26	0.09679160652822483	0.20646613936009417	5	0.0025	50	50	0.001	0.1	106
27	0.10597026111211988	0.10887356366014846	5	0.0025	50	50	0.001	0.1	106
28	0.09656504107803236	0.1249994527598412	5	0.0025	50	50	0.001	0.1	106
29	0.10857720923798314	0.13226830561860797	5	0.0025	50	50	0.001	0.1	106
30	0.09777838768037589	0.16759018867809047	5	0.0025	50	50	0.001	0.1	106
31	0.10366523415277656	0.10280143321415207	5	0.0025	50	50	0.001	0.1	106
32	0.09746538363274436	0.067974285772836	5	0.0025	50	50	0.001	0.1	106
33	0.10699187111021241	0.1938364787835692	5	0.0025	50	50	0.001	0.1	106
34	0.1043283398072499	0.13725530727985485	5	0.0025	50	50	0.001	0.1	106
35	0.11295984947335058	0.10923815205208887	5	0.0025	50	50	0.001	0.1	106
36	0.09890389840182799	0.1328044810383999	5	0.0025	50	50	0.001	0.1	106
37	0.10917175095538258	0.11935884112324815	5	0.0025	50	50	0.001	0.1	106
38	0.10357607214135875	0.1653134488067937	5	0.0025	50	50	0.001	0.1	106
39	0.11580483291824908	0.11066432428291605	5	0.0025	50	50	0.001	0.1	106
40	0.09704578040401386	0.1442410944752666	5	0.0025	50	50	0.001	0.1	106
41	0.08561282158357031	0.06596810615712324	5	0.0025	50	50	0.001	0.1	106
42	0.10045995622711835	0.13220099395365378	5	0.0025	50	50	0.001	0.1	106
43	0.1167649074571268	0.14943563339815086	5	0.0025	50	50	0.001	0.1	106
44	0.09896777813244383	0.1140571150138091	5	0.0025	50	50	0.001	0.1	106
45	0.11580932318521561	0.08237974570768514	5	0.0025	50	50	0.001	0.1	106
46	0.10198092328923346	0.15087381748920645	5	0.0025	50	50	0.001	0.1	106
47	0.10323515118694478	0.14821392841936298	5	0.0025	50	50	0.001	0.1	106
48	0.12181766964174616	0.1677452803056965	5	0.0025	50	50	0.001	0.1	106
49	0.10379530593292197	0.10528004038402274	5	0.0025	50	50	0.001	0.1	106
