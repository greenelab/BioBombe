	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.031077375883052698	0.020702422968687108	50	0.002	100	50	0.0	0.5	6893
1	0.018221795045430648	0.016139239671125467	50	0.002	100	50	0.0	0.5	6893
2	0.01566620786289147	0.014601746424462781	50	0.002	100	50	0.0	0.5	6893
3	0.01471692721641312	0.014011105351563165	50	0.002	100	50	0.0	0.5	6893
4	0.014363184492312024	0.013892393753317186	50	0.002	100	50	0.0	0.5	6893
5	0.014222530334670257	0.013713837319888872	50	0.002	100	50	0.0	0.5	6893
6	0.014195885116460598	0.013742953373286624	50	0.002	100	50	0.0	0.5	6893
7	0.014137184641155884	0.013890032257606946	50	0.002	100	50	0.0	0.5	6893
8	0.01410747988729906	0.013610838196573362	50	0.002	100	50	0.0	0.5	6893
9	0.014075587400120762	0.013606927904298611	50	0.002	100	50	0.0	0.5	6893
10	0.014053173815463683	0.013655529848974817	50	0.002	100	50	0.0	0.5	6893
11	0.014045536909701593	0.013527504382138612	50	0.002	100	50	0.0	0.5	6893
12	0.014032515639202364	0.013671437629194037	50	0.002	100	50	0.0	0.5	6893
13	0.01406848916943618	0.013687125451677617	50	0.002	100	50	0.0	0.5	6893
14	0.014034356827126683	0.013533804086651332	50	0.002	100	50	0.0	0.5	6893
15	0.014013619207258934	0.013663701159277678	50	0.002	100	50	0.0	0.5	6893
16	0.014027600117169442	0.013605372023984192	50	0.002	100	50	0.0	0.5	6893
17	0.014003327906604282	0.01362450467333568	50	0.002	100	50	0.0	0.5	6893
18	0.01402786163785158	0.01362934539069637	50	0.002	100	50	0.0	0.5	6893
19	0.014005454786360885	0.013572110878178997	50	0.002	100	50	0.0	0.5	6893
20	0.01400544957429864	0.013480714504494836	50	0.002	100	50	0.0	0.5	6893
21	0.013980869462435182	0.013565290589277306	50	0.002	100	50	0.0	0.5	6893
22	0.0140121040684125	0.01348499875750756	50	0.002	100	50	0.0	0.5	6893
23	0.013964007525383938	0.01354474905543528	50	0.002	100	50	0.0	0.5	6893
24	0.01397426917380824	0.013616016243244334	50	0.002	100	50	0.0	0.5	6893
25	0.014013779360013814	0.013627933746072006	50	0.002	100	50	0.0	0.5	6893
26	0.013948771064812321	0.01364588794649274	50	0.002	100	50	0.0	0.5	6893
27	0.013950332594465736	0.013594793795071983	50	0.002	100	50	0.0	0.5	6893
28	0.013960699835062203	0.013555492879911887	50	0.002	100	50	0.0	0.5	6893
29	0.013946915800095199	0.013475787743968785	50	0.002	100	50	0.0	0.5	6893
30	0.013952622178245031	0.013573967187485549	50	0.002	100	50	0.0	0.5	6893
31	0.013908606491868957	0.013517586375456695	50	0.002	100	50	0.0	0.5	6893
32	0.01393485554536211	0.01355035799639175	50	0.002	100	50	0.0	0.5	6893
33	0.013924594643638275	0.013527279958328371	50	0.002	100	50	0.0	0.5	6893
34	0.013929327292721824	0.013605436400989388	50	0.002	100	50	0.0	0.5	6893
35	0.013919205366231443	0.01357395156868956	50	0.002	100	50	0.0	0.5	6893
36	0.013943306190093025	0.013492083144917314	50	0.002	100	50	0.0	0.5	6893
37	0.013917655202908495	0.013565973943209785	50	0.002	100	50	0.0	0.5	6893
38	0.013915952762358724	0.013545638016188235	50	0.002	100	50	0.0	0.5	6893
39	0.013901393567617085	0.013486462287305646	50	0.002	100	50	0.0	0.5	6893
40	0.013899803578554413	0.014276529186855767	50	0.002	100	50	0.0	0.5	6893
41	0.013978654886582549	0.013532800779786552	50	0.002	100	50	0.0	0.5	6893
42	0.013897269501079824	0.013586043107748942	50	0.002	100	50	0.0	0.5	6893
43	0.013915654651473973	0.013434490632358404	50	0.002	100	50	0.0	0.5	6893
44	0.013903612167657871	0.013584088108521917	50	0.002	100	50	0.0	0.5	6893
45	0.01389098396910851	0.013534346668416524	50	0.002	100	50	0.0	0.5	6893
46	0.013889685124958294	0.01349997680178393	50	0.002	100	50	0.0	0.5	6893
47	0.013896574909760907	0.013482414933908055	50	0.002	100	50	0.0	0.5	6893
48	0.013854628285848441	0.013413097321217876	50	0.002	100	50	0.0	0.5	6893
49	0.013850518976712498	0.013474469112292872	50	0.002	100	50	0.0	0.5	6893
