	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.027803583225180135	0.019415835776930786	25	0.002	50	50	0.0	0.0	9634
1	0.01823455322061704	0.01791216003179664	25	0.002	50	50	0.0	0.0	9634
2	0.017725230169398528	0.017720514562971048	25	0.002	50	50	0.0	0.0	9634
3	0.017591845429978627	0.01762706820584164	25	0.002	50	50	0.0	0.0	9634
4	0.017507959984466123	0.01755882327731549	25	0.002	50	50	0.0	0.0	9634
5	0.017436313015365974	0.017555166285192988	25	0.002	50	50	0.0	0.0	9634
6	0.017373103450939835	0.017436547333064774	25	0.002	50	50	0.0	0.0	9634
7	0.017310839079294312	0.017429822824368287	25	0.002	50	50	0.0	0.0	9634
8	0.017281503795637126	0.01737667235187887	25	0.002	50	50	0.0	0.0	9634
9	0.017241940624963637	0.017514871789523566	25	0.002	50	50	0.0	0.0	9634
10	0.017181378828525277	0.01734771730153898	25	0.002	50	50	0.0	0.0	9634
11	0.017159923725878917	0.01739224948587313	25	0.002	50	50	0.0	0.0	9634
12	0.017137815686856777	0.017325847482675575	25	0.002	50	50	0.0	0.0	9634
13	0.017117534906485755	0.017300320500739447	25	0.002	50	50	0.0	0.0	9634
14	0.01708650807389497	0.017258859048980373	25	0.002	50	50	0.0	0.0	9634
15	0.017053762134305067	0.017145676627384775	25	0.002	50	50	0.0	0.0	9634
16	0.01704597278846085	0.01718848130628324	25	0.002	50	50	0.0	0.0	9634
17	0.017019708499686	0.01715231052177814	25	0.002	50	50	0.0	0.0	9634
18	0.017036246619845544	0.01717155046376398	25	0.002	50	50	0.0	0.0	9634
19	0.017006442177172842	0.017173602154930738	25	0.002	50	50	0.0	0.0	9634
20	0.0169967414015182	0.017111771852205405	25	0.002	50	50	0.0	0.0	9634
21	0.01697837575913128	0.017099076835705718	25	0.002	50	50	0.0	0.0	9634
22	0.016992143884144464	0.017105960459884675	25	0.002	50	50	0.0	0.0	9634
23	0.016980147608393097	0.01714361640651413	25	0.002	50	50	0.0	0.0	9634
24	0.01696631702965781	0.017202175765460355	25	0.002	50	50	0.0	0.0	9634
25	0.01696997568097164	0.01712667200194376	25	0.002	50	50	0.0	0.0	9634
26	0.01696890373848332	0.017111825060462632	25	0.002	50	50	0.0	0.0	9634
27	0.016933809294441826	0.017256157960650113	25	0.002	50	50	0.0	0.0	9634
28	0.016943913809365437	0.017106095318242653	25	0.002	50	50	0.0	0.0	9634
29	0.01694016221387916	0.017120403424617667	25	0.002	50	50	0.0	0.0	9634
30	0.01696323463351918	0.017079316738487203	25	0.002	50	50	0.0	0.0	9634
31	0.016941269996802486	0.017168007684198437	25	0.002	50	50	0.0	0.0	9634
32	0.01692642473455324	0.017129539656337088	25	0.002	50	50	0.0	0.0	9634
33	0.016918533383212166	0.017044308070043535	25	0.002	50	50	0.0	0.0	9634
34	0.01691315220553152	0.017126423465248276	25	0.002	50	50	0.0	0.0	9634
35	0.01691468687494351	0.01707116875932846	25	0.002	50	50	0.0	0.0	9634
36	0.016916236478166907	0.0170694256582463	25	0.002	50	50	0.0	0.0	9634
37	0.016911490933238845	0.017028184301339188	25	0.002	50	50	0.0	0.0	9634
38	0.016914817861857265	0.01706774139609437	25	0.002	50	50	0.0	0.0	9634
39	0.01692256873645087	0.017092684778895934	25	0.002	50	50	0.0	0.0	9634
40	0.016880296945807772	0.0172461357793947	25	0.002	50	50	0.0	0.0	9634
41	0.01689497101606743	0.017000395420005626	25	0.002	50	50	0.0	0.0	9634
42	0.0168933399075251	0.017048708011839633	25	0.002	50	50	0.0	0.0	9634
43	0.01686805110825662	0.017182850843405862	25	0.002	50	50	0.0	0.0	9634
44	0.01687840218393079	0.017096044143116954	25	0.002	50	50	0.0	0.0	9634
45	0.016887023351222996	0.01706904098106616	25	0.002	50	50	0.0	0.0	9634
46	0.016873735192247764	0.01704110137149549	25	0.002	50	50	0.0	0.0	9634
47	0.01687185649348378	0.017062711239174494	25	0.002	50	50	0.0	0.0	9634
48	0.016847397067886755	0.01704728184534988	25	0.002	50	50	0.0	0.0	9634
49	0.01684385618381143	0.016977061163171072	25	0.002	50	50	0.0	0.0	9634
