	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.025646999024007498	0.01647325896481711	100	0.001	50	50	0.0	0.1	6928
1	0.014901209576317598	0.013940627309164285	100	0.001	50	50	0.0	0.1	6928
2	0.013120571419008572	0.012808169215119819	100	0.001	50	50	0.0	0.1	6928
3	0.012239107025181127	0.01210942642716958	100	0.001	50	50	0.0	0.1	6928
4	0.011650295977194872	0.011694317530434628	100	0.001	50	50	0.0	0.1	6928
5	0.011268507926396864	0.011381908360847324	100	0.001	50	50	0.0	0.1	6928
6	0.011049924318400755	0.011160290014732408	100	0.001	50	50	0.0	0.1	6928
7	0.010902729516748597	0.011080583603785553	100	0.001	50	50	0.0	0.1	6928
8	0.010812972415930011	0.01096241631283359	100	0.001	50	50	0.0	0.1	6928
9	0.010764101888237643	0.010942829101494234	100	0.001	50	50	0.0	0.1	6928
10	0.010723066749125418	0.010933337138385207	100	0.001	50	50	0.0	0.1	6928
11	0.010713774934201297	0.010910277126666807	100	0.001	50	50	0.0	0.1	6928
12	0.01069093967976798	0.010891191869703465	100	0.001	50	50	0.0	0.1	6928
13	0.010674911229919199	0.010858691393631024	100	0.001	50	50	0.0	0.1	6928
14	0.010670113189781711	0.010882981997659968	100	0.001	50	50	0.0	0.1	6928
15	0.010667861177591264	0.010912111807208557	100	0.001	50	50	0.0	0.1	6928
16	0.010639599831449319	0.010853253805343894	100	0.001	50	50	0.0	0.1	6928
17	0.010631571320820238	0.010845733412949237	100	0.001	50	50	0.0	0.1	6928
18	0.010635090332023556	0.010879475812126756	100	0.001	50	50	0.0	0.1	6928
19	0.010633167049196616	0.01081227438335608	100	0.001	50	50	0.0	0.1	6928
20	0.010620594076502782	0.010814192453773254	100	0.001	50	50	0.0	0.1	6928
21	0.010615970801079639	0.010892846407885192	100	0.001	50	50	0.0	0.1	6928
22	0.010603889386832214	0.01082474425841073	100	0.001	50	50	0.0	0.1	6928
23	0.010601779172337678	0.010813324096083755	100	0.001	50	50	0.0	0.1	6928
24	0.010608203986553384	0.010804510657563379	100	0.001	50	50	0.0	0.1	6928
25	0.010600560443398866	0.010908648097463822	100	0.001	50	50	0.0	0.1	6928
26	0.010598809508379032	0.01083398424088955	100	0.001	50	50	0.0	0.1	6928
27	0.010595168221041815	0.01081174559691782	100	0.001	50	50	0.0	0.1	6928
28	0.010599452089492584	0.01080916568558542	100	0.001	50	50	0.0	0.1	6928
29	0.010599619570538175	0.010781259309806742	100	0.001	50	50	0.0	0.1	6928
30	0.010579993218162938	0.010820112880283742	100	0.001	50	50	0.0	0.1	6928
31	0.010588792667092064	0.010830063372850418	100	0.001	50	50	0.0	0.1	6928
32	0.01058293151278688	0.01079784629129258	100	0.001	50	50	0.0	0.1	6928
33	0.010575213258228994	0.01078553657700979	100	0.001	50	50	0.0	0.1	6928
34	0.010576926816472917	0.010816311144962707	100	0.001	50	50	0.0	0.1	6928
35	0.010578109813909702	0.010791700908533132	100	0.001	50	50	0.0	0.1	6928
36	0.010567553642858997	0.010817627536478393	100	0.001	50	50	0.0	0.1	6928
37	0.010575465128596678	0.010814554383889211	100	0.001	50	50	0.0	0.1	6928
38	0.010566427955350694	0.01081976166126776	100	0.001	50	50	0.0	0.1	6928
39	0.01056420266439092	0.010819499884833569	100	0.001	50	50	0.0	0.1	6928
40	0.010561847548271313	0.01084320588717611	100	0.001	50	50	0.0	0.1	6928
41	0.010573965478516323	0.010777491524131759	100	0.001	50	50	0.0	0.1	6928
42	0.010554479080386215	0.01076573798215697	100	0.001	50	50	0.0	0.1	6928
43	0.010558893677517242	0.010782711953993168	100	0.001	50	50	0.0	0.1	6928
44	0.010559636538514458	0.010757279920660629	100	0.001	50	50	0.0	0.1	6928
45	0.010552873397355826	0.010799053931754817	100	0.001	50	50	0.0	0.1	6928
46	0.010555029199264241	0.010822548123208332	100	0.001	50	50	0.0	0.1	6928
47	0.010548975666444506	0.010809035352066189	100	0.001	50	50	0.0	0.1	6928
48	0.010551806558689352	0.01077282718288397	100	0.001	50	50	0.0	0.1	6928
49	0.01054521869099474	0.010831189316912888	100	0.001	50	50	0.0	0.1	6928
