	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.026356884108674865	0.017693521597388826	125	0.002	50	50	1e-06	0.1	2753
1	0.017223056707252993	0.016727177565116044	125	0.002	50	50	1e-06	0.1	2753
2	0.015935842796204785	0.016414652603462938	125	0.002	50	50	1e-06	0.1	2753
3	0.01513314881218261	0.013947121882686538	125	0.002	50	50	1e-06	0.1	2753
4	0.014843850775118128	0.014152273409296518	125	0.002	50	50	1e-06	0.1	2753
5	0.01442427373987214	0.014496542682540007	125	0.002	50	50	1e-06	0.1	2753
6	0.014324089348384264	0.013973493064908634	125	0.002	50	50	1e-06	0.1	2753
7	0.014170381988929148	0.015063428977080559	125	0.002	50	50	1e-06	0.1	2753
8	0.014025139638418557	0.014093439459772228	125	0.002	50	50	1e-06	0.1	2753
9	0.013788274124947007	0.014838244687644747	125	0.002	50	50	1e-06	0.1	2753
10	0.014107916629501697	0.014656649581931289	125	0.002	50	50	1e-06	0.1	2753
11	0.013517916147930265	0.015368603531406556	125	0.002	50	50	1e-06	0.1	2753
12	0.013773894268324014	0.01397336774949077	125	0.002	50	50	1e-06	0.1	2753
13	0.013427789494099228	0.013159255498938306	125	0.002	50	50	1e-06	0.1	2753
14	0.013523004064469988	0.012909448057427346	125	0.002	50	50	1e-06	0.1	2753
15	0.013463901220710527	0.013306594241844992	125	0.002	50	50	1e-06	0.1	2753
16	0.01315631073650535	0.015329312390681662	125	0.002	50	50	1e-06	0.1	2753
17	0.013837294455079037	0.013599612349448422	125	0.002	50	50	1e-06	0.1	2753
18	0.013592244951260447	0.01405968209532718	125	0.002	50	50	1e-06	0.1	2753
19	0.013280335002353509	0.013631218898307753	125	0.002	50	50	1e-06	0.1	2753
20	0.013459861568527185	0.014019679764275	125	0.002	50	50	1e-06	0.1	2753
21	0.013098321617809997	0.012782226357587665	125	0.002	50	50	1e-06	0.1	2753
22	0.01336251782645385	0.013952368831201448	125	0.002	50	50	1e-06	0.1	2753
23	0.013249131527463282	0.013210919379375975	125	0.002	50	50	1e-06	0.1	2753
24	0.013184927939983973	0.012904226236814637	125	0.002	50	50	1e-06	0.1	2753
25	0.013463285538227135	0.012702510683275546	125	0.002	50	50	1e-06	0.1	2753
26	0.013263710764092593	0.014644102505043178	125	0.002	50	50	1e-06	0.1	2753
27	0.013169157590163409	0.013243168036864775	125	0.002	50	50	1e-06	0.1	2753
28	0.013125017702775004	0.015794318801515075	125	0.002	50	50	1e-06	0.1	2753
29	0.013032776129158057	0.013379160710120748	125	0.002	50	50	1e-06	0.1	2753
30	0.012849177762313539	0.01289072209153588	125	0.002	50	50	1e-06	0.1	2753
31	0.013249199112116796	0.012889267431561395	125	0.002	50	50	1e-06	0.1	2753
32	0.013248777496065	0.01256860526239439	125	0.002	50	50	1e-06	0.1	2753
33	0.013302578998245374	0.016515293448850027	125	0.002	50	50	1e-06	0.1	2753
34	0.01322041048255646	0.01380485812839598	125	0.002	50	50	1e-06	0.1	2753
35	0.013097760525888152	0.015025458020829448	125	0.002	50	50	1e-06	0.1	2753
36	0.012895026416675604	0.013960942262730225	125	0.002	50	50	1e-06	0.1	2753
37	0.013253593185522168	0.01469897776201054	125	0.002	50	50	1e-06	0.1	2753
38	0.013123284072664578	0.014253563459528109	125	0.002	50	50	1e-06	0.1	2753
39	0.013057825636404785	0.014253110295414468	125	0.002	50	50	1e-06	0.1	2753
40	0.01309288203285691	0.01313475457093114	125	0.002	50	50	1e-06	0.1	2753
41	0.012820334746799654	0.012632240965093413	125	0.002	50	50	1e-06	0.1	2753
42	0.012963490663350584	0.013094695749733576	125	0.002	50	50	1e-06	0.1	2753
43	0.013257004205257406	0.01266803234872581	125	0.002	50	50	1e-06	0.1	2753
44	0.01300669107412011	0.014329942970769925	125	0.002	50	50	1e-06	0.1	2753
45	0.013069197178835996	0.013162040488213927	125	0.002	50	50	1e-06	0.1	2753
46	0.0129348793910304	0.014025667646675448	125	0.002	50	50	1e-06	0.1	2753
47	0.013105030543488763	0.013287207332526977	125	0.002	50	50	1e-06	0.1	2753
48	0.013034531297228464	0.014130093032640208	125	0.002	50	50	1e-06	0.1	2753
49	0.01277059004894861	0.013878445628937868	125	0.002	50	50	1e-06	0.1	2753
