	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.2458371990933677	0.22780067264235954	25	0.0005	50	50	0.001	0.0	8533
1	0.1952167813533882	0.21320366999045384	25	0.0005	50	50	0.001	0.0	8533
2	0.1772276468374746	0.21099473111488168	25	0.0005	50	50	0.001	0.0	8533
3	0.1634525959440819	0.1971037868787864	25	0.0005	50	50	0.001	0.0	8533
4	0.15602418874676063	0.18249983165277806	25	0.0005	50	50	0.001	0.0	8533
5	0.14805979534633784	0.18654466464574204	25	0.0005	50	50	0.001	0.0	8533
6	0.1433510105610907	0.1753542196454327	25	0.0005	50	50	0.001	0.0	8533
7	0.13697706829547932	0.1702233195646771	25	0.0005	50	50	0.001	0.0	8533
8	0.1311058803124799	0.16552600176224974	25	0.0005	50	50	0.001	0.0	8533
9	0.13080682224942028	0.16054254439775165	25	0.0005	50	50	0.001	0.0	8533
10	0.12880401388380602	0.15494707232451577	25	0.0005	50	50	0.001	0.0	8533
11	0.12331454675538968	0.1451494427358671	25	0.0005	50	50	0.001	0.0	8533
12	0.12181668836474228	0.15317092602271196	25	0.0005	50	50	0.001	0.0	8533
13	0.120428368970823	0.13796746160970363	25	0.0005	50	50	0.001	0.0	8533
14	0.11858356062552	0.1580254893685846	25	0.0005	50	50	0.001	0.0	8533
15	0.11570586066015921	0.13633780885153018	25	0.0005	50	50	0.001	0.0	8533
16	0.11494536465553325	0.1546351589105781	25	0.0005	50	50	0.001	0.0	8533
17	0.11562831977830106	0.13644168470375398	25	0.0005	50	50	0.001	0.0	8533
18	0.1114146406123644	0.14869789907398917	25	0.0005	50	50	0.001	0.0	8533
19	0.10992039387305004	0.13385864018140287	25	0.0005	50	50	0.001	0.0	8533
20	0.10999967679769215	0.14349621280771369	25	0.0005	50	50	0.001	0.0	8533
21	0.10895550704627364	0.15722542773241294	25	0.0005	50	50	0.001	0.0	8533
22	0.10864635657261462	0.13249709287633404	25	0.0005	50	50	0.001	0.0	8533
23	0.10770559275294672	0.1330633121141968	25	0.0005	50	50	0.001	0.0	8533
24	0.1054515161358701	0.1323739221287503	25	0.0005	50	50	0.001	0.0	8533
25	0.10696557077837335	0.15570563126362533	25	0.0005	50	50	0.001	0.0	8533
26	0.11156490721179729	0.14318953240806695	25	0.0005	50	50	0.001	0.0	8533
27	0.10568264160298534	0.12143261823268967	25	0.0005	50	50	0.001	0.0	8533
28	0.10434807536548324	0.13269186458669702	25	0.0005	50	50	0.001	0.0	8533
29	0.104826639700136	0.13958172232311497	25	0.0005	50	50	0.001	0.0	8533
30	0.1041525433161149	0.12944214117230696	25	0.0005	50	50	0.001	0.0	8533
31	0.1023836889617168	0.1321853610115343	25	0.0005	50	50	0.001	0.0	8533
32	0.10119956562173464	0.13879808558446727	25	0.0005	50	50	0.001	0.0	8533
33	0.10175219852337608	0.15203181082956194	25	0.0005	50	50	0.001	0.0	8533
34	0.10167371503502988	0.1363958245709567	25	0.0005	50	50	0.001	0.0	8533
35	0.10257189560586204	0.14769663033476296	25	0.0005	50	50	0.001	0.0	8533
36	0.10294536693904398	0.12728512120463426	25	0.0005	50	50	0.001	0.0	8533
37	0.10300382307084438	0.13686615211557931	25	0.0005	50	50	0.001	0.0	8533
38	0.10554541586605899	0.14191913168813255	25	0.0005	50	50	0.001	0.0	8533
39	0.10272282038489906	0.12312344344863473	25	0.0005	50	50	0.001	0.0	8533
40	0.10346286509153974	0.12441781240143238	25	0.0005	50	50	0.001	0.0	8533
41	0.09873018030409261	0.14104353170663858	25	0.0005	50	50	0.001	0.0	8533
42	0.09893579231107145	0.1360489352255433	25	0.0005	50	50	0.001	0.0	8533
43	0.09685767819661903	0.12089245962994048	25	0.0005	50	50	0.001	0.0	8533
44	0.09881107077084843	0.14559222122451315	25	0.0005	50	50	0.001	0.0	8533
45	0.10123556447675944	0.14289720336520192	25	0.0005	50	50	0.001	0.0	8533
46	0.10345609125288528	0.13380622316728816	25	0.0005	50	50	0.001	0.0	8533
47	0.10066483083478794	0.13103965463305522	25	0.0005	50	50	0.001	0.0	8533
48	0.09957810363255486	0.15463083270175051	25	0.0005	50	50	0.001	0.0	8533
49	0.09951089536356619	0.1478271219971987	25	0.0005	50	50	0.001	0.0	8533
