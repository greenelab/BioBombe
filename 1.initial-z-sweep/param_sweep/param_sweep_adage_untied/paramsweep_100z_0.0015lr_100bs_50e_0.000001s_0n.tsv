	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.038051820045791614	0.025612153469034636	100	0.0015	100	50	1e-06	0.0	9510
1	0.02252051850384491	0.023112262693548977	100	0.0015	100	50	1e-06	0.0	9510
2	0.01990701316606618	0.019136301069084136	100	0.0015	100	50	1e-06	0.0	9510
3	0.01832496724885464	0.017733673387016553	100	0.0015	100	50	1e-06	0.0	9510
4	0.017465624312594064	0.017342900590219642	100	0.0015	100	50	1e-06	0.0	9510
5	0.016906829089603857	0.017555493270233986	100	0.0015	100	50	1e-06	0.0	9510
6	0.016825487931089494	0.016619189699353155	100	0.0015	100	50	1e-06	0.0	9510
7	0.01607233846527866	0.016626012901531578	100	0.0015	100	50	1e-06	0.0	9510
8	0.01586544578132145	0.01501372280792399	100	0.0015	100	50	1e-06	0.0	9510
9	0.015553126759584932	0.015031254410487287	100	0.0015	100	50	1e-06	0.0	9510
10	0.01548943978098229	0.015519916021174272	100	0.0015	100	50	1e-06	0.0	9510
11	0.015366869239722499	0.016024276567890128	100	0.0015	100	50	1e-06	0.0	9510
12	0.014901048619378092	0.014809231133152148	100	0.0015	100	50	1e-06	0.0	9510
13	0.014833618514754275	0.015684526760921764	100	0.0015	100	50	1e-06	0.0	9510
14	0.014572553462768879	0.014657636703727463	100	0.0015	100	50	1e-06	0.0	9510
15	0.014876060895930469	0.01556094654481395	100	0.0015	100	50	1e-06	0.0	9510
16	0.014686954598828341	0.014732607025973656	100	0.0015	100	50	1e-06	0.0	9510
17	0.014459161763828936	0.015481768375401515	100	0.0015	100	50	1e-06	0.0	9510
18	0.01444284950438315	0.01417158676906138	100	0.0015	100	50	1e-06	0.0	9510
19	0.014515393439030895	0.014629789969988921	100	0.0015	100	50	1e-06	0.0	9510
20	0.014073135302778348	0.015392787863160296	100	0.0015	100	50	1e-06	0.0	9510
21	0.014252257401088618	0.014143010642358154	100	0.0015	100	50	1e-06	0.0	9510
22	0.01419481974250244	0.014145291392579248	100	0.0015	100	50	1e-06	0.0	9510
23	0.01425927857816232	0.013761660988739982	100	0.0015	100	50	1e-06	0.0	9510
24	0.01427167587045176	0.014031783177252026	100	0.0015	100	50	1e-06	0.0	9510
25	0.014103921002567979	0.014225415324518034	100	0.0015	100	50	1e-06	0.0	9510
26	0.013791846386371182	0.013821757284578927	100	0.0015	100	50	1e-06	0.0	9510
27	0.014189471314963665	0.01479500551738315	100	0.0015	100	50	1e-06	0.0	9510
28	0.013902818686463881	0.015458215462546047	100	0.0015	100	50	1e-06	0.0	9510
29	0.013861387933335401	0.013465060378793435	100	0.0015	100	50	1e-06	0.0	9510
30	0.013894930383861128	0.01468885957973922	100	0.0015	100	50	1e-06	0.0	9510
31	0.013949586832744497	0.014123686975719368	100	0.0015	100	50	1e-06	0.0	9510
32	0.014008805984277966	0.01571767101060763	100	0.0015	100	50	1e-06	0.0	9510
33	0.013670741723988687	0.015010334147108331	100	0.0015	100	50	1e-06	0.0	9510
34	0.013770503281571844	0.01526390721248623	100	0.0015	100	50	1e-06	0.0	9510
35	0.013910516708773463	0.015493410473856826	100	0.0015	100	50	1e-06	0.0	9510
36	0.013883495833643606	0.014706142754231653	100	0.0015	100	50	1e-06	0.0	9510
37	0.013643670390527959	0.014455317695897578	100	0.0015	100	50	1e-06	0.0	9510
38	0.014077531246645132	0.015101349194949033	100	0.0015	100	50	1e-06	0.0	9510
39	0.013538258567450057	0.01454350408736481	100	0.0015	100	50	1e-06	0.0	9510
40	0.013705158970666707	0.015099167229027183	100	0.0015	100	50	1e-06	0.0	9510
41	0.013734529118517545	0.014841985639476753	100	0.0015	100	50	1e-06	0.0	9510
42	0.013633697527098337	0.013196561036784607	100	0.0015	100	50	1e-06	0.0	9510
43	0.013543609476998618	0.013079203250346061	100	0.0015	100	50	1e-06	0.0	9510
44	0.013594066883573576	0.013974331867797425	100	0.0015	100	50	1e-06	0.0	9510
45	0.014115732150130757	0.014072300739814287	100	0.0015	100	50	1e-06	0.0	9510
46	0.013344299508256524	0.013378119071229695	100	0.0015	100	50	1e-06	0.0	9510
47	0.013753697196963387	0.014422192784955807	100	0.0015	100	50	1e-06	0.0	9510
48	0.013220565736592195	0.015009126125569554	100	0.0015	100	50	1e-06	0.0	9510
49	0.013968728136136284	0.013494888728352738	100	0.0015	100	50	1e-06	0.0	9510
