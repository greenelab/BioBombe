	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.04631597213177977	0.0319277665205656	100	0.0005	100	50	1e-06	0.1	2390
1	0.02799124842115648	0.024691411651970096	100	0.0005	100	50	1e-06	0.1	2390
2	0.023184060249198613	0.021441390495711712	100	0.0005	100	50	1e-06	0.1	2390
3	0.02098557404983022	0.019832882809365456	100	0.0005	100	50	1e-06	0.1	2390
4	0.019617100882929773	0.018724801652774528	100	0.0005	100	50	1e-06	0.1	2390
5	0.018667943292628573	0.01792411464684951	100	0.0005	100	50	1e-06	0.1	2390
6	0.017951647092092654	0.017277296219398598	100	0.0005	100	50	1e-06	0.1	2390
7	0.017390809630866096	0.0169240115495331	100	0.0005	100	50	1e-06	0.1	2390
8	0.01691378742560521	0.016563817349406776	100	0.0005	100	50	1e-06	0.1	2390
9	0.016617030125065036	0.016539794688485206	100	0.0005	100	50	1e-06	0.1	2390
10	0.016370847637800827	0.015770130308191816	100	0.0005	100	50	1e-06	0.1	2390
11	0.01594079404271499	0.015478761398356343	100	0.0005	100	50	1e-06	0.1	2390
12	0.01574535326800491	0.015481813623788936	100	0.0005	100	50	1e-06	0.1	2390
13	0.015478106178196865	0.015121845275619519	100	0.0005	100	50	1e-06	0.1	2390
14	0.015248010700817292	0.014930710326488456	100	0.0005	100	50	1e-06	0.1	2390
15	0.015100247750345103	0.014996919695494508	100	0.0005	100	50	1e-06	0.1	2390
16	0.014904855570232408	0.014503388220433637	100	0.0005	100	50	1e-06	0.1	2390
17	0.014727310204899622	0.014437733608054044	100	0.0005	100	50	1e-06	0.1	2390
18	0.014570094560033853	0.014753372545565975	100	0.0005	100	50	1e-06	0.1	2390
19	0.014606423332593075	0.014432802454463383	100	0.0005	100	50	1e-06	0.1	2390
20	0.0142697397172079	0.014140341197626655	100	0.0005	100	50	1e-06	0.1	2390
21	0.014114811269588776	0.01383484087806074	100	0.0005	100	50	1e-06	0.1	2390
22	0.013991730348816032	0.01415044013375192	100	0.0005	100	50	1e-06	0.1	2390
23	0.013946539025152577	0.01392856348362924	100	0.0005	100	50	1e-06	0.1	2390
24	0.01384013398004005	0.013807002592112434	100	0.0005	100	50	1e-06	0.1	2390
25	0.013822760053622499	0.013658672033401337	100	0.0005	100	50	1e-06	0.1	2390
26	0.013597426061400455	0.013356559582225565	100	0.0005	100	50	1e-06	0.1	2390
27	0.013453108154658359	0.013661556825554621	100	0.0005	100	50	1e-06	0.1	2390
28	0.013493196064309291	0.013246325003143478	100	0.0005	100	50	1e-06	0.1	2390
29	0.013303313858654324	0.013586394691814885	100	0.0005	100	50	1e-06	0.1	2390
30	0.013421893269310408	0.013485129685791113	100	0.0005	100	50	1e-06	0.1	2390
31	0.013191065196951929	0.012914857212774612	100	0.0005	100	50	1e-06	0.1	2390
32	0.013032576727285992	0.012899290355381843	100	0.0005	100	50	1e-06	0.1	2390
33	0.013033691998387128	0.0130684982369125	100	0.0005	100	50	1e-06	0.1	2390
34	0.013022923249124841	0.013158814728715908	100	0.0005	100	50	1e-06	0.1	2390
35	0.01283176676049143	0.013112540816243589	100	0.0005	100	50	1e-06	0.1	2390
36	0.012830657658598463	0.012741483001832638	100	0.0005	100	50	1e-06	0.1	2390
37	0.012770333748639682	0.012926081592576796	100	0.0005	100	50	1e-06	0.1	2390
38	0.012716137745122714	0.012613513417912373	100	0.0005	100	50	1e-06	0.1	2390
39	0.012633928611778015	0.013061699177891756	100	0.0005	100	50	1e-06	0.1	2390
40	0.012685991027700644	0.01246373333663717	100	0.0005	100	50	1e-06	0.1	2390
41	0.01254013971174582	0.01259780371380012	100	0.0005	100	50	1e-06	0.1	2390
42	0.01243061168509333	0.012400750727900242	100	0.0005	100	50	1e-06	0.1	2390
43	0.01240459446522507	0.012374164347837805	100	0.0005	100	50	1e-06	0.1	2390
44	0.012346047503304008	0.012294647194815525	100	0.0005	100	50	1e-06	0.1	2390
45	0.012297845612683054	0.012819407744614503	100	0.0005	100	50	1e-06	0.1	2390
46	0.012436442683167612	0.012460375363167454	100	0.0005	100	50	1e-06	0.1	2390
47	0.012289159172867077	0.012282970710434946	100	0.0005	100	50	1e-06	0.1	2390
48	0.012136335041926846	0.012378168096463152	100	0.0005	100	50	1e-06	0.1	2390
49	0.012228895090662856	0.012246816928354208	100	0.0005	100	50	1e-06	0.1	2390
