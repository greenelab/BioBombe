	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.04286114075153347	0.03222406674781903	5	0.0005	50	50	0.0	0.5	6801
1	0.029980324175492568	0.029230250177431288	5	0.0005	50	50	0.0	0.5	6801
2	0.027456606256332405	0.026771133081777376	5	0.0005	50	50	0.0	0.5	6801
3	0.02609513811592967	0.026184498312852807	5	0.0005	50	50	0.0	0.5	6801
4	0.025754372042052793	0.025973570844724802	5	0.0005	50	50	0.0	0.5	6801
5	0.025607912073502135	0.02584643528420998	5	0.0005	50	50	0.0	0.5	6801
6	0.02550270346534641	0.02572982093714619	5	0.0005	50	50	0.0	0.5	6801
7	0.02541960251944916	0.025630458662318455	5	0.0005	50	50	0.0	0.5	6801
8	0.025336331772659253	0.025558172089419903	5	0.0005	50	50	0.0	0.5	6801
9	0.02525355758652618	0.025456394622704267	5	0.0005	50	50	0.0	0.5	6801
10	0.025198727737113708	0.02538570996737161	5	0.0005	50	50	0.0	0.5	6801
11	0.025116564258363172	0.02528496083392126	5	0.0005	50	50	0.0	0.5	6801
12	0.02503631207100595	0.025195950478400828	5	0.0005	50	50	0.0	0.5	6801
13	0.024958584175261013	0.025105569646987586	5	0.0005	50	50	0.0	0.5	6801
14	0.024892242329525006	0.025028236060764777	5	0.0005	50	50	0.0	0.5	6801
15	0.02480471696422449	0.024948882469711522	5	0.0005	50	50	0.0	0.5	6801
16	0.024738689515497077	0.024847029118903737	5	0.0005	50	50	0.0	0.5	6801
17	0.024675813291337022	0.02478626331610046	5	0.0005	50	50	0.0	0.5	6801
18	0.024603045467850467	0.024701376618322404	5	0.0005	50	50	0.0	0.5	6801
19	0.024541341934840293	0.024657572457570418	5	0.0005	50	50	0.0	0.5	6801
20	0.024482908533722033	0.024551388748830637	5	0.0005	50	50	0.0	0.5	6801
21	0.02443680946905042	0.02450374107501589	5	0.0005	50	50	0.0	0.5	6801
22	0.024397300044584194	0.024456067876195815	5	0.0005	50	50	0.0	0.5	6801
23	0.0243402632206843	0.024470783581326844	5	0.0005	50	50	0.0	0.5	6801
24	0.02430735857227043	0.024359254184291194	5	0.0005	50	50	0.0	0.5	6801
25	0.024248181284344642	0.024340751461584983	5	0.0005	50	50	0.0	0.5	6801
26	0.02422755039356903	0.02428785419843051	5	0.0005	50	50	0.0	0.5	6801
27	0.024183114342534756	0.0242500175253611	5	0.0005	50	50	0.0	0.5	6801
28	0.024164503174903706	0.024208402232646257	5	0.0005	50	50	0.0	0.5	6801
29	0.024132683774236538	0.024177396723405808	5	0.0005	50	50	0.0	0.5	6801
30	0.024108675072949334	0.024185364464045025	5	0.0005	50	50	0.0	0.5	6801
31	0.024093788404096442	0.024136612352062138	5	0.0005	50	50	0.0	0.5	6801
32	0.024073089639465587	0.024088566495999553	5	0.0005	50	50	0.0	0.5	6801
33	0.0240477109505015	0.024105973427769788	5	0.0005	50	50	0.0	0.5	6801
34	0.024018573008092216	0.024067304016983076	5	0.0005	50	50	0.0	0.5	6801
35	0.024004813541123847	0.024037227323047288	5	0.0005	50	50	0.0	0.5	6801
36	0.023992164142791553	0.024032890298056556	5	0.0005	50	50	0.0	0.5	6801
37	0.02397319528951087	0.024004299029793383	5	0.0005	50	50	0.0	0.5	6801
38	0.023959304706215174	0.024023462033494026	5	0.0005	50	50	0.0	0.5	6801
39	0.023955837226347438	0.024006893705170652	5	0.0005	50	50	0.0	0.5	6801
40	0.023937891600250845	0.023954966331673627	5	0.0005	50	50	0.0	0.5	6801
41	0.023927044696471878	0.02396475600993998	5	0.0005	50	50	0.0	0.5	6801
42	0.023915081923202425	0.023923299647511533	5	0.0005	50	50	0.0	0.5	6801
43	0.023903709257406026	0.023942346301777412	5	0.0005	50	50	0.0	0.5	6801
44	0.023888175490035347	0.023943018232317318	5	0.0005	50	50	0.0	0.5	6801
45	0.023876091015176796	0.023921475929152898	5	0.0005	50	50	0.0	0.5	6801
46	0.02387049947949901	0.02390595693604212	5	0.0005	50	50	0.0	0.5	6801
47	0.023863167244445108	0.02390758303594179	5	0.0005	50	50	0.0	0.5	6801
48	0.02386320690495497	0.023903445705742956	5	0.0005	50	50	0.0	0.5	6801
49	0.023829367665779155	0.023880071072602364	5	0.0005	50	50	0.0	0.5	6801
