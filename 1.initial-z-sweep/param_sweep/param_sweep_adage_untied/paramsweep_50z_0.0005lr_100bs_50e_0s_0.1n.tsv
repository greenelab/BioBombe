	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.03802563322014045	0.026254020595698695	50	0.0005	100	50	0.0	0.1	4156
1	0.023362763097014447	0.02103575571203323	50	0.0005	100	50	0.0	0.1	4156
2	0.019170073409440425	0.01806841850152549	50	0.0005	100	50	0.0	0.1	4156
3	0.016878862184660667	0.01646796671983503	50	0.0005	100	50	0.0	0.1	4156
4	0.015606891066445423	0.015483209396753439	50	0.0005	100	50	0.0	0.1	4156
5	0.014709724428963867	0.014655524487277746	50	0.0005	100	50	0.0	0.1	4156
6	0.014057375729308806	0.014102677086343274	50	0.0005	100	50	0.0	0.1	4156
7	0.013578235168470265	0.013685584014876394	50	0.0005	100	50	0.0	0.1	4156
8	0.013195023652806072	0.013371522502749304	50	0.0005	100	50	0.0	0.1	4156
9	0.012910360907729129	0.01311039346596137	50	0.0005	100	50	0.0	0.1	4156
10	0.012672200340599148	0.012946402591726178	50	0.0005	100	50	0.0	0.1	4156
11	0.012479379230354908	0.012696431768100074	50	0.0005	100	50	0.0	0.1	4156
12	0.0123075268660831	0.012548763139340778	50	0.0005	100	50	0.0	0.1	4156
13	0.01215989472858808	0.01241566297770914	50	0.0005	100	50	0.0	0.1	4156
14	0.012031905412829088	0.012290194682264078	50	0.0005	100	50	0.0	0.1	4156
15	0.011920089716788092	0.012261203730596412	50	0.0005	100	50	0.0	0.1	4156
16	0.011833731354871509	0.012119387848085472	50	0.0005	100	50	0.0	0.1	4156
17	0.011766418748765054	0.012047877223595948	50	0.0005	100	50	0.0	0.1	4156
18	0.011722272609949309	0.011996100348621664	50	0.0005	100	50	0.0	0.1	4156
19	0.011672774599689954	0.011956165375519209	50	0.0005	100	50	0.0	0.1	4156
20	0.011645004379626454	0.01192183671501353	50	0.0005	100	50	0.0	0.1	4156
21	0.011612401796334876	0.011903826076088626	50	0.0005	100	50	0.0	0.1	4156
22	0.011602738180975345	0.011903117747396857	50	0.0005	100	50	0.0	0.1	4156
23	0.011584680926968526	0.011895175168493737	50	0.0005	100	50	0.0	0.1	4156
24	0.0115704390205602	0.011879859545604677	50	0.0005	100	50	0.0	0.1	4156
25	0.011562616267414385	0.01186197355966552	50	0.0005	100	50	0.0	0.1	4156
26	0.011549358104090374	0.011867548725487625	50	0.0005	100	50	0.0	0.1	4156
27	0.011536892670411828	0.011854196925350174	50	0.0005	100	50	0.0	0.1	4156
28	0.011530111771297357	0.011822924142557393	50	0.0005	100	50	0.0	0.1	4156
29	0.011523794121509954	0.011817395817096671	50	0.0005	100	50	0.0	0.1	4156
30	0.011518273108213281	0.011812631902685585	50	0.0005	100	50	0.0	0.1	4156
31	0.011513639211873913	0.011863374197588481	50	0.0005	100	50	0.0	0.1	4156
32	0.01151501049081723	0.011795820269455873	50	0.0005	100	50	0.0	0.1	4156
33	0.011499898112628838	0.011806253612711029	50	0.0005	100	50	0.0	0.1	4156
34	0.011493656516564294	0.011796599369759655	50	0.0005	100	50	0.0	0.1	4156
35	0.011491092642011138	0.011789372418766724	50	0.0005	100	50	0.0	0.1	4156
36	0.01149237280192888	0.01180211872389508	50	0.0005	100	50	0.0	0.1	4156
37	0.011479485805230396	0.011772567361778442	50	0.0005	100	50	0.0	0.1	4156
38	0.011476882805432983	0.011771584469219581	50	0.0005	100	50	0.0	0.1	4156
39	0.011472049936126614	0.011768967431416134	50	0.0005	100	50	0.0	0.1	4156
40	0.011469691901968476	0.011763260922400036	50	0.0005	100	50	0.0	0.1	4156
41	0.011466317839602329	0.011764583307857951	50	0.0005	100	50	0.0	0.1	4156
42	0.011462347277544117	0.011776849752146016	50	0.0005	100	50	0.0	0.1	4156
43	0.01145707498644207	0.011750529477476047	50	0.0005	100	50	0.0	0.1	4156
44	0.011460315855333742	0.011747011868550263	50	0.0005	100	50	0.0	0.1	4156
45	0.011454381882743869	0.011803669903078339	50	0.0005	100	50	0.0	0.1	4156
46	0.011452304997685124	0.011757481964322851	50	0.0005	100	50	0.0	0.1	4156
47	0.011451165623999289	0.011788725776394855	50	0.0005	100	50	0.0	0.1	4156
48	0.011450521437583626	0.011744576050449398	50	0.0005	100	50	0.0	0.1	4156
49	0.011446121450730082	0.011789505031622276	50	0.0005	100	50	0.0	0.1	4156
