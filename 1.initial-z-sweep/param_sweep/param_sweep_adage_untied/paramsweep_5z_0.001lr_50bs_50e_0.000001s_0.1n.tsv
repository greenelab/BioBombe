	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.0384954743235306	0.029940134932929883	5	0.001	50	50	1e-06	0.1	3714
1	0.026263940607632028	0.02459651369238219	5	0.001	50	50	1e-06	0.1	3714
2	0.02402910955359493	0.023812986475844684	5	0.001	50	50	1e-06	0.1	3714
3	0.023494602061794653	0.023367237288996322	5	0.001	50	50	1e-06	0.1	3714
4	0.023188713671453358	0.023124616550384926	5	0.001	50	50	1e-06	0.1	3714
5	0.02296773868086683	0.023048984164632073	5	0.001	50	50	1e-06	0.1	3714
6	0.02278214517332163	0.022750098546735414	5	0.001	50	50	1e-06	0.1	3714
7	0.02261618306231267	0.022636100037262043	5	0.001	50	50	1e-06	0.1	3714
8	0.022463297364746716	0.02249063182458367	5	0.001	50	50	1e-06	0.1	3714
9	0.022342332173880906	0.02231283596650934	5	0.001	50	50	1e-06	0.1	3714
10	0.022220544582340677	0.02220971800429643	5	0.001	50	50	1e-06	0.1	3714
11	0.022097188615287946	0.022131993237662042	5	0.001	50	50	1e-06	0.1	3714
12	0.022001667052679953	0.02201641486676314	5	0.001	50	50	1e-06	0.1	3714
13	0.021932953559428148	0.021961082923395228	5	0.001	50	50	1e-06	0.1	3714
14	0.02184975813331436	0.02206616547051283	5	0.001	50	50	1e-06	0.1	3714
15	0.021793598857089206	0.021838539484781472	5	0.001	50	50	1e-06	0.1	3714
16	0.021724814189936142	0.021885007046462245	5	0.001	50	50	1e-06	0.1	3714
17	0.021686720835260867	0.02175819955011171	5	0.001	50	50	1e-06	0.1	3714
18	0.021631482992949324	0.021735443614323554	5	0.001	50	50	1e-06	0.1	3714
19	0.021570729011226305	0.02173881750219069	5	0.001	50	50	1e-06	0.1	3714
20	0.021542693063154504	0.02169811739862307	5	0.001	50	50	1e-06	0.1	3714
21	0.021528550104402234	0.021820032944186923	5	0.001	50	50	1e-06	0.1	3714
22	0.02147963696283988	0.02154951861366829	5	0.001	50	50	1e-06	0.1	3714
23	0.0214385579785489	0.021538086545370504	5	0.001	50	50	1e-06	0.1	3714
24	0.021422155743428616	0.021512824333278217	5	0.001	50	50	1e-06	0.1	3714
25	0.021387155007178783	0.021486004048791033	5	0.001	50	50	1e-06	0.1	3714
26	0.021342651156494294	0.021578635087318675	5	0.001	50	50	1e-06	0.1	3714
27	0.021366109616415704	0.02149938331136968	5	0.001	50	50	1e-06	0.1	3714
28	0.02132825346869983	0.021422100572154126	5	0.001	50	50	1e-06	0.1	3714
29	0.02134081844209162	0.021396519726651575	5	0.001	50	50	1e-06	0.1	3714
30	0.021279586253484518	0.021409667323184972	5	0.001	50	50	1e-06	0.1	3714
31	0.021262126868598824	0.021433410866909	5	0.001	50	50	1e-06	0.1	3714
32	0.02124023823564027	0.021381311820210965	5	0.001	50	50	1e-06	0.1	3714
33	0.02126162651893431	0.021331605791732183	5	0.001	50	50	1e-06	0.1	3714
34	0.02124159889208432	0.02133476995572761	5	0.001	50	50	1e-06	0.1	3714
35	0.021210401694840546	0.021342960537106766	5	0.001	50	50	1e-06	0.1	3714
36	0.02120000605123064	0.02138968930716838	5	0.001	50	50	1e-06	0.1	3714
37	0.02119408378750165	0.02126267169518521	5	0.001	50	50	1e-06	0.1	3714
38	0.021178185278869367	0.02125464212398684	5	0.001	50	50	1e-06	0.1	3714
39	0.02117553071429464	0.021370531902087576	5	0.001	50	50	1e-06	0.1	3714
40	0.02116528265083221	0.02132618569378985	5	0.001	50	50	1e-06	0.1	3714
41	0.02118769859600071	0.02123098186863654	5	0.001	50	50	1e-06	0.1	3714
42	0.021129305393823995	0.02123580391502745	5	0.001	50	50	1e-06	0.1	3714
43	0.021132195788112797	0.021605081678177613	5	0.001	50	50	1e-06	0.1	3714
44	0.021125317297810184	0.021180764720356716	5	0.001	50	50	1e-06	0.1	3714
45	0.021107377117175384	0.02121164382259089	5	0.001	50	50	1e-06	0.1	3714
46	0.021101732839531716	0.021225377076784464	5	0.001	50	50	1e-06	0.1	3714
47	0.02111105280566688	0.021182706429984557	5	0.001	50	50	1e-06	0.1	3714
48	0.021086017966973316	0.021339670689082053	5	0.001	50	50	1e-06	0.1	3714
49	0.021123794579563225	0.021844884024551904	5	0.001	50	50	1e-06	0.1	3714
