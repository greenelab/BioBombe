	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.060835242289628305	0.03528961486558841	5	0.0005	50	50	0.0	0.0	2090
1	0.034620755719246346	0.03455892506538112	5	0.0005	50	50	0.0	0.0	2090
2	0.03416905223826198	0.03435137631446408	5	0.0005	50	50	0.0	0.0	2090
3	0.03398730663740393	0.03418048604411103	5	0.0005	50	50	0.0	0.0	2090
4	0.03387980956121572	0.034104135172373935	5	0.0005	50	50	0.0	0.0	2090
5	0.03378755242284674	0.03399726192165971	5	0.0005	50	50	0.0	0.0	2090
6	0.03368551375693258	0.033889615042829606	5	0.0005	50	50	0.0	0.0	2090
7	0.03358920320194117	0.03381133418580086	5	0.0005	50	50	0.0	0.0	2090
8	0.03349229240504864	0.03367282073396342	5	0.0005	50	50	0.0	0.0	2090
9	0.03338469496527349	0.033588663826253175	5	0.0005	50	50	0.0	0.0	2090
10	0.03327811219436917	0.03346821368025548	5	0.0005	50	50	0.0	0.0	2090
11	0.03317355840146054	0.033351464663591256	5	0.0005	50	50	0.0	0.0	2090
12	0.033063465969780104	0.03324852736371197	5	0.0005	50	50	0.0	0.0	2090
13	0.03295071127381333	0.03313048099867472	5	0.0005	50	50	0.0	0.0	2090
14	0.03283507295699273	0.03300355079923943	5	0.0005	50	50	0.0	0.0	2090
15	0.03272130954240899	0.03290009965860137	5	0.0005	50	50	0.0	0.0	2090
16	0.032607003903966474	0.03274522065745941	5	0.0005	50	50	0.0	0.0	2090
17	0.032494682598212796	0.03262177369348975	5	0.0005	50	50	0.0	0.0	2090
18	0.03238324075185327	0.03249524192560471	5	0.0005	50	50	0.0	0.0	2090
19	0.03227588240503252	0.03238301803259959	5	0.0005	50	50	0.0	0.0	2090
20	0.032165001204771025	0.032253119930710436	5	0.0005	50	50	0.0	0.0	2090
21	0.03205758067097052	0.032126094932253	5	0.0005	50	50	0.0	0.0	2090
22	0.03194601282170269	0.03203325059770626	5	0.0005	50	50	0.0	0.0	2090
23	0.031848771925621834	0.03189568253266082	5	0.0005	50	50	0.0	0.0	2090
24	0.031738793594758924	0.03179653960833928	5	0.0005	50	50	0.0	0.0	2090
25	0.03163939474086623	0.03167533473847131	5	0.0005	50	50	0.0	0.0	2090
26	0.03154078887791965	0.031548016592432844	5	0.0005	50	50	0.0	0.0	2090
27	0.03144400486477019	0.03143720950995417	5	0.0005	50	50	0.0	0.0	2090
28	0.03135538891885494	0.031328008593866745	5	0.0005	50	50	0.0	0.0	2090
29	0.03126745313543715	0.031204326420196157	5	0.0005	50	50	0.0	0.0	2090
30	0.031177035838121765	0.031108119288178065	5	0.0005	50	50	0.0	0.0	2090
31	0.03109693117807804	0.031005905143361018	5	0.0005	50	50	0.0	0.0	2090
32	0.031021878982082914	0.030914540383003182	5	0.0005	50	50	0.0	0.0	2090
33	0.03094746829152525	0.03082786373665866	5	0.0005	50	50	0.0	0.0	2090
34	0.030879728733926526	0.030747134477099543	5	0.0005	50	50	0.0	0.0	2090
35	0.03081204602727345	0.030663633704840796	5	0.0005	50	50	0.0	0.0	2090
36	0.030749156490137684	0.03058817298872749	5	0.0005	50	50	0.0	0.0	2090
37	0.030689005214714238	0.030523656345690185	5	0.0005	50	50	0.0	0.0	2090
38	0.03063327291798138	0.03044305542701175	5	0.0005	50	50	0.0	0.0	2090
39	0.03057957072122424	0.030374693689622114	5	0.0005	50	50	0.0	0.0	2090
40	0.030529129166822117	0.030332258576616273	5	0.0005	50	50	0.0	0.0	2090
41	0.030482241348410457	0.030258246685020328	5	0.0005	50	50	0.0	0.0	2090
42	0.03043631014857284	0.030206824266431894	5	0.0005	50	50	0.0	0.0	2090
43	0.030400051545871377	0.030140656650237328	5	0.0005	50	50	0.0	0.0	2090
44	0.030355006915852658	0.030095603163879416	5	0.0005	50	50	0.0	0.0	2090
45	0.03031642299035043	0.03006205807153285	5	0.0005	50	50	0.0	0.0	2090
46	0.030280694836455985	0.030023066611892864	5	0.0005	50	50	0.0	0.0	2090
47	0.030244191999875762	0.0300293667188509	5	0.0005	50	50	0.0	0.0	2090
48	0.030219345386292912	0.02994518066412746	5	0.0005	50	50	0.0	0.0	2090
49	0.030186568081622726	0.029903232150249908	5	0.0005	50	50	0.0	0.0	2090
