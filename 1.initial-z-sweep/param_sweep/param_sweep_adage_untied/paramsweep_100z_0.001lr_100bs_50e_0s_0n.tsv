	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.031160274279696344	0.02023518126792707	100	0.001	100	50	0.0	0.0	7273
1	0.017118126658144356	0.015524843860823612	100	0.001	100	50	0.0	0.0	7273
2	0.014500212391905116	0.013980799164074556	100	0.001	100	50	0.0	0.0	7273
3	0.013331180779742444	0.01312252754313483	100	0.001	100	50	0.0	0.0	7273
4	0.012616771072169856	0.012529527503163706	100	0.001	100	50	0.0	0.0	7273
5	0.012063140244488634	0.012030071862056195	100	0.001	100	50	0.0	0.0	7273
6	0.01162513189728558	0.011663007589117633	100	0.001	100	50	0.0	0.0	7273
7	0.011286773793395377	0.0114042752192678	100	0.001	100	50	0.0	0.0	7273
8	0.01103032696683466	0.011250190458208836	100	0.001	100	50	0.0	0.0	7273
9	0.01083188242590951	0.010971301972481421	100	0.001	100	50	0.0	0.0	7273
10	0.010673459897206241	0.01090131079453982	100	0.001	100	50	0.0	0.0	7273
11	0.010579476616014194	0.010784332786489057	100	0.001	100	50	0.0	0.0	7273
12	0.01048596868144868	0.010733949946485332	100	0.001	100	50	0.0	0.0	7273
13	0.010424229412088419	0.01075527435400119	100	0.001	100	50	0.0	0.0	7273
14	0.010401226978277686	0.010636741754885614	100	0.001	100	50	0.0	0.0	7273
15	0.010366208341796239	0.010608666243448313	100	0.001	100	50	0.0	0.0	7273
16	0.010330866541625221	0.010629800776906497	100	0.001	100	50	0.0	0.0	7273
17	0.010331981092937583	0.010578677702844713	100	0.001	100	50	0.0	0.0	7273
18	0.010305498407683291	0.010570484959657516	100	0.001	100	50	0.0	0.0	7273
19	0.010291022534304979	0.01055972930222009	100	0.001	100	50	0.0	0.0	7273
20	0.010288067127407883	0.01054876520837983	100	0.001	100	50	0.0	0.0	7273
21	0.010266363011881064	0.010564126304028481	100	0.001	100	50	0.0	0.0	7273
22	0.010260978602225147	0.010575689012131318	100	0.001	100	50	0.0	0.0	7273
23	0.010252770972629605	0.010520106932971035	100	0.001	100	50	0.0	0.0	7273
24	0.010242044054027965	0.010529339845945798	100	0.001	100	50	0.0	0.0	7273
25	0.010247451550945913	0.01052418567354205	100	0.001	100	50	0.0	0.0	7273
26	0.010231084040711711	0.010530196878182957	100	0.001	100	50	0.0	0.0	7273
27	0.010223406573392836	0.010523507855903806	100	0.001	100	50	0.0	0.0	7273
28	0.010226867881479963	0.010523007819375619	100	0.001	100	50	0.0	0.0	7273
29	0.01021817005148897	0.010484887607552354	100	0.001	100	50	0.0	0.0	7273
30	0.010229877893977491	0.01050574792794755	100	0.001	100	50	0.0	0.0	7273
31	0.010201128234523434	0.010507930896421236	100	0.001	100	50	0.0	0.0	7273
32	0.010203008239098034	0.010475311857464779	100	0.001	100	50	0.0	0.0	7273
33	0.010198011047703596	0.010466399070153273	100	0.001	100	50	0.0	0.0	7273
34	0.010191829654178476	0.010491909375538903	100	0.001	100	50	0.0	0.0	7273
35	0.010194184880022585	0.01047373983660004	100	0.001	100	50	0.0	0.0	7273
36	0.010192476702434729	0.010505383490561642	100	0.001	100	50	0.0	0.0	7273
37	0.01018403405383978	0.010470646462023942	100	0.001	100	50	0.0	0.0	7273
38	0.010178642432741337	0.010543250934671376	100	0.001	100	50	0.0	0.0	7273
39	0.010192092322169291	0.01047323210375031	100	0.001	100	50	0.0	0.0	7273
40	0.010174897074039273	0.010471952379276945	100	0.001	100	50	0.0	0.0	7273
41	0.010177205070757459	0.010454671320293533	100	0.001	100	50	0.0	0.0	7273
42	0.010173329397340256	0.010571593707195888	100	0.001	100	50	0.0	0.0	7273
43	0.010167259047385498	0.010493199259085477	100	0.001	100	50	0.0	0.0	7273
44	0.010161632327541976	0.010462835169331407	100	0.001	100	50	0.0	0.0	7273
45	0.010161331477898043	0.010480079237179364	100	0.001	100	50	0.0	0.0	7273
46	0.01015393306017096	0.01046545444551435	100	0.001	100	50	0.0	0.0	7273
47	0.01015037005211381	0.0104464212019374	100	0.001	100	50	0.0	0.0	7273
48	0.010149926190779705	0.010555771256068696	100	0.001	100	50	0.0	0.0	7273
49	0.010167536064847856	0.010470023478450784	100	0.001	100	50	0.0	0.0	7273
