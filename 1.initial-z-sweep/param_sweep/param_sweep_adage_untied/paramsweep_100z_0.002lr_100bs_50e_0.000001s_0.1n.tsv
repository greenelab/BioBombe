	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.03759314145916209	0.024912966856907477	100	0.002	100	50	1e-06	0.1	1075
1	0.022761742355657963	0.02146059274673462	100	0.002	100	50	1e-06	0.1	1075
2	0.020208703427414553	0.020008705969522377	100	0.002	100	50	1e-06	0.1	1075
3	0.01906052426156339	0.019657874568926446	100	0.002	100	50	1e-06	0.1	1075
4	0.01832109197921173	0.019897918752884318	100	0.002	100	50	1e-06	0.1	1075
5	0.017623771422607043	0.01656151420114487	100	0.002	100	50	1e-06	0.1	1075
6	0.01717169211254681	0.017869206389365986	100	0.002	100	50	1e-06	0.1	1075
7	0.017143396940290087	0.016833546409386977	100	0.002	100	50	1e-06	0.1	1075
8	0.017126605844800517	0.017593111614937082	100	0.002	100	50	1e-06	0.1	1075
9	0.016487332514870005	0.015694132548388286	100	0.002	100	50	1e-06	0.1	1075
10	0.016370298061213148	0.017789165407461942	100	0.002	100	50	1e-06	0.1	1075
11	0.015966822608433125	0.01715369748368318	100	0.002	100	50	1e-06	0.1	1075
12	0.016254722477026615	0.01596686427604343	100	0.002	100	50	1e-06	0.1	1075
13	0.015993586864568192	0.017391112369501225	100	0.002	100	50	1e-06	0.1	1075
14	0.016201122755929394	0.016091822019740798	100	0.002	100	50	1e-06	0.1	1075
15	0.015734734537762023	0.017263241299209017	100	0.002	100	50	1e-06	0.1	1075
16	0.015794412379366685	0.015619751521836731	100	0.002	100	50	1e-06	0.1	1075
17	0.015581911290455268	0.01475833748497539	100	0.002	100	50	1e-06	0.1	1075
18	0.01563425745205964	0.015630347857226834	100	0.002	100	50	1e-06	0.1	1075
19	0.015659539069468664	0.01724278147957407	100	0.002	100	50	1e-06	0.1	1075
20	0.015572041710234151	0.015825106368807944	100	0.002	100	50	1e-06	0.1	1075
21	0.015370963094028798	0.015297098455676386	100	0.002	100	50	1e-06	0.1	1075
22	0.015295723829235185	0.01702185916085772	100	0.002	100	50	1e-06	0.1	1075
23	0.015909718452968336	0.016313410798589882	100	0.002	100	50	1e-06	0.1	1075
24	0.015120751113150675	0.016147633620945605	100	0.002	100	50	1e-06	0.1	1075
25	0.015293644209572736	0.01607782194073923	100	0.002	100	50	1e-06	0.1	1075
26	0.0156210418153405	0.01581362067556176	100	0.002	100	50	1e-06	0.1	1075
27	0.015398758039306654	0.014907455226730548	100	0.002	100	50	1e-06	0.1	1075
28	0.014621918353560904	0.014878431076885523	100	0.002	100	50	1e-06	0.1	1075
29	0.015099305949822617	0.014391526392880065	100	0.002	100	50	1e-06	0.1	1075
30	0.016096398770523435	0.01535470354376115	100	0.002	100	50	1e-06	0.1	1075
31	0.014972575722919422	0.015167027996785326	100	0.002	100	50	1e-06	0.1	1075
32	0.015591622493004718	0.014156486319082416	100	0.002	100	50	1e-06	0.1	1075
33	0.015177279427999025	0.01570410422453689	100	0.002	100	50	1e-06	0.1	1075
34	0.015166934634225726	0.015607730506867683	100	0.002	100	50	1e-06	0.1	1075
35	0.015195193075883925	0.016676377994765172	100	0.002	100	50	1e-06	0.1	1075
36	0.01511006438963192	0.014080945712231086	100	0.002	100	50	1e-06	0.1	1075
37	0.014578339149175168	0.015951664131811427	100	0.002	100	50	1e-06	0.1	1075
38	0.015337802073277645	0.01472961509432893	100	0.002	100	50	1e-06	0.1	1075
39	0.01498730268029	0.015519248560270434	100	0.002	100	50	1e-06	0.1	1075
40	0.014872855947021596	0.015650857845410333	100	0.002	100	50	1e-06	0.1	1075
41	0.015504993586381981	0.013607839020912893	100	0.002	100	50	1e-06	0.1	1075
42	0.014434689088478886	0.015166977817552382	100	0.002	100	50	1e-06	0.1	1075
43	0.015075645654895733	0.014863707538316628	100	0.002	100	50	1e-06	0.1	1075
44	0.015078426283721582	0.01724857009099672	100	0.002	100	50	1e-06	0.1	1075
45	0.014909710274120991	0.01631719171715968	100	0.002	100	50	1e-06	0.1	1075
46	0.014794122968013496	0.015138222470908047	100	0.002	100	50	1e-06	0.1	1075
47	0.014992766114640227	0.01608617462032612	100	0.002	100	50	1e-06	0.1	1075
48	0.014829008778582708	0.01573096578638025	100	0.002	100	50	1e-06	0.1	1075
49	0.014798252605765339	0.015176391903930709	100	0.002	100	50	1e-06	0.1	1075
