	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.026056843874391302	0.016780785696285404	100	0.001	50	50	0.0	0.5	3379
1	0.015628427642057328	0.013812881586343107	100	0.001	50	50	0.0	0.5	3379
2	0.013838831984550696	0.012703481149889999	100	0.001	50	50	0.0	0.5	3379
3	0.01303968989316714	0.012114258962069028	100	0.001	50	50	0.0	0.5	3379
4	0.01253957329635525	0.011730284649116587	100	0.001	50	50	0.0	0.5	3379
5	0.012206455197948699	0.011426515070575486	100	0.001	50	50	0.0	0.5	3379
6	0.011994507336512352	0.011131030915173245	100	0.001	50	50	0.0	0.5	3379
7	0.01185734935778035	0.011042501800560017	100	0.001	50	50	0.0	0.5	3379
8	0.011758683606626838	0.010965123111969769	100	0.001	50	50	0.0	0.5	3379
9	0.011682564017901027	0.010943046724690876	100	0.001	50	50	0.0	0.5	3379
10	0.01165573244593253	0.010849902634268509	100	0.001	50	50	0.0	0.5	3379
11	0.011627692681743478	0.010863763810870865	100	0.001	50	50	0.0	0.5	3379
12	0.011606682804517522	0.010828532039919729	100	0.001	50	50	0.0	0.5	3379
13	0.011594621712652775	0.01090386280002888	100	0.001	50	50	0.0	0.5	3379
14	0.011572330314094159	0.010800558849314431	100	0.001	50	50	0.0	0.5	3379
15	0.011576942405038624	0.01081507715323573	100	0.001	50	50	0.0	0.5	3379
16	0.011546834307969801	0.010767878417858772	100	0.001	50	50	0.0	0.5	3379
17	0.011528915236983557	0.01076529782628694	100	0.001	50	50	0.0	0.5	3379
18	0.01153247312825772	0.010810548696047261	100	0.001	50	50	0.0	0.5	3379
19	0.0115283306856862	0.010773074376907905	100	0.001	50	50	0.0	0.5	3379
20	0.011507444450560303	0.010760496584182145	100	0.001	50	50	0.0	0.5	3379
21	0.011506738981872586	0.010744394335617982	100	0.001	50	50	0.0	0.5	3379
22	0.011496156118976397	0.010789956771065241	100	0.001	50	50	0.0	0.5	3379
23	0.011490026941056157	0.010751455545026531	100	0.001	50	50	0.0	0.5	3379
24	0.011481368878727086	0.010732987101401699	100	0.001	50	50	0.0	0.5	3379
25	0.01147042325782235	0.010827265421630206	100	0.001	50	50	0.0	0.5	3379
26	0.011485019267459427	0.01082525572723515	100	0.001	50	50	0.0	0.5	3379
27	0.011460290549044546	0.010770421275730115	100	0.001	50	50	0.0	0.5	3379
28	0.011473128169420407	0.010736608651625153	100	0.001	50	50	0.0	0.5	3379
29	0.01144803051894075	0.010777531959201935	100	0.001	50	50	0.0	0.5	3379
30	0.011432809924591452	0.010719827595336032	100	0.001	50	50	0.0	0.5	3379
31	0.011447862108947144	0.010746296546840417	100	0.001	50	50	0.0	0.5	3379
32	0.011452174361810622	0.010783170568925929	100	0.001	50	50	0.0	0.5	3379
33	0.011428183787030899	0.010755520743134487	100	0.001	50	50	0.0	0.5	3379
34	0.011447715955712895	0.010899689363718146	100	0.001	50	50	0.0	0.5	3379
35	0.011432173420078193	0.010743113036977971	100	0.001	50	50	0.0	0.5	3379
36	0.011424909611855407	0.010723823350257672	100	0.001	50	50	0.0	0.5	3379
37	0.011441358394008994	0.010769283452407808	100	0.001	50	50	0.0	0.5	3379
38	0.011431487960726874	0.01073150069454603	100	0.001	50	50	0.0	0.5	3379
39	0.011409685151127317	0.010759914076635988	100	0.001	50	50	0.0	0.5	3379
40	0.011418367286359074	0.010755603791109463	100	0.001	50	50	0.0	0.5	3379
41	0.01141844913509888	0.010781888606073068	100	0.001	50	50	0.0	0.5	3379
42	0.011408236557272482	0.010739496702517082	100	0.001	50	50	0.0	0.5	3379
43	0.0114095772687901	0.010727647592244139	100	0.001	50	50	0.0	0.5	3379
44	0.011396999814112558	0.010781531576530199	100	0.001	50	50	0.0	0.5	3379
45	0.011398460081407739	0.010730770363135843	100	0.001	50	50	0.0	0.5	3379
46	0.011415542218615307	0.010740823753491528	100	0.001	50	50	0.0	0.5	3379
47	0.0113978880817425	0.010741768908788437	100	0.001	50	50	0.0	0.5	3379
48	0.011399394248112676	0.010769879764184555	100	0.001	50	50	0.0	0.5	3379
49	0.011391404712932637	0.010748913882026026	100	0.001	50	50	0.0	0.5	3379
