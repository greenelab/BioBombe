	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.0489355098801643	0.03613195909511291	25	0.0005	100	50	1e-06	0.1	2815
1	0.03141928898422096	0.028471733181671476	25	0.0005	100	50	1e-06	0.1	2815
2	0.02599874053921752	0.024374733420790495	25	0.0005	100	50	1e-06	0.1	2815
3	0.023045707390331304	0.022191162418794905	25	0.0005	100	50	1e-06	0.1	2815
4	0.021373729771728356	0.02090058879958854	25	0.0005	100	50	1e-06	0.1	2815
5	0.020333521915913345	0.01990676191893636	25	0.0005	100	50	1e-06	0.1	2815
6	0.019492618883760585	0.019148423989974746	25	0.0005	100	50	1e-06	0.1	2815
7	0.018808438506958482	0.018566235771712562	25	0.0005	100	50	1e-06	0.1	2815
8	0.018269378317324714	0.018141192603094172	25	0.0005	100	50	1e-06	0.1	2815
9	0.0178421326120133	0.017711562537240936	25	0.0005	100	50	1e-06	0.1	2815
10	0.017482637175351215	0.01746801338933166	25	0.0005	100	50	1e-06	0.1	2815
11	0.01719869577270375	0.01708307114018423	25	0.0005	100	50	1e-06	0.1	2815
12	0.01692875115222446	0.01687371742201125	25	0.0005	100	50	1e-06	0.1	2815
13	0.016710147902058433	0.016865025783744755	25	0.0005	100	50	1e-06	0.1	2815
14	0.01652344998406003	0.016638834143402927	25	0.0005	100	50	1e-06	0.1	2815
15	0.01635137673615412	0.016333967856849128	25	0.0005	100	50	1e-06	0.1	2815
16	0.01617766397821258	0.016354225987272895	25	0.0005	100	50	1e-06	0.1	2815
17	0.01604426694816438	0.016022280334044483	25	0.0005	100	50	1e-06	0.1	2815
18	0.01588920521278092	0.015964707790608615	25	0.0005	100	50	1e-06	0.1	2815
19	0.015756386376440074	0.015913482607621876	25	0.0005	100	50	1e-06	0.1	2815
20	0.015638040147763717	0.01563175838889401	25	0.0005	100	50	1e-06	0.1	2815
21	0.015537381008632294	0.015689745367314118	25	0.0005	100	50	1e-06	0.1	2815
22	0.01545884210317947	0.015536320995874204	25	0.0005	100	50	1e-06	0.1	2815
23	0.015330241015245256	0.015543049758738246	25	0.0005	100	50	1e-06	0.1	2815
24	0.015260857591676804	0.01542905465224277	25	0.0005	100	50	1e-06	0.1	2815
25	0.015183971783497103	0.015258553112014758	25	0.0005	100	50	1e-06	0.1	2815
26	0.015073244471799887	0.015311041237861202	25	0.0005	100	50	1e-06	0.1	2815
27	0.015016515916463712	0.015053237179369018	25	0.0005	100	50	1e-06	0.1	2815
28	0.014947821249918034	0.015474212177838582	25	0.0005	100	50	1e-06	0.1	2815
29	0.014911956044382342	0.015067143125342023	25	0.0005	100	50	1e-06	0.1	2815
30	0.014806848986203543	0.01483468109488943	25	0.0005	100	50	1e-06	0.1	2815
31	0.014736476897778603	0.014958485852335767	25	0.0005	100	50	1e-06	0.1	2815
32	0.014693395841938364	0.014768923720056422	25	0.0005	100	50	1e-06	0.1	2815
33	0.014649252417047853	0.01475170428506731	25	0.0005	100	50	1e-06	0.1	2815
34	0.014600364536262275	0.014657969962285536	25	0.0005	100	50	1e-06	0.1	2815
35	0.014541269648568063	0.014764832911468032	25	0.0005	100	50	1e-06	0.1	2815
36	0.014513589633818888	0.014577026868926408	25	0.0005	100	50	1e-06	0.1	2815
37	0.014444592762447583	0.014601587748820992	25	0.0005	100	50	1e-06	0.1	2815
38	0.014409416818726737	0.014589196827839598	25	0.0005	100	50	1e-06	0.1	2815
39	0.01438013176544258	0.014630342748222685	25	0.0005	100	50	1e-06	0.1	2815
40	0.014375443871489313	0.014448814111873935	25	0.0005	100	50	1e-06	0.1	2815
41	0.01429651302220093	0.014630093949759667	25	0.0005	100	50	1e-06	0.1	2815
42	0.014281632985397707	0.014371615061696697	25	0.0005	100	50	1e-06	0.1	2815
43	0.014220649069599576	0.014520680464191601	25	0.0005	100	50	1e-06	0.1	2815
44	0.014190761573394231	0.014303016004439294	25	0.0005	100	50	1e-06	0.1	2815
45	0.014169407702137874	0.014328668871627369	25	0.0005	100	50	1e-06	0.1	2815
46	0.014133308529236435	0.014442898450600941	25	0.0005	100	50	1e-06	0.1	2815
47	0.014100657906401085	0.01429304401844341	25	0.0005	100	50	1e-06	0.1	2815
48	0.014076306304568777	0.014162983747117264	25	0.0005	100	50	1e-06	0.1	2815
49	0.014052470776050709	0.014151047920562454	25	0.0005	100	50	1e-06	0.1	2815
