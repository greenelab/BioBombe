	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.026493879442352437	0.0183302544655695	50	0.0025	50	50	0.0	0.5	3217
1	0.018340382701749473	0.017312132484541342	50	0.0025	50	50	0.0	0.5	3217
2	0.01791952331635013	0.017109237782244015	50	0.0025	50	50	0.0	0.5	3217
3	0.017846876723201278	0.01720300643574838	50	0.0025	50	50	0.0	0.5	3217
4	0.01779788966739544	0.016991696233218303	50	0.0025	50	50	0.0	0.5	3217
5	0.017743407521572198	0.017100408774788134	50	0.0025	50	50	0.0	0.5	3217
6	0.01771846260156367	0.017165305461542213	50	0.0025	50	50	0.0	0.5	3217
7	0.01765626441090935	0.01686423920080721	50	0.0025	50	50	0.0	0.5	3217
8	0.017615757900008508	0.017087151757646246	50	0.0025	50	50	0.0	0.5	3217
9	0.017594662995692976	0.01682805620404548	50	0.0025	50	50	0.0	0.5	3217
10	0.017544192621047283	0.016720442250940812	50	0.0025	50	50	0.0	0.5	3217
11	0.017527493817715314	0.016774037692617504	50	0.0025	50	50	0.0	0.5	3217
12	0.017545566129604347	0.016755584650539418	50	0.0025	50	50	0.0	0.5	3217
13	0.017515212583772043	0.016721748034638953	50	0.0025	50	50	0.0	0.5	3217
14	0.017469090676418175	0.01662781267439373	50	0.0025	50	50	0.0	0.5	3217
15	0.01747481751794024	0.016785135556788792	50	0.0025	50	50	0.0	0.5	3217
16	0.017440285620733843	0.01672263119198795	50	0.0025	50	50	0.0	0.5	3217
17	0.017438093036679144	0.016684507443631928	50	0.0025	50	50	0.0	0.5	3217
18	0.017402542883827674	0.016615752185949517	50	0.0025	50	50	0.0	0.5	3217
19	0.017403719380013522	0.016585038844887774	50	0.0025	50	50	0.0	0.5	3217
20	0.01737310512955651	0.016654647810181628	50	0.0025	50	50	0.0	0.5	3217
21	0.017402795171623374	0.016723409038656756	50	0.0025	50	50	0.0	0.5	3217
22	0.01738619832194369	0.01663410597895744	50	0.0025	50	50	0.0	0.5	3217
23	0.01734958358467556	0.01658583483186837	50	0.0025	50	50	0.0	0.5	3217
24	0.01736053825790116	0.017010238967180593	50	0.0025	50	50	0.0	0.5	3217
25	0.01737843958458529	0.01671830083049449	50	0.0025	50	50	0.0	0.5	3217
26	0.017351200343845286	0.01670417185502401	50	0.0025	50	50	0.0	0.5	3217
27	0.01734594719615643	0.016523834551198418	50	0.0025	50	50	0.0	0.5	3217
28	0.01733691129508145	0.01657526953818978	50	0.0025	50	50	0.0	0.5	3217
29	0.017354234415690718	0.01667109482795228	50	0.0025	50	50	0.0	0.5	3217
30	0.01733220483235873	0.01655715802082539	50	0.0025	50	50	0.0	0.5	3217
31	0.017342080600289803	0.016607426872644323	50	0.0025	50	50	0.0	0.5	3217
32	0.017332310551569904	0.0167511230722839	50	0.0025	50	50	0.0	0.5	3217
33	0.01731283789146191	0.016701228291608295	50	0.0025	50	50	0.0	0.5	3217
34	0.017334666677570477	0.01665605693685165	50	0.0025	50	50	0.0	0.5	3217
35	0.01732172635812809	0.016653853634204966	50	0.0025	50	50	0.0	0.5	3217
36	0.017324900553010354	0.016593908691639882	50	0.0025	50	50	0.0	0.5	3217
37	0.017338781834755228	0.01668359340483725	50	0.0025	50	50	0.0	0.5	3217
38	0.01731144388510148	0.01661600369468588	50	0.0025	50	50	0.0	0.5	3217
39	0.017331761489569362	0.016672920587029214	50	0.0025	50	50	0.0	0.5	3217
40	0.017340286539583166	0.016589191165284376	50	0.0025	50	50	0.0	0.5	3217
41	0.017289397583871328	0.016537506083457467	50	0.0025	50	50	0.0	0.5	3217
42	0.017305333077081216	0.0165250431212025	50	0.0025	50	50	0.0	0.5	3217
43	0.017301931447744952	0.01656314375744438	50	0.0025	50	50	0.0	0.5	3217
44	0.017310242481156906	0.016730017662689403	50	0.0025	50	50	0.0	0.5	3217
45	0.017279336426055267	0.016536641080666114	50	0.0025	50	50	0.0	0.5	3217
46	0.017283037597147107	0.01663953034353245	50	0.0025	50	50	0.0	0.5	3217
47	0.01730470882263084	0.016654251690020865	50	0.0025	50	50	0.0	0.5	3217
48	0.017320262610913906	0.016658193462067077	50	0.0025	50	50	0.0	0.5	3217
49	0.017275317609555522	0.01653114059338093	50	0.0025	50	50	0.0	0.5	3217
