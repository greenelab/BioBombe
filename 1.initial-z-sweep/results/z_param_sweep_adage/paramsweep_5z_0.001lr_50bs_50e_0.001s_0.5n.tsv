	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.1899191967610293	0.11134684611517887	5	0.001	50	50	0.001	0.5	6562
1	0.14237004478537135	0.1010451299026181	5	0.001	50	50	0.001	0.5	6562
2	0.11103738096487151	0.07256710392567213	5	0.001	50	50	0.001	0.5	6562
3	0.09265786239517795	0.10076905912354617	5	0.001	50	50	0.001	0.5	6562
4	0.08089714388335459	0.0662185360693567	5	0.001	50	50	0.001	0.5	6562
5	0.07467600982250347	0.05826345937999667	5	0.001	50	50	0.001	0.5	6562
6	0.07107747599765901	0.06540640990604178	5	0.001	50	50	0.001	0.5	6562
7	0.07043229448465096	0.05698648905007607	5	0.001	50	50	0.001	0.5	6562
8	0.06595112433785474	0.07181085147547676	5	0.001	50	50	0.001	0.5	6562
9	0.0655168819862668	0.06916647156554472	5	0.001	50	50	0.001	0.5	6562
10	0.06764351385374967	0.06898076138521472	5	0.001	50	50	0.001	0.5	6562
11	0.06329836801104473	0.07579347542549411	5	0.001	50	50	0.001	0.5	6562
12	0.062366712714142646	0.04865870225896799	5	0.001	50	50	0.001	0.5	6562
13	0.06388536148690638	0.07043810012121729	5	0.001	50	50	0.001	0.5	6562
14	0.06509369256030889	0.05921412121155522	5	0.001	50	50	0.001	0.5	6562
15	0.060704186905409345	0.05895400635655934	5	0.001	50	50	0.001	0.5	6562
16	0.06366549995800558	0.07683891359980202	5	0.001	50	50	0.001	0.5	6562
17	0.06206316889657372	0.07208347626842458	5	0.001	50	50	0.001	0.5	6562
18	0.0612637225032315	0.05798964908998282	5	0.001	50	50	0.001	0.5	6562
19	0.06154525869285644	0.06398495455516456	5	0.001	50	50	0.001	0.5	6562
20	0.06216477947704384	0.05480341268543076	5	0.001	50	50	0.001	0.5	6562
21	0.06147231329436271	0.09090117830961202	5	0.001	50	50	0.001	0.5	6562
22	0.0636229109374038	0.07698976606073617	5	0.001	50	50	0.001	0.5	6562
23	0.060771250010762015	0.07333062177463426	5	0.001	50	50	0.001	0.5	6562
24	0.06136849280702033	0.06192503060369145	5	0.001	50	50	0.001	0.5	6562
25	0.06283390566130431	0.056730460033646964	5	0.001	50	50	0.001	0.5	6562
26	0.06104468523032871	0.06560188627322819	5	0.001	50	50	0.001	0.5	6562
27	0.061068877070812926	0.06573327620786189	5	0.001	50	50	0.001	0.5	6562
28	0.060451413440369375	0.06465696683064473	5	0.001	50	50	0.001	0.5	6562
29	0.06001579684727658	0.07770829667723657	5	0.001	50	50	0.001	0.5	6562
30	0.06066837253358302	0.06381784768394029	5	0.001	50	50	0.001	0.5	6562
31	0.0608107826980099	0.06780745448049579	5	0.001	50	50	0.001	0.5	6562
32	0.061920922239661585	0.05133026477170264	5	0.001	50	50	0.001	0.5	6562
33	0.0622775292889346	0.06133784479808853	5	0.001	50	50	0.001	0.5	6562
34	0.0608476081519328	0.06250459341115067	5	0.001	50	50	0.001	0.5	6562
35	0.06092107571082871	0.055169609291603645	5	0.001	50	50	0.001	0.5	6562
36	0.05918894351655842	0.07333291809201013	5	0.001	50	50	0.001	0.5	6562
37	0.061540919728953106	0.08499990944994568	5	0.001	50	50	0.001	0.5	6562
38	0.062630423791386	0.07228606312498308	5	0.001	50	50	0.001	0.5	6562
39	0.061409200919329214	0.06572123437436088	5	0.001	50	50	0.001	0.5	6562
40	0.06317502627631853	0.06690863884600809	5	0.001	50	50	0.001	0.5	6562
41	0.06205802237537618	0.05965559913226569	5	0.001	50	50	0.001	0.5	6562
42	0.05991745492627273	0.0656367923572916	5	0.001	50	50	0.001	0.5	6562
43	0.06134005358865534	0.05888609573188065	5	0.001	50	50	0.001	0.5	6562
44	0.060121567014549	0.06970722954827102	5	0.001	50	50	0.001	0.5	6562
45	0.06019745631687423	0.09793754141371747	5	0.001	50	50	0.001	0.5	6562
46	0.06194382937620895	0.07606199019041845	5	0.001	50	50	0.001	0.5	6562
47	0.060229923619254416	0.06858967659179385	5	0.001	50	50	0.001	0.5	6562
48	0.06303400822711222	0.057283296148305185	5	0.001	50	50	0.001	0.5	6562
49	0.06307754572055475	0.08216797990678146	5	0.001	50	50	0.001	0.5	6562
