	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.03829298186863215	0.0346307017151302	5	0.002	50	50	0.0	0.5	2871
1	0.033973769682424805	0.03430295494842712	5	0.002	50	50	0.0	0.5	2871
2	0.03364369942416145	0.03391531114083631	5	0.002	50	50	0.0	0.5	2871
3	0.03327379928177353	0.03342316099522675	5	0.002	50	50	0.0	0.5	2871
4	0.03289078504363985	0.03297604514325098	5	0.002	50	50	0.0	0.5	2871
5	0.032460664306261405	0.03259052315915634	5	0.002	50	50	0.0	0.5	2871
6	0.032078365748713554	0.03209154520817742	5	0.002	50	50	0.0	0.5	2871
7	0.03167019488778122	0.03172045685778271	5	0.002	50	50	0.0	0.5	2871
8	0.03134890036726908	0.03136549487239886	5	0.002	50	50	0.0	0.5	2871
9	0.031042748496045623	0.031101579555304966	5	0.002	50	50	0.0	0.5	2871
10	0.030788249984141376	0.030841202498280068	5	0.002	50	50	0.0	0.5	2871
11	0.03059202825859732	0.030550336109093225	5	0.002	50	50	0.0	0.5	2871
12	0.03041906341828044	0.030435816543337036	5	0.002	50	50	0.0	0.5	2871
13	0.030308482707224325	0.030285360052982206	5	0.002	50	50	0.0	0.5	2871
14	0.0301890553261273	0.030175787081539517	5	0.002	50	50	0.0	0.5	2871
15	0.030090529526646478	0.030100208438263342	5	0.002	50	50	0.0	0.5	2871
16	0.030017525090236512	0.030044159145017884	5	0.002	50	50	0.0	0.5	2871
17	0.029972651304532083	0.030026055929423746	5	0.002	50	50	0.0	0.5	2871
18	0.029923028459153695	0.029921591716389355	5	0.002	50	50	0.0	0.5	2871
19	0.029871299579101604	0.02984975852841515	5	0.002	50	50	0.0	0.5	2871
20	0.029862006197956686	0.02984572131450272	5	0.002	50	50	0.0	0.5	2871
21	0.0298294049078114	0.029913817819058327	5	0.002	50	50	0.0	0.5	2871
22	0.02980712860027991	0.029752936082434473	5	0.002	50	50	0.0	0.5	2871
23	0.02977310943409435	0.02972712385580371	5	0.002	50	50	0.0	0.5	2871
24	0.029753890536384376	0.029774113584943758	5	0.002	50	50	0.0	0.5	2871
25	0.02976479726267408	0.02974916820416145	5	0.002	50	50	0.0	0.5	2871
26	0.029733921678729486	0.029716010310510833	5	0.002	50	50	0.0	0.5	2871
27	0.029713386310998405	0.02970038640738445	5	0.002	50	50	0.0	0.5	2871
28	0.029715558085390743	0.02967455812923995	5	0.002	50	50	0.0	0.5	2871
29	0.02970094779840941	0.029652543116652944	5	0.002	50	50	0.0	0.5	2871
30	0.029686007203476267	0.029699108533091118	5	0.002	50	50	0.0	0.5	2871
31	0.029693710416378104	0.029683478977922957	5	0.002	50	50	0.0	0.5	2871
32	0.029675277212192815	0.02977119925757781	5	0.002	50	50	0.0	0.5	2871
33	0.029675540809824225	0.02965514122171908	5	0.002	50	50	0.0	0.5	2871
34	0.02967117328331718	0.029639533783236152	5	0.002	50	50	0.0	0.5	2871
35	0.02966023076329217	0.029656825174023727	5	0.002	50	50	0.0	0.5	2871
36	0.029655202592782533	0.029830540364775556	5	0.002	50	50	0.0	0.5	2871
37	0.02964769394744358	0.02961825109647861	5	0.002	50	50	0.0	0.5	2871
38	0.02963528727830995	0.029685870315131677	5	0.002	50	50	0.0	0.5	2871
39	0.02964255996590642	0.029614028561838954	5	0.002	50	50	0.0	0.5	2871
40	0.029627299086834563	0.02960275830505113	5	0.002	50	50	0.0	0.5	2871
41	0.02963744732514174	0.029638361559742723	5	0.002	50	50	0.0	0.5	2871
42	0.029634797350593243	0.029593350166316014	5	0.002	50	50	0.0	0.5	2871
43	0.029625250592718567	0.029714584952473186	5	0.002	50	50	0.0	0.5	2871
44	0.029625924040353552	0.02955393083963408	5	0.002	50	50	0.0	0.5	2871
45	0.029611109738223017	0.029565141160561068	5	0.002	50	50	0.0	0.5	2871
46	0.029612537751857435	0.02956701703298388	5	0.002	50	50	0.0	0.5	2871
47	0.029620136286990936	0.029588453653295228	5	0.002	50	50	0.0	0.5	2871
48	0.029596610463546995	0.029580838397772088	5	0.002	50	50	0.0	0.5	2871
49	0.029611256664574724	0.029581046394334242	5	0.002	50	50	0.0	0.5	2871
