	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	3.769077270865301	2.2787275093235433	100	0.002	100	50	0.001	0.1	9146
1	2.271121528726651	3.1029210617163896	100	0.002	100	50	0.001	0.1	9146
2	2.304964230336786	2.690799378528194	100	0.002	100	50	0.001	0.1	9146
3	2.27170764764817	2.4360923060495585	100	0.002	100	50	0.001	0.1	9146
4	2.169325257710971	2.972806916410107	100	0.002	100	50	0.001	0.1	9146
5	2.2747762343220663	2.925410210744373	100	0.002	100	50	0.001	0.1	9146
6	2.3505466209801127	2.9358768754889812	100	0.002	100	50	0.001	0.1	9146
7	2.241168497042614	2.7549783670651524	100	0.002	100	50	0.001	0.1	9146
8	2.2619330126047767	2.871946806433552	100	0.002	100	50	0.001	0.1	9146
9	2.1923227374040524	2.905405473298826	100	0.002	100	50	0.001	0.1	9146
10	2.2532126809438	3.2620013842847104	100	0.002	100	50	0.001	0.1	9146
11	2.213048704619946	3.5392029682035426	100	0.002	100	50	0.001	0.1	9146
12	2.1973869960043135	2.7404506623631	100	0.002	100	50	0.001	0.1	9146
13	2.3853641922436166	3.4670493782820255	100	0.002	100	50	0.001	0.1	9146
14	2.4793479312375517	3.3055997355262363	100	0.002	100	50	0.001	0.1	9146
15	2.353309556795942	3.1117327646361255	100	0.002	100	50	0.001	0.1	9146
16	2.3063930220752367	3.3512715664238137	100	0.002	100	50	0.001	0.1	9146
17	2.360081081839711	3.4946939940662274	100	0.002	100	50	0.001	0.1	9146
18	2.40148602994522	3.276241928395988	100	0.002	100	50	0.001	0.1	9146
19	2.399084519924576	3.114972066468992	100	0.002	100	50	0.001	0.1	9146
20	2.333080107988694	3.114411300272604	100	0.002	100	50	0.001	0.1	9146
21	2.448326386567524	3.1962393061836636	100	0.002	100	50	0.001	0.1	9146
22	2.3111465966759766	3.3574673039963323	100	0.002	100	50	0.001	0.1	9146
23	2.502549613084421	3.3665114363110544	100	0.002	100	50	0.001	0.1	9146
24	2.4390215563030715	3.349448591299768	100	0.002	100	50	0.001	0.1	9146
25	2.33366913715306	3.6173083741167993	100	0.002	100	50	0.001	0.1	9146
26	2.5518263185250953	3.687721980461427	100	0.002	100	50	0.001	0.1	9146
27	2.6294395057881257	4.197894895509825	100	0.002	100	50	0.001	0.1	9146
28	2.6306427647998327	3.6307302132163404	100	0.002	100	50	0.001	0.1	9146
29	2.5892145790323546	4.152554659952853	100	0.002	100	50	0.001	0.1	9146
30	2.662883618686451	3.3174339815489877	100	0.002	100	50	0.001	0.1	9146
31	2.62464089830155	3.342102357351985	100	0.002	100	50	0.001	0.1	9146
32	2.561408419262954	3.325029344905175	100	0.002	100	50	0.001	0.1	9146
33	2.4939763958751997	3.755591662618444	100	0.002	100	50	0.001	0.1	9146
34	2.670622622974365	3.40325049392124	100	0.002	100	50	0.001	0.1	9146
35	2.6213751995517915	4.148276694874006	100	0.002	100	50	0.001	0.1	9146
36	2.624034760381544	3.705557632628636	100	0.002	100	50	0.001	0.1	9146
37	2.6152785913313306	3.3179839354856067	100	0.002	100	50	0.001	0.1	9146
38	2.537059833567036	3.884583253705479	100	0.002	100	50	0.001	0.1	9146
39	2.6597670533477746	3.2764497450615204	100	0.002	100	50	0.001	0.1	9146
40	2.3254104057420113	3.168319356145184	100	0.002	100	50	0.001	0.1	9146
41	2.4712856290578005	3.166592556249571	100	0.002	100	50	0.001	0.1	9146
42	2.5005256735998653	3.29818397589441	100	0.002	100	50	0.001	0.1	9146
43	2.6493849508772236	3.9203335023974826	100	0.002	100	50	0.001	0.1	9146
44	2.5050656905301407	4.121204790376113	100	0.002	100	50	0.001	0.1	9146
45	3.009081566076052	4.3226632866759145	100	0.002	100	50	0.001	0.1	9146
46	2.7729537056189697	3.2466287077271003	100	0.002	100	50	0.001	0.1	9146
47	2.543281093656124	3.8610835882263475	100	0.002	100	50	0.001	0.1	9146
48	2.6631024500477216	3.6826657649435917	100	0.002	100	50	0.001	0.1	9146
49	2.705728428448398	3.420763237070627	100	0.002	100	50	0.001	0.1	9146
