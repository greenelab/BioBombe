	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.6622418398277977	0.2833427741240361	25	0.0005	50	50	0.001	0.5	9895
1	0.5295592514485592	0.27669055796945985	25	0.0005	50	50	0.001	0.5	9895
2	0.42453736351290633	0.21869293328225042	25	0.0005	50	50	0.001	0.5	9895
3	0.32822660294388223	0.19258100549417972	25	0.0005	50	50	0.001	0.5	9895
4	0.2551740137425832	0.15740650493373834	25	0.0005	50	50	0.001	0.5	9895
5	0.19594914705340089	0.19870815550050133	25	0.0005	50	50	0.001	0.5	9895
6	0.16254060952972177	0.17897261753250945	25	0.0005	50	50	0.001	0.5	9895
7	0.1390406148788983	0.16721909842231306	25	0.0005	50	50	0.001	0.5	9895
8	0.12873053105964957	0.14544429457666314	25	0.0005	50	50	0.001	0.5	9895
9	0.12478392878558195	0.13043560010753216	25	0.0005	50	50	0.001	0.5	9895
10	0.11635354737568443	0.13938196741372175	25	0.0005	50	50	0.001	0.5	9895
11	0.11399970507740177	0.11816795194525108	25	0.0005	50	50	0.001	0.5	9895
12	0.11206478517018531	0.13059266874598727	25	0.0005	50	50	0.001	0.5	9895
13	0.11021073202606622	0.11509938092179325	25	0.0005	50	50	0.001	0.5	9895
14	0.10837960613696175	0.10867548798055995	25	0.0005	50	50	0.001	0.5	9895
15	0.10622944289767551	0.11826765901955774	25	0.0005	50	50	0.001	0.5	9895
16	0.10626198523855483	0.1169160357168938	25	0.0005	50	50	0.001	0.5	9895
17	0.10680120139221805	0.12087616495374967	25	0.0005	50	50	0.001	0.5	9895
18	0.10388848553319154	0.10414621827992153	25	0.0005	50	50	0.001	0.5	9895
19	0.10281294270673949	0.1330540480223942	25	0.0005	50	50	0.001	0.5	9895
20	0.10493711361056635	0.11915779169328354	25	0.0005	50	50	0.001	0.5	9895
21	0.10293251673280275	0.1049462554559653	25	0.0005	50	50	0.001	0.5	9895
22	0.10054776509421343	0.11064804426570696	25	0.0005	50	50	0.001	0.5	9895
23	0.1036242560109423	0.11961503547703559	25	0.0005	50	50	0.001	0.5	9895
24	0.10107039752467069	0.1144540944701171	25	0.0005	50	50	0.001	0.5	9895
25	0.10171333073376089	0.12114958544876106	25	0.0005	50	50	0.001	0.5	9895
26	0.10211469675812498	0.1009525398850213	25	0.0005	50	50	0.001	0.5	9895
27	0.0999103593820595	0.11920320976304734	25	0.0005	50	50	0.001	0.5	9895
28	0.10033981356218506	0.120858070741534	25	0.0005	50	50	0.001	0.5	9895
29	0.10100713570585518	0.11237606337831764	25	0.0005	50	50	0.001	0.5	9895
30	0.1021444619882883	0.11910633644512916	25	0.0005	50	50	0.001	0.5	9895
31	0.10295070904213767	0.10042571505784532	25	0.0005	50	50	0.001	0.5	9895
32	0.1016817922424614	0.12384867585525913	25	0.0005	50	50	0.001	0.5	9895
33	0.10077923967837528	0.11348794308093949	25	0.0005	50	50	0.001	0.5	9895
34	0.09989475805467138	0.11406212389811048	25	0.0005	50	50	0.001	0.5	9895
35	0.10072142426761573	0.11941421221421736	25	0.0005	50	50	0.001	0.5	9895
36	0.10110489593581921	0.14746344989845903	25	0.0005	50	50	0.001	0.5	9895
37	0.10277707816360734	0.10562979662167639	25	0.0005	50	50	0.001	0.5	9895
38	0.10066303990929322	0.12102902550998199	25	0.0005	50	50	0.001	0.5	9895
39	0.09986265703345554	0.11052912611863354	25	0.0005	50	50	0.001	0.5	9895
40	0.10100770734775323	0.10822857954818933	25	0.0005	50	50	0.001	0.5	9895
41	0.10302104386182923	0.11841662038637621	25	0.0005	50	50	0.001	0.5	9895
42	0.10013173479683009	0.11567590666318715	25	0.0005	50	50	0.001	0.5	9895
43	0.10286058694231869	0.1105064729631061	25	0.0005	50	50	0.001	0.5	9895
44	0.10067202919744082	0.11860991581334211	25	0.0005	50	50	0.001	0.5	9895
45	0.10060976705728891	0.10571202810989055	25	0.0005	50	50	0.001	0.5	9895
46	0.09987283454040254	0.1128676984437793	25	0.0005	50	50	0.001	0.5	9895
47	0.09751346134679117	0.10477416391126512	25	0.0005	50	50	0.001	0.5	9895
48	0.10073333101806764	0.12585988398605732	25	0.0005	50	50	0.001	0.5	9895
49	0.10184574166456672	0.12016756748549114	25	0.0005	50	50	0.001	0.5	9895
