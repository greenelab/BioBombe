	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.03145769548827095	0.021686639821951067	50	0.0005	50	50	0.0	0.1	6316
1	0.01899065673141535	0.01690992703002452	50	0.0005	50	50	0.0	0.1	6316
2	0.01593608955889196	0.014858236231878543	50	0.0005	50	50	0.0	0.1	6316
3	0.014421291682585435	0.013671230348485948	50	0.0005	50	50	0.0	0.1	6316
4	0.013600095509821868	0.013080687101852027	50	0.0005	50	50	0.0	0.1	6316
5	0.013057388157890388	0.012620023409007954	50	0.0005	50	50	0.0	0.1	6316
6	0.012645986284374	0.012267308302551337	50	0.0005	50	50	0.0	0.1	6316
7	0.012340170518592796	0.011998591086262727	50	0.0005	50	50	0.0	0.1	6316
8	0.01212942077035537	0.011824239795069507	50	0.0005	50	50	0.0	0.1	6316
9	0.011996703077051075	0.01172329158474109	50	0.0005	50	50	0.0	0.1	6316
10	0.011910476910699748	0.011643479264788259	50	0.0005	50	50	0.0	0.1	6316
11	0.011863894198728199	0.011614965403142668	50	0.0005	50	50	0.0	0.1	6316
12	0.011824464750363686	0.011568156909731788	50	0.0005	50	50	0.0	0.1	6316
13	0.011796795876163814	0.011553519893345026	50	0.0005	50	50	0.0	0.1	6316
14	0.011779100648899723	0.011535811047452585	50	0.0005	50	50	0.0	0.1	6316
15	0.011766490294581915	0.011503048761112057	50	0.0005	50	50	0.0	0.1	6316
16	0.011754677374904123	0.011491369874524683	50	0.0005	50	50	0.0	0.1	6316
17	0.011738747064964932	0.011560135403466384	50	0.0005	50	50	0.0	0.1	6316
18	0.011729967260778166	0.011472413072408842	50	0.0005	50	50	0.0	0.1	6316
19	0.011723781267134933	0.011492759724776216	50	0.0005	50	50	0.0	0.1	6316
20	0.01171311421992041	0.01147445848471633	50	0.0005	50	50	0.0	0.1	6316
21	0.011705069210347467	0.01145801487882723	50	0.0005	50	50	0.0	0.1	6316
22	0.01170380920164614	0.011450785908484779	50	0.0005	50	50	0.0	0.1	6316
23	0.011694352775036458	0.011472922507637887	50	0.0005	50	50	0.0	0.1	6316
24	0.01169061740353968	0.011475599630883616	50	0.0005	50	50	0.0	0.1	6316
25	0.011689304612208113	0.011434413344878882	50	0.0005	50	50	0.0	0.1	6316
26	0.011672198239737258	0.011437179677430576	50	0.0005	50	50	0.0	0.1	6316
27	0.011673782784525417	0.011423850198762481	50	0.0005	50	50	0.0	0.1	6316
28	0.011675215596850603	0.011441526660271858	50	0.0005	50	50	0.0	0.1	6316
29	0.011669199608411202	0.011415360783926616	50	0.0005	50	50	0.0	0.1	6316
30	0.011662953155973849	0.01140923343463507	50	0.0005	50	50	0.0	0.1	6316
31	0.011664598784659287	0.011402032923943454	50	0.0005	50	50	0.0	0.1	6316
32	0.011659046025066368	0.011398763898012173	50	0.0005	50	50	0.0	0.1	6316
33	0.011656486684143619	0.011448216416212386	50	0.0005	50	50	0.0	0.1	6316
34	0.011656601517018484	0.011437993745958828	50	0.0005	50	50	0.0	0.1	6316
35	0.011651226592842918	0.01140965092001237	50	0.0005	50	50	0.0	0.1	6316
36	0.011648271185846881	0.011400724077387134	50	0.0005	50	50	0.0	0.1	6316
37	0.011641227402260791	0.011415359441255064	50	0.0005	50	50	0.0	0.1	6316
38	0.011642614282168187	0.011389644499547623	50	0.0005	50	50	0.0	0.1	6316
39	0.011642757641632594	0.011393602315984653	50	0.0005	50	50	0.0	0.1	6316
40	0.011639012838083083	0.011400339558692097	50	0.0005	50	50	0.0	0.1	6316
41	0.011639608702085406	0.011386796613054681	50	0.0005	50	50	0.0	0.1	6316
42	0.011633529656290735	0.0113846223844112	50	0.0005	50	50	0.0	0.1	6316
43	0.011634443213093247	0.01138944992792025	50	0.0005	50	50	0.0	0.1	6316
44	0.011635415371486432	0.01138608159771613	50	0.0005	50	50	0.0	0.1	6316
45	0.01162628166432555	0.011396659673485427	50	0.0005	50	50	0.0	0.1	6316
46	0.011628556985601595	0.011368803297085813	50	0.0005	50	50	0.0	0.1	6316
47	0.011625130329085982	0.011387810891006234	50	0.0005	50	50	0.0	0.1	6316
48	0.011625298313637424	0.01139128807020404	50	0.0005	50	50	0.0	0.1	6316
49	0.011623177189321755	0.011372027051480164	50	0.0005	50	50	0.0	0.1	6316
