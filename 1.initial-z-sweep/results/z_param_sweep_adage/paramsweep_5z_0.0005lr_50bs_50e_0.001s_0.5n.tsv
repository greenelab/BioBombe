	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.19231365427009156	0.12398086444084777	5	0.0005	50	50	0.001	0.5	111
1	0.1575528619808762	0.10545036530061616	5	0.0005	50	50	0.001	0.5	111
2	0.1315671811753944	0.08444723414246484	5	0.0005	50	50	0.001	0.5	111
3	0.11084553772383943	0.08104060420741542	5	0.0005	50	50	0.001	0.5	111
4	0.0934350420338472	0.08327403046318951	5	0.0005	50	50	0.001	0.5	111
5	0.08010766540831997	0.07220313462996802	5	0.0005	50	50	0.001	0.5	111
6	0.0699941168207678	0.06742426687513209	5	0.0005	50	50	0.001	0.5	111
7	0.06562437624860035	0.07212650510936576	5	0.0005	50	50	0.001	0.5	111
8	0.06276051170192362	0.07115223131945667	5	0.0005	50	50	0.001	0.5	111
9	0.05942462972483751	0.06239685844309471	5	0.0005	50	50	0.001	0.5	111
10	0.05732868942232741	0.06507404953469281	5	0.0005	50	50	0.001	0.5	111
11	0.05538707087484275	0.0673494208639712	5	0.0005	50	50	0.001	0.5	111
12	0.05503257628481585	0.06583070972966419	5	0.0005	50	50	0.001	0.5	111
13	0.054092011564164565	0.0562326594631599	5	0.0005	50	50	0.001	0.5	111
14	0.051318944590442256	0.05653041304155016	5	0.0005	50	50	0.001	0.5	111
15	0.051275103320610534	0.05267339134962791	5	0.0005	50	50	0.001	0.5	111
16	0.051869157306366334	0.049014983930220794	5	0.0005	50	50	0.001	0.5	111
17	0.050754298744423415	0.05033537166381885	5	0.0005	50	50	0.001	0.5	111
18	0.04963289105327352	0.048564524947172366	5	0.0005	50	50	0.001	0.5	111
19	0.050499400972661465	0.04902574020379132	5	0.0005	50	50	0.001	0.5	111
20	0.050083214112166756	0.05222813445312571	5	0.0005	50	50	0.001	0.5	111
21	0.04956639753424069	0.04776996830709806	5	0.0005	50	50	0.001	0.5	111
22	0.04906215175588947	0.052357130308224184	5	0.0005	50	50	0.001	0.5	111
23	0.04928673172529289	0.050472608359662344	5	0.0005	50	50	0.001	0.5	111
24	0.048939171238576495	0.052395202226609164	5	0.0005	50	50	0.001	0.5	111
25	0.04970367407331454	0.05880837441630391	5	0.0005	50	50	0.001	0.5	111
26	0.049187958749456584	0.05446338323772979	5	0.0005	50	50	0.001	0.5	111
27	0.04892574200911463	0.04882017967520891	5	0.0005	50	50	0.001	0.5	111
28	0.04873250681195757	0.04680666652281927	5	0.0005	50	50	0.001	0.5	111
29	0.04776344858454262	0.044939514484619775	5	0.0005	50	50	0.001	0.5	111
30	0.04803416072692246	0.04728026222259547	5	0.0005	50	50	0.001	0.5	111
31	0.04801750449175018	0.04924378052610284	5	0.0005	50	50	0.001	0.5	111
32	0.04791761989767893	0.04540360979664622	5	0.0005	50	50	0.001	0.5	111
33	0.04752157265267982	0.04911178032053816	5	0.0005	50	50	0.001	0.5	111
34	0.04825304516794058	0.045586957516109514	5	0.0005	50	50	0.001	0.5	111
35	0.04796406157131936	0.04608748253456265	5	0.0005	50	50	0.001	0.5	111
36	0.04734934537789146	0.056328706037303	5	0.0005	50	50	0.001	0.5	111
37	0.04822474975496274	0.04773612751360149	5	0.0005	50	50	0.001	0.5	111
38	0.04792739762790548	0.05477946880585149	5	0.0005	50	50	0.001	0.5	111
39	0.04791845990255638	0.04600043332001219	5	0.0005	50	50	0.001	0.5	111
40	0.04828480901931723	0.051976277861551845	5	0.0005	50	50	0.001	0.5	111
41	0.04726404812344073	0.04853838147955233	5	0.0005	50	50	0.001	0.5	111
42	0.04794791049548471	0.05460932619342612	5	0.0005	50	50	0.001	0.5	111
43	0.04751672827892269	0.04949214110012036	5	0.0005	50	50	0.001	0.5	111
44	0.04842026926427494	0.05058173280401622	5	0.0005	50	50	0.001	0.5	111
45	0.04934744981908968	0.045131030383859946	5	0.0005	50	50	0.001	0.5	111
46	0.047964436150782545	0.05010084535776999	5	0.0005	50	50	0.001	0.5	111
47	0.04808323219193734	0.045512171942975736	5	0.0005	50	50	0.001	0.5	111
48	0.04806441288256599	0.05204242378843674	5	0.0005	50	50	0.001	0.5	111
49	0.04763345518548658	0.048327318319684	5	0.0005	50	50	0.001	0.5	111
