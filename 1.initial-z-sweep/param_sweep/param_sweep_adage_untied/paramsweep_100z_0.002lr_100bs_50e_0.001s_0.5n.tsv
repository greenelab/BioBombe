	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	5.676131615410268	3.0720880193418574	100	0.002	100	50	0.001	0.5	8520
1	3.8799514020431514	2.8348138045170566	100	0.002	100	50	0.001	0.5	8520
2	3.0265688331381972	2.8220371867229104	100	0.002	100	50	0.001	0.5	8520
3	2.6113788240060765	3.5617099988984786	100	0.002	100	50	0.001	0.5	8520
4	2.6206293542491736	3.1779036996013574	100	0.002	100	50	0.001	0.5	8520
5	2.408210910536158	3.0476226111443045	100	0.002	100	50	0.001	0.5	8520
6	2.422210189670682	3.044733751344407	100	0.002	100	50	0.001	0.5	8520
7	2.3480203354205433	3.071154083622117	100	0.002	100	50	0.001	0.5	8520
8	2.1947535914979883	3.0678216250859074	100	0.002	100	50	0.001	0.5	8520
9	2.3261896109183335	3.3532207928469715	100	0.002	100	50	0.001	0.5	8520
10	2.1602213341308607	3.0666497888802113	100	0.002	100	50	0.001	0.5	8520
11	2.267735893052227	2.726511933835469	100	0.002	100	50	0.001	0.5	8520
12	2.1492769059530294	2.7891935265087033	100	0.002	100	50	0.001	0.5	8520
13	2.0558849590992074	2.6260587321184787	100	0.002	100	50	0.001	0.5	8520
14	2.194329936816793	3.0414116056653784	100	0.002	100	50	0.001	0.5	8520
15	1.9891201399609448	3.0573661764994635	100	0.002	100	50	0.001	0.5	8520
16	2.040656756556251	2.821118128231333	100	0.002	100	50	0.001	0.5	8520
17	2.0297815174222134	2.9943216916024116	100	0.002	100	50	0.001	0.5	8520
18	2.0821285775271865	2.5980029288487043	100	0.002	100	50	0.001	0.5	8520
19	1.993459723213078	2.7075374078568264	100	0.002	100	50	0.001	0.5	8520
20	2.1008223825435413	2.4892564861541953	100	0.002	100	50	0.001	0.5	8520
21	2.1037879439788534	2.8827636672707406	100	0.002	100	50	0.001	0.5	8520
22	2.070352928805374	3.1415026609573946	100	0.002	100	50	0.001	0.5	8520
23	2.160515835937906	2.84725864758683	100	0.002	100	50	0.001	0.5	8520
24	1.9685526897496173	2.6900559497381034	100	0.002	100	50	0.001	0.5	8520
25	1.9232476839353843	2.7609141141917006	100	0.002	100	50	0.001	0.5	8520
26	2.0432802849582488	2.949494348429357	100	0.002	100	50	0.001	0.5	8520
27	2.0510587608106303	2.9721836916119373	100	0.002	100	50	0.001	0.5	8520
28	2.154883416368568	2.7586648181565177	100	0.002	100	50	0.001	0.5	8520
29	1.9579093699296704	2.816667330196665	100	0.002	100	50	0.001	0.5	8520
30	2.246852624280843	2.6963132670003187	100	0.002	100	50	0.001	0.5	8520
31	1.9538673610080888	2.665155948234106	100	0.002	100	50	0.001	0.5	8520
32	2.1944455534020277	2.666100083300078	100	0.002	100	50	0.001	0.5	8520
33	2.0105802750284787	2.8715259582089194	100	0.002	100	50	0.001	0.5	8520
34	2.013256141109952	2.4102529854893002	100	0.002	100	50	0.001	0.5	8520
35	1.946239231272457	2.9057850776165437	100	0.002	100	50	0.001	0.5	8520
36	2.179573778026253	2.783868023815848	100	0.002	100	50	0.001	0.5	8520
37	2.0250228009314615	2.9771873360610144	100	0.002	100	50	0.001	0.5	8520
38	2.0636145753373785	2.7064181073901756	100	0.002	100	50	0.001	0.5	8520
39	1.9577913774664415	2.5449138344131965	100	0.002	100	50	0.001	0.5	8520
40	2.1088769425687786	2.4143938744729154	100	0.002	100	50	0.001	0.5	8520
41	1.9930228128337486	2.708532035236833	100	0.002	100	50	0.001	0.5	8520
42	2.1501133552073015	2.6818026910548456	100	0.002	100	50	0.001	0.5	8520
43	2.043451380567572	2.8813701592257557	100	0.002	100	50	0.001	0.5	8520
44	1.9258730341780772	2.878035339069184	100	0.002	100	50	0.001	0.5	8520
45	2.1218795989032864	2.636240260095031	100	0.002	100	50	0.001	0.5	8520
46	1.8923255479843624	2.9352618601764364	100	0.002	100	50	0.001	0.5	8520
47	2.23483434197602	2.571833674356085	100	0.002	100	50	0.001	0.5	8520
48	1.9722234904766083	2.806389790192161	100	0.002	100	50	0.001	0.5	8520
49	1.9865542599787105	2.569160805833499	100	0.002	100	50	0.001	0.5	8520
