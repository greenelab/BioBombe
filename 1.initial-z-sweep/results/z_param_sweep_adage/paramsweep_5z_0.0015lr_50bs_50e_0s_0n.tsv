	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.03437787370789314	0.026692355183410826	5	0.0015	50	50	0.0	0.0	8273
1	0.025887765896818366	0.025202538793190715	5	0.0015	50	50	0.0	0.0	8273
2	0.025300396294862866	0.024891353075180637	5	0.0015	50	50	0.0	0.0	8273
3	0.0250086435630821	0.02454064496174939	5	0.0015	50	50	0.0	0.0	8273
4	0.02473301316169108	0.024333947681845033	5	0.0015	50	50	0.0	0.0	8273
5	0.024477978576634436	0.024087499239505136	5	0.0015	50	50	0.0	0.0	8273
6	0.02428240369058315	0.02384062103898644	5	0.0015	50	50	0.0	0.0	8273
7	0.024102725677091687	0.023683741499970795	5	0.0015	50	50	0.0	0.0	8273
8	0.023979894214924267	0.023580163571249913	5	0.0015	50	50	0.0	0.0	8273
9	0.023873704401990894	0.02349627640518586	5	0.0015	50	50	0.0	0.0	8273
10	0.02379641514166621	0.023443318354980897	5	0.0015	50	50	0.0	0.0	8273
11	0.023734295992624947	0.023307939271939415	5	0.0015	50	50	0.0	0.0	8273
12	0.023674567227176535	0.023370979670755722	5	0.0015	50	50	0.0	0.0	8273
13	0.023639557779256387	0.023229278859114327	5	0.0015	50	50	0.0	0.0	8273
14	0.02359318488971955	0.023211368713990908	5	0.0015	50	50	0.0	0.0	8273
15	0.023570113085486562	0.023216509333247207	5	0.0015	50	50	0.0	0.0	8273
16	0.02353006312092312	0.023171402432067216	5	0.0015	50	50	0.0	0.0	8273
17	0.023521650819414406	0.02316502343870372	5	0.0015	50	50	0.0	0.0	8273
18	0.023500055233589473	0.02311996698920859	5	0.0015	50	50	0.0	0.0	8273
19	0.02346916054254268	0.02308841771223577	5	0.0015	50	50	0.0	0.0	8273
20	0.023453872321193534	0.023135811069100582	5	0.0015	50	50	0.0	0.0	8273
21	0.023441797614684904	0.023121044039726257	5	0.0015	50	50	0.0	0.0	8273
22	0.02342961800957377	0.023037217838785845	5	0.0015	50	50	0.0	0.0	8273
23	0.02342300806430021	0.023045660753380045	5	0.0015	50	50	0.0	0.0	8273
24	0.02340268226542053	0.023110412545573417	5	0.0015	50	50	0.0	0.0	8273
25	0.02339753713690296	0.02306363294987332	5	0.0015	50	50	0.0	0.0	8273
26	0.023395022999308866	0.023111039227725897	5	0.0015	50	50	0.0	0.0	8273
27	0.023383145267178475	0.023024659657256096	5	0.0015	50	50	0.0	0.0	8273
28	0.023372606492556715	0.02304892538268525	5	0.0015	50	50	0.0	0.0	8273
29	0.02336743007445011	0.02307037352076794	5	0.0015	50	50	0.0	0.0	8273
30	0.023365261606435955	0.023011188459071557	5	0.0015	50	50	0.0	0.0	8273
31	0.02336483038815456	0.023000693835503284	5	0.0015	50	50	0.0	0.0	8273
32	0.023359881559244178	0.02303565715583857	5	0.0015	50	50	0.0	0.0	8273
33	0.023346065305245425	0.023017455522775877	5	0.0015	50	50	0.0	0.0	8273
34	0.023337903980774795	0.02297545866559956	5	0.0015	50	50	0.0	0.0	8273
35	0.02333870905546558	0.023014233716501787	5	0.0015	50	50	0.0	0.0	8273
36	0.023335873332473393	0.022985701308537623	5	0.0015	50	50	0.0	0.0	8273
37	0.02332642596184536	0.022974317010143065	5	0.0015	50	50	0.0	0.0	8273
38	0.02333818371809879	0.023004401770792545	5	0.0015	50	50	0.0	0.0	8273
39	0.023330525291988046	0.023047499226879892	5	0.0015	50	50	0.0	0.0	8273
40	0.023325870799795735	0.02295955690425281	5	0.0015	50	50	0.0	0.0	8273
41	0.023326788129082943	0.02302464462075931	5	0.0015	50	50	0.0	0.0	8273
42	0.023314315576371866	0.023050977355207586	5	0.0015	50	50	0.0	0.0	8273
43	0.02332035332132979	0.02299650701877606	5	0.0015	50	50	0.0	0.0	8273
44	0.02331426374524797	0.02300200194305603	5	0.0015	50	50	0.0	0.0	8273
45	0.023303921708339878	0.022963988696212523	5	0.0015	50	50	0.0	0.0	8273
46	0.02330803739346867	0.022999325443066328	5	0.0015	50	50	0.0	0.0	8273
47	0.023303502272431813	0.022996414680724844	5	0.0015	50	50	0.0	0.0	8273
48	0.0233110867010905	0.022985957865647787	5	0.0015	50	50	0.0	0.0	8273
49	0.02331757788448136	0.02296633378426272	5	0.0015	50	50	0.0	0.0	8273
