	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.07235678625041274	0.06584475300565049	5	0.002	100	50	0.0	0.1	3913
1	0.06098489414848697	0.0565309428162944	5	0.002	100	50	0.0	0.1	3913
2	0.05318121509174352	0.050157122135903134	5	0.002	100	50	0.0	0.1	3913
3	0.04782630884650852	0.04577445357781523	5	0.002	100	50	0.0	0.1	3913
4	0.04413701121971481	0.0427478658423597	5	0.002	100	50	0.0	0.1	3913
5	0.04157650233712888	0.04063524968252583	5	0.002	100	50	0.0	0.1	3913
6	0.03978301169647366	0.039151603039033554	5	0.002	100	50	0.0	0.1	3913
7	0.03851067483572363	0.03809240086442198	5	0.002	100	50	0.0	0.1	3913
8	0.03759925410865433	0.03733029237896717	5	0.002	100	50	0.0	0.1	3913
9	0.03693980775701497	0.036774651619319025	5	0.002	100	50	0.0	0.1	3913
10	0.03645518655229499	0.036366686110970624	5	0.002	100	50	0.0	0.1	3913
11	0.036098514079911465	0.036063820266131	5	0.002	100	50	0.0	0.1	3913
12	0.035830729732737716	0.03583539156225398	5	0.002	100	50	0.0	0.1	3913
13	0.03562847690981898	0.03566030694267946	5	0.002	100	50	0.0	0.1	3913
14	0.03547501020924224	0.035528494298002235	5	0.002	100	50	0.0	0.1	3913
15	0.03535604948892478	0.035425953659626086	5	0.002	100	50	0.0	0.1	3913
16	0.03526457515186532	0.03534770602392421	5	0.002	100	50	0.0	0.1	3913
17	0.03519344981492648	0.03528489616929231	5	0.002	100	50	0.0	0.1	3913
18	0.03513730038857784	0.035238228275317765	5	0.002	100	50	0.0	0.1	3913
19	0.03509375754801991	0.0352002039736931	5	0.002	100	50	0.0	0.1	3913
20	0.03505908325551978	0.035169632275576346	5	0.002	100	50	0.0	0.1	3913
21	0.035031376722169126	0.03514764148806067	5	0.002	100	50	0.0	0.1	3913
22	0.0350096616425031	0.03512644695819678	5	0.002	100	50	0.0	0.1	3913
23	0.034991769130980566	0.035111700870224895	5	0.002	100	50	0.0	0.1	3913
24	0.034977777850076365	0.03509918021939225	5	0.002	100	50	0.0	0.1	3913
25	0.03496671122679178	0.03508922590893723	5	0.002	100	50	0.0	0.1	3913
26	0.03495744895041591	0.03508228199631261	5	0.002	100	50	0.0	0.1	3913
27	0.034950437915685466	0.03507512000106261	5	0.002	100	50	0.0	0.1	3913
28	0.03494409043636716	0.035069408276283943	5	0.002	100	50	0.0	0.1	3913
29	0.03494056652723622	0.035064490593927085	5	0.002	100	50	0.0	0.1	3913
30	0.03493622750199007	0.03506258051009069	5	0.002	100	50	0.0	0.1	3913
31	0.034932472720436696	0.0350599153960982	5	0.002	100	50	0.0	0.1	3913
32	0.03492960524659702	0.035056636905578996	5	0.002	100	50	0.0	0.1	3913
33	0.03492822836279951	0.035055644560897326	5	0.002	100	50	0.0	0.1	3913
34	0.03492601872088868	0.03505407111366666	5	0.002	100	50	0.0	0.1	3913
35	0.03492490927379392	0.035051839586425694	5	0.002	100	50	0.0	0.1	3913
36	0.03492374270663661	0.03505135594687316	5	0.002	100	50	0.0	0.1	3913
37	0.034922683591526296	0.035050354762640325	5	0.002	100	50	0.0	0.1	3913
38	0.03492173507198585	0.035049357780933835	5	0.002	100	50	0.0	0.1	3913
39	0.03492145346964215	0.03504898808682854	5	0.002	100	50	0.0	0.1	3913
40	0.034920766972607716	0.035047302831028436	5	0.002	100	50	0.0	0.1	3913
41	0.03492063350368418	0.035046701086239876	5	0.002	100	50	0.0	0.1	3913
42	0.034920127600713224	0.03504830779041205	5	0.002	100	50	0.0	0.1	3913
43	0.0349214181599215	0.035048221439180134	5	0.002	100	50	0.0	0.1	3913
44	0.03491909804888617	0.03504879592453088	5	0.002	100	50	0.0	0.1	3913
45	0.034919594575903386	0.03504764039361454	5	0.002	100	50	0.0	0.1	3913
46	0.034919475058316676	0.035049036216439525	5	0.002	100	50	0.0	0.1	3913
47	0.03491854242498444	0.03504696267569726	5	0.002	100	50	0.0	0.1	3913
48	0.034919349761840246	0.03504794747007736	5	0.002	100	50	0.0	0.1	3913
49	0.0349192168481682	0.03504713984423568	5	0.002	100	50	0.0	0.1	3913
