	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.031907378474576344	0.020033531517759107	100	0.001	100	50	0.0	0.5	2683
1	0.017800422949688942	0.01564658099845992	100	0.001	100	50	0.0	0.5	2683
2	0.015203833024567718	0.01397891143197995	100	0.001	100	50	0.0	0.5	2683
3	0.013965541205395551	0.013142241629812845	100	0.001	100	50	0.0	0.5	2683
4	0.013230105833526715	0.01237665347391686	100	0.001	100	50	0.0	0.5	2683
5	0.01271185672822277	0.012023420153224901	100	0.001	100	50	0.0	0.5	2683
6	0.012315468852066195	0.011587435034162456	100	0.001	100	50	0.0	0.5	2683
7	0.012015650656244858	0.011351190706853885	100	0.001	100	50	0.0	0.5	2683
8	0.011797311029731467	0.011141876661597999	100	0.001	100	50	0.0	0.5	2683
9	0.011609178028734016	0.010984535651356266	100	0.001	100	50	0.0	0.5	2683
10	0.01146982183269733	0.010969513760128167	100	0.001	100	50	0.0	0.5	2683
11	0.011370723917593546	0.010712195048910026	100	0.001	100	50	0.0	0.5	2683
12	0.011267239687368502	0.010677709115978979	100	0.001	100	50	0.0	0.5	2683
13	0.011196015747480706	0.010539582344644612	100	0.001	100	50	0.0	0.5	2683
14	0.011142490449970281	0.01056814945016206	100	0.001	100	50	0.0	0.5	2683
15	0.011121762138381276	0.010481899792958856	100	0.001	100	50	0.0	0.5	2683
16	0.011064296313644114	0.01049536675834462	100	0.001	100	50	0.0	0.5	2683
17	0.011043741873044093	0.010434575564090881	100	0.001	100	50	0.0	0.5	2683
18	0.01100995944464427	0.010420316246197511	100	0.001	100	50	0.0	0.5	2683
19	0.011005623491189468	0.010369110756320434	100	0.001	100	50	0.0	0.5	2683
20	0.010981680263472194	0.010358525158741277	100	0.001	100	50	0.0	0.5	2683
21	0.010977469394861081	0.010302088759397914	100	0.001	100	50	0.0	0.5	2683
22	0.010946736646097632	0.010290577952495383	100	0.001	100	50	0.0	0.5	2683
23	0.01095277733847928	0.010328627455032236	100	0.001	100	50	0.0	0.5	2683
24	0.010933374129825427	0.010307182386930654	100	0.001	100	50	0.0	0.5	2683
25	0.01094588680123768	0.010328742080718906	100	0.001	100	50	0.0	0.5	2683
26	0.010922799193114596	0.010347611676851718	100	0.001	100	50	0.0	0.5	2683
27	0.010917054791417826	0.010303506967798588	100	0.001	100	50	0.0	0.5	2683
28	0.010908170167780588	0.010284196866772372	100	0.001	100	50	0.0	0.5	2683
29	0.010907655098213028	0.010311236268489926	100	0.001	100	50	0.0	0.5	2683
30	0.010901500565918735	0.010242973826469472	100	0.001	100	50	0.0	0.5	2683
31	0.010901400743632746	0.010277223285380216	100	0.001	100	50	0.0	0.5	2683
32	0.010885504922508706	0.010278327410139614	100	0.001	100	50	0.0	0.5	2683
33	0.01088307756215451	0.010239302789717629	100	0.001	100	50	0.0	0.5	2683
34	0.010879175207478409	0.010237133726976228	100	0.001	100	50	0.0	0.5	2683
35	0.010887097698811181	0.010358038995892209	100	0.001	100	50	0.0	0.5	2683
36	0.010877423770931522	0.010270196255332084	100	0.001	100	50	0.0	0.5	2683
37	0.010889633293234427	0.010252944651428418	100	0.001	100	50	0.0	0.5	2683
38	0.010882559993361598	0.010275780901768696	100	0.001	100	50	0.0	0.5	2683
39	0.010868815906226325	0.010311454173042144	100	0.001	100	50	0.0	0.5	2683
40	0.01086644018010535	0.010365906009454116	100	0.001	100	50	0.0	0.5	2683
41	0.010857511031472358	0.01025224608114527	100	0.001	100	50	0.0	0.5	2683
42	0.010847408040818969	0.010279138330334572	100	0.001	100	50	0.0	0.5	2683
43	0.010859620787775581	0.010280120959345173	100	0.001	100	50	0.0	0.5	2683
44	0.010864902212922965	0.01030706481235262	100	0.001	100	50	0.0	0.5	2683
45	0.010849798954433606	0.010199130117451598	100	0.001	100	50	0.0	0.5	2683
46	0.01084272355713092	0.010240539059000194	100	0.001	100	50	0.0	0.5	2683
47	0.010841532845537277	0.010297685005055672	100	0.001	100	50	0.0	0.5	2683
48	0.010853407375968049	0.010245053776064408	100	0.001	100	50	0.0	0.5	2683
49	0.01083424358884846	0.010286712142893506	100	0.001	100	50	0.0	0.5	2683
