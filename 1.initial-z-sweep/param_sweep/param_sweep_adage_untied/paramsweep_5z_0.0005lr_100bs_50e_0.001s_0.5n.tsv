	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.325411461766235	0.13956051600480854	5	0.0005	100	50	0.001	0.5	1551
1	0.2838156049906682	0.13391791549057167	5	0.0005	100	50	0.001	0.5	1551
2	0.24953025570904094	0.13634224540872739	5	0.0005	100	50	0.001	0.5	1551
3	0.21767633222933974	0.10852806765878177	5	0.0005	100	50	0.001	0.5	1551
4	0.1891124191206484	0.14637075935848357	5	0.0005	100	50	0.001	0.5	1551
5	0.16877305263000986	0.11802720375373305	5	0.0005	100	50	0.001	0.5	1551
6	0.13946729803866081	0.09780385909356305	5	0.0005	100	50	0.001	0.5	1551
7	0.11938785656005964	0.11829765138161114	5	0.0005	100	50	0.001	0.5	1551
8	0.10736924236167203	0.15242364063830494	5	0.0005	100	50	0.001	0.5	1551
9	0.09880572324425764	0.1124120011184913	5	0.0005	100	50	0.001	0.5	1551
10	0.0924575213466778	0.10720516923622693	5	0.0005	100	50	0.001	0.5	1551
11	0.08785637119078717	0.10843229541701067	5	0.0005	100	50	0.001	0.5	1551
12	0.08208903758288455	0.09878306314491633	5	0.0005	100	50	0.001	0.5	1551
13	0.08386250221772337	0.07212935779849157	5	0.0005	100	50	0.001	0.5	1551
14	0.07685736611740351	0.09583999487227737	5	0.0005	100	50	0.001	0.5	1551
15	0.07144308953996066	0.08085135429613222	5	0.0005	100	50	0.001	0.5	1551
16	0.0783879064659877	0.09562224172497343	5	0.0005	100	50	0.001	0.5	1551
17	0.06855710317349759	0.08244810947154721	5	0.0005	100	50	0.001	0.5	1551
18	0.07023664173714339	0.08433652030977191	5	0.0005	100	50	0.001	0.5	1551
19	0.08013883690687836	0.08928093590540366	5	0.0005	100	50	0.001	0.5	1551
20	0.06911351888877963	0.06373219260408135	5	0.0005	100	50	0.001	0.5	1551
21	0.06654612752306693	0.06946452657191748	5	0.0005	100	50	0.001	0.5	1551
22	0.06365485353068642	0.08064035969442665	5	0.0005	100	50	0.001	0.5	1551
23	0.06415698507757758	0.06701212343590665	5	0.0005	100	50	0.001	0.5	1551
24	0.0597301866959325	0.08149200732005941	5	0.0005	100	50	0.001	0.5	1551
25	0.06610519534874694	0.09641633158546105	5	0.0005	100	50	0.001	0.5	1551
26	0.06703474171777074	0.0756022914617285	5	0.0005	100	50	0.001	0.5	1551
27	0.06493010088519603	0.06016685387714415	5	0.0005	100	50	0.001	0.5	1551
28	0.0612798508663911	0.08426320470199986	5	0.0005	100	50	0.001	0.5	1551
29	0.07408477383225755	0.07408921711189569	5	0.0005	100	50	0.001	0.5	1551
30	0.06281172899628476	0.056334604496709705	5	0.0005	100	50	0.001	0.5	1551
31	0.05303229403922576	0.06750461102301258	5	0.0005	100	50	0.001	0.5	1551
32	0.0628625430989111	0.06672434247389122	5	0.0005	100	50	0.001	0.5	1551
33	0.06049752729004658	0.0806880994178141	5	0.0005	100	50	0.001	0.5	1551
34	0.06572772212137354	0.09567899779767425	5	0.0005	100	50	0.001	0.5	1551
35	0.0634521450433818	0.07501943330378423	5	0.0005	100	50	0.001	0.5	1551
36	0.06541161303735243	0.08881882955649614	5	0.0005	100	50	0.001	0.5	1551
37	0.05942430280399895	0.05942605613209093	5	0.0005	100	50	0.001	0.5	1551
38	0.06091307737879098	0.05003901166453188	5	0.0005	100	50	0.001	0.5	1551
39	0.05599408478461365	0.06547132326044271	5	0.0005	100	50	0.001	0.5	1551
40	0.05701349868232254	0.0685286273392733	5	0.0005	100	50	0.001	0.5	1551
41	0.06557655323787132	0.06855768332859755	5	0.0005	100	50	0.001	0.5	1551
42	0.06581201560064734	0.09015251841417463	5	0.0005	100	50	0.001	0.5	1551
43	0.05927392198225016	0.06466360030478546	5	0.0005	100	50	0.001	0.5	1551
44	0.05766440762633739	0.06741941862705789	5	0.0005	100	50	0.001	0.5	1551
45	0.05708666961819399	0.07208463831681822	5	0.0005	100	50	0.001	0.5	1551
46	0.055835207861518805	0.06537719142140667	5	0.0005	100	50	0.001	0.5	1551
47	0.06487251190623214	0.07974429930743707	5	0.0005	100	50	0.001	0.5	1551
48	0.06666799144229499	0.05553605666750932	5	0.0005	100	50	0.001	0.5	1551
49	0.05737708902472671	0.07590015149937077	5	0.0005	100	50	0.001	0.5	1551
