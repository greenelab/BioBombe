	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.032206035225959766	0.0207035608703616	100	0.001	100	50	0.0	0.1	7365
1	0.01797170065498518	0.015790604193824883	100	0.001	100	50	0.0	0.1	7365
2	0.015171170041252402	0.014155610168911873	100	0.001	100	50	0.0	0.1	7365
3	0.0138790984112169	0.013222798787014663	100	0.001	100	50	0.0	0.1	7365
4	0.01311055692725068	0.012613734864339546	100	0.001	100	50	0.0	0.1	7365
5	0.012590525010029802	0.012166988986043925	100	0.001	100	50	0.0	0.1	7365
6	0.012212893359373369	0.011848441581553414	100	0.001	100	50	0.0	0.1	7365
7	0.011925343776506217	0.011618806307433782	100	0.001	100	50	0.0	0.1	7365
8	0.011709515615711206	0.011390103319264508	100	0.001	100	50	0.0	0.1	7365
9	0.011524657534907732	0.011337999851010156	100	0.001	100	50	0.0	0.1	7365
10	0.011394279487260872	0.011160181480928202	100	0.001	100	50	0.0	0.1	7365
11	0.011319224525001234	0.011069801833701407	100	0.001	100	50	0.0	0.1	7365
12	0.01123211671930991	0.011052970818990048	100	0.001	100	50	0.0	0.1	7365
13	0.011173979376763198	0.011013249679687602	100	0.001	100	50	0.0	0.1	7365
14	0.011153740532918665	0.011002511932847604	100	0.001	100	50	0.0	0.1	7365
15	0.011133291274977994	0.010919161682261107	100	0.001	100	50	0.0	0.1	7365
16	0.011108018331938889	0.010889308443417626	100	0.001	100	50	0.0	0.1	7365
17	0.011086288478744311	0.010885047115542237	100	0.001	100	50	0.0	0.1	7365
18	0.011074258136750692	0.010926479089072056	100	0.001	100	50	0.0	0.1	7365
19	0.011065810743387297	0.010976708816439197	100	0.001	100	50	0.0	0.1	7365
20	0.011050489018072132	0.01085967052884642	100	0.001	100	50	0.0	0.1	7365
21	0.011053183224160233	0.010908646083456494	100	0.001	100	50	0.0	0.1	7365
22	0.011033955665734063	0.010865026999471521	100	0.001	100	50	0.0	0.1	7365
23	0.011029908357867428	0.010851607453184876	100	0.001	100	50	0.0	0.1	7365
24	0.011023835662143315	0.010822993017604884	100	0.001	100	50	0.0	0.1	7365
25	0.01100452709586872	0.010836441274625507	100	0.001	100	50	0.0	0.1	7365
26	0.011007210777902893	0.01080568422550909	100	0.001	100	50	0.0	0.1	7365
27	0.011013438495747293	0.010862079904865238	100	0.001	100	50	0.0	0.1	7365
28	0.011002453054742416	0.010873220392625714	100	0.001	100	50	0.0	0.1	7365
29	0.01099406257386537	0.010787517092338484	100	0.001	100	50	0.0	0.1	7365
30	0.010987185234334338	0.010822315997734352	100	0.001	100	50	0.0	0.1	7365
31	0.010992105752839161	0.0108101105452809	100	0.001	100	50	0.0	0.1	7365
32	0.01098185109284654	0.010886826345885803	100	0.001	100	50	0.0	0.1	7365
33	0.010985871396019293	0.010816105377876395	100	0.001	100	50	0.0	0.1	7365
34	0.010982682051834221	0.01078156874217734	100	0.001	100	50	0.0	0.1	7365
35	0.010969126836085983	0.010753416401079463	100	0.001	100	50	0.0	0.1	7365
36	0.010961321934691166	0.010768905428040551	100	0.001	100	50	0.0	0.1	7365
37	0.010961479242029504	0.01081518446723886	100	0.001	100	50	0.0	0.1	7365
38	0.010964552654115892	0.010812955189061781	100	0.001	100	50	0.0	0.1	7365
39	0.010960880248158026	0.010762334965083954	100	0.001	100	50	0.0	0.1	7365
40	0.010967720194489102	0.010798901244713062	100	0.001	100	50	0.0	0.1	7365
41	0.01096097971069804	0.010776990185888844	100	0.001	100	50	0.0	0.1	7365
42	0.010951676747210471	0.010813795473519178	100	0.001	100	50	0.0	0.1	7365
43	0.010949941335288907	0.01073915793615648	100	0.001	100	50	0.0	0.1	7365
44	0.010946718377512255	0.01079039151173078	100	0.001	100	50	0.0	0.1	7365
45	0.01094869522390315	0.010744518076869202	100	0.001	100	50	0.0	0.1	7365
46	0.010955042041510479	0.010784627381804796	100	0.001	100	50	0.0	0.1	7365
47	0.010941695209608807	0.010805077589051103	100	0.001	100	50	0.0	0.1	7365
48	0.010945740863000132	0.010736812981661145	100	0.001	100	50	0.0	0.1	7365
49	0.010941136382028665	0.010774230336980542	100	0.001	100	50	0.0	0.1	7365
