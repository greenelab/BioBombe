	loss	val_loss	num_components	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.040741877627582655	0.028161549445661942	50	0.001	100	50	1e-06	0.0	460
1	0.024074281669830992	0.02147794577576234	50	0.001	100	50	1e-06	0.0	460
2	0.020204582075989803	0.019226123089145293	50	0.001	100	50	1e-06	0.0	460
3	0.01852734302812003	0.01835178380857006	50	0.001	100	50	1e-06	0.0	460
4	0.017581755675820297	0.01707907615988079	50	0.001	100	50	1e-06	0.0	460
5	0.016754481769404837	0.016680830712100744	50	0.001	100	50	1e-06	0.0	460
6	0.01622475238310538	0.015981293612838246	50	0.001	100	50	1e-06	0.0	460
7	0.015770304462295923	0.015826171410072375	50	0.001	100	50	1e-06	0.0	460
8	0.01563636111217244	0.015527037982018682	50	0.001	100	50	1e-06	0.0	460
9	0.015088330236998005	0.015301314647350439	50	0.001	100	50	1e-06	0.0	460
10	0.014909089040507846	0.01514956556139496	50	0.001	100	50	1e-06	0.0	460
11	0.014708056699448573	0.015375270269611711	50	0.001	100	50	1e-06	0.0	460
12	0.014636034711294646	0.015020764292169711	50	0.001	100	50	1e-06	0.0	460
13	0.014337161683815738	0.01408813687942452	50	0.001	100	50	1e-06	0.0	460
14	0.014197892985896066	0.014487935949551443	50	0.001	100	50	1e-06	0.0	460
15	0.01416459893234906	0.01393988084610744	50	0.001	100	50	1e-06	0.0	460
16	0.01398586161293364	0.014155981608134041	50	0.001	100	50	1e-06	0.0	460
17	0.01377170017276236	0.013609931432066867	50	0.001	100	50	1e-06	0.0	460
18	0.01361589529301742	0.014353064928795024	50	0.001	100	50	1e-06	0.0	460
19	0.01363513435025477	0.013387095660370121	50	0.001	100	50	1e-06	0.0	460
20	0.013547382293539936	0.013845708301330046	50	0.001	100	50	1e-06	0.0	460
21	0.013372904941135685	0.013375023604294082	50	0.001	100	50	1e-06	0.0	460
22	0.013499324207217797	0.013299669176482561	50	0.001	100	50	1e-06	0.0	460
23	0.013327301798166142	0.013815281134504776	50	0.001	100	50	1e-06	0.0	460
24	0.013127789362092796	0.013501978853279386	50	0.001	100	50	1e-06	0.0	460
25	0.013140546945123063	0.013231113161286251	50	0.001	100	50	1e-06	0.0	460
26	0.013085576207669385	0.014317608317342474	50	0.001	100	50	1e-06	0.0	460
27	0.013250564190191131	0.012973346549796785	50	0.001	100	50	1e-06	0.0	460
28	0.01280034697507458	0.013174120682232922	50	0.001	100	50	1e-06	0.0	460
29	0.012988531177640468	0.01316014413737886	50	0.001	100	50	1e-06	0.0	460
30	0.013017858566773104	0.013429128751871007	50	0.001	100	50	1e-06	0.0	460
31	0.012862280521212957	0.013272099537030575	50	0.001	100	50	1e-06	0.0	460
32	0.012946017550633607	0.01301412917068139	50	0.001	100	50	1e-06	0.0	460
33	0.012748568736113316	0.013295649531267113	50	0.001	100	50	1e-06	0.0	460
34	0.012777532798629011	0.013314122186321943	50	0.001	100	50	1e-06	0.0	460
35	0.012979976982167185	0.013118627069813572	50	0.001	100	50	1e-06	0.0	460
36	0.01270571197288618	0.013018318070864471	50	0.001	100	50	1e-06	0.0	460
37	0.012616490923255305	0.013164450758159958	50	0.001	100	50	1e-06	0.0	460
38	0.012762525926337072	0.012750379050268042	50	0.001	100	50	1e-06	0.0	460
39	0.012582223984501598	0.013268963323396775	50	0.001	100	50	1e-06	0.0	460
40	0.012723524309140703	0.012591784050684587	50	0.001	100	50	1e-06	0.0	460
41	0.012703478264108002	0.012643534469330971	50	0.001	100	50	1e-06	0.0	460
42	0.012521836637356742	0.012522114301901702	50	0.001	100	50	1e-06	0.0	460
43	0.012452399672386903	0.012840005496149992	50	0.001	100	50	1e-06	0.0	460
44	0.01305581651359692	0.013902155158909512	50	0.001	100	50	1e-06	0.0	460
45	0.01273402414947248	0.01295793471754623	50	0.001	100	50	1e-06	0.0	460
46	0.01253871248102392	0.012388079432524868	50	0.001	100	50	1e-06	0.0	460
47	0.012502266730668756	0.012399753933170558	50	0.001	100	50	1e-06	0.0	460
48	0.012447750298857443	0.012652408864071332	50	0.001	100	50	1e-06	0.0	460
49	0.012398867906572575	0.012514219240037934	50	0.001	100	50	1e-06	0.0	460
